<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Prodigy Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="AI-powered workflow orchestration for development teams">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Prodigy Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/gbaker-prodigy/prodigy" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Prodigy is an AI-powered workflow orchestration tool that enables development teams to automate complex tasks using Claude AI through structured YAML workflows.</p>
<h2 id="what-is-prodigy"><a class="header" href="#what-is-prodigy">What is Prodigy?</a></h2>
<p>Prodigy combines the power of Claude AI with workflow orchestration to:</p>
<ul>
<li><strong>Automate repetitive development tasks</strong> - Code reviews, refactoring, testing</li>
<li><strong>Process work in parallel</strong> - MapReduce-style parallel execution across git worktrees</li>
<li><strong>Maintain quality</strong> - Built-in validation, error handling, and retry mechanisms</li>
<li><strong>Track changes</strong> - Full git integration with automatic commits and merge workflows</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<p>Create a simple workflow in <code>workflow.yml</code>:</p>
<pre><code class="language-yaml">- shell: "cargo build"
- shell: "cargo test"
  on_failure:
    claude: "/fix-failing-tests"
- shell: "cargo clippy"
</code></pre>
<p>Run it:</p>
<pre><code class="language-bash">prodigy run workflow.yml
</code></pre>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<ul>
<li><strong>Workflows</strong>: YAML files defining sequences of commands</li>
<li><strong>Commands</strong>: Shell commands, Claude AI invocations, or control flow</li>
<li><strong>Variables</strong>: Dynamic values captured and interpolated across steps</li>
<li><strong>MapReduce</strong>: Parallel processing across multiple git worktrees</li>
<li><strong>Validation</strong>: Automatic testing and quality checks</li>
</ul>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li><a href="workflow-basics.html">Workflow Basics</a> - Learn workflow fundamentals</li>
<li><a href="commands.html">Command Types</a> - Explore available command types</li>
<li><a href="examples.html">Examples</a> - See real-world workflows</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="workflow-basics"><a class="header" href="#workflow-basics">Workflow Basics</a></h1>
<p>This chapter covers the fundamentals of creating Prodigy workflows. You’ll learn about workflow structure, basic commands, and configuration options.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Prodigy workflows are YAML files that define a sequence of commands to execute. They can be as simple as a list of shell commands or as complex as parallel MapReduce jobs.</p>
<p><strong>Two Main Workflow Types:</strong></p>
<ul>
<li><strong>Standard Workflows</strong>: Sequential command execution (covered here)</li>
<li><strong>MapReduce Workflows</strong>: Parallel processing with map/reduce phases (see <a href="mapreduce.html">MapReduce chapter</a>)</li>
</ul>
<h2 id="simple-workflows"><a class="header" href="#simple-workflows">Simple Workflows</a></h2>
<p>The simplest workflow is just an array of commands:</p>
<pre><code class="language-yaml"># Simple array format - just list your commands
- shell: "echo 'Starting workflow...'"
- claude: "/prodigy-analyze"
- shell: "cargo test"
</code></pre>
<p>This executes each command sequentially. No additional configuration needed.</p>
<h2 id="full-workflow-structure"><a class="header" href="#full-workflow-structure">Full Workflow Structure</a></h2>
<p>For more complex workflows, use the full format with explicit configuration:</p>
<pre><code class="language-yaml"># Full format with environment and merge configuration
commands:
  - shell: "cargo build"
  - claude: "/prodigy-test"

# Global environment variables (available to all commands)
env:
  NODE_ENV: production
  API_URL: https://api.example.com

# Secret environment variables (masked in logs)
secrets:
  API_KEY: "${env:SECRET_API_KEY}"

# Environment files to load (.env format)
env_files:
  - .env.production

# Environment profiles (switch contexts easily)
profiles:
  development:
    NODE_ENV: development
    DEBUG: "true"

# Custom merge workflow (for worktree integration)
merge:
  - shell: "git fetch origin"
  - claude: "/merge-worktree ${merge.source_branch}"
  timeout: 600  # Optional timeout in seconds
</code></pre>
<h2 id="available-fields"><a class="header" href="#available-fields">Available Fields</a></h2>
<p>Standard workflows support these top-level fields:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td><code>commands</code></td><td>Array</td><td>Yes*</td><td>List of commands to execute sequentially</td></tr>
<tr><td><code>env</code></td><td>Map</td><td>No</td><td>Global environment variables</td></tr>
<tr><td><code>secrets</code></td><td>Map</td><td>No</td><td>Secret environment variables (masked in logs)</td></tr>
<tr><td><code>env_files</code></td><td>Array</td><td>No</td><td>Paths to .env files to load</td></tr>
<tr><td><code>profiles</code></td><td>Map</td><td>No</td><td>Named environment profiles</td></tr>
<tr><td><code>merge</code></td><td>Object</td><td>No</td><td>Custom merge workflow for worktree integration</td></tr>
</tbody></table>
</div>
<p><strong>Note:</strong> <code>commands</code> is only required in the full format. Simple array format doesn’t use the <code>commands</code> key.</p>
<h2 id="command-types"><a class="header" href="#command-types">Command Types</a></h2>
<p>Prodigy supports several types of commands in workflows:</p>
<h3 id="core-commands"><a class="header" href="#core-commands">Core Commands</a></h3>
<p><strong><code>shell:</code></strong> - Execute shell commands</p>
<pre><code class="language-yaml">- shell: "cargo build --release"
- shell: "npm install"
</code></pre>
<p><strong><code>claude:</code></strong> - Invoke Claude Code commands</p>
<pre><code class="language-yaml">- claude: "/prodigy-lint"
- claude: "/analyze codebase"
</code></pre>
<h3 id="advanced-commands"><a class="header" href="#advanced-commands">Advanced Commands</a></h3>
<ul>
<li><strong><code>goal_seek:</code></strong> - Goal-seeking operations with validation (see <a href="goal-seeking.html">Goal Seeking chapter</a>)</li>
<li><strong><code>foreach:</code></strong> - Iterate over lists with nested commands (see <a href="loops.html">Loops chapter</a>)</li>
<li><strong><code>validate:</code></strong> - Validation steps (see <a href="validation.html">Validation chapter</a>)</li>
<li><strong><code>analyze:</code></strong> - Analysis operations (see <a href="analysis.html">Analysis chapter</a>)</li>
</ul>
<p>For detailed information on each command type and advanced features like conditional execution, error handling, and output capture, see the <a href="command-reference.html">Command Reference chapter</a>.</p>
<h2 id="environment-configuration"><a class="header" href="#environment-configuration">Environment Configuration</a></h2>
<p>Environment variables can be configured at multiple levels:</p>
<h3 id="global-environment-variables"><a class="header" href="#global-environment-variables">Global Environment Variables</a></h3>
<pre><code class="language-yaml">env:
  NODE_ENV: production
  DATABASE_URL: postgres://localhost/mydb
</code></pre>
<h3 id="secret-variables"><a class="header" href="#secret-variables">Secret Variables</a></h3>
<p>Secret variables are masked in logs for security:</p>
<pre><code class="language-yaml">secrets:
  API_KEY: "${env:SECRET_API_KEY}"
  DB_PASSWORD: "${env:DATABASE_PASSWORD}"
</code></pre>
<h3 id="environment-files"><a class="header" href="#environment-files">Environment Files</a></h3>
<p>Load variables from .env files:</p>
<pre><code class="language-yaml">env_files:
  - .env
  - .env.production
</code></pre>
<h3 id="environment-profiles"><a class="header" href="#environment-profiles">Environment Profiles</a></h3>
<p>Switch between different environment contexts:</p>
<pre><code class="language-yaml">profiles:
  development:
    NODE_ENV: development
    DEBUG: "true"
    API_URL: http://localhost:3000

  production:
    NODE_ENV: production
    DEBUG: "false"
    API_URL: https://api.example.com
</code></pre>
<p>Activate a profile with: <code>prodigy run --profile development</code></p>
<p>For more details, see the <a href="environment.html">Environment Variables chapter</a>.</p>
<h2 id="merge-workflows"><a class="header" href="#merge-workflows">Merge Workflows</a></h2>
<p>Merge workflows execute when merging worktree changes back to the main branch. This allows custom validation and conflict resolution:</p>
<pre><code class="language-yaml">merge:
  - shell: "git fetch origin"
  - shell: "git merge origin/main"
  - shell: "cargo test"
  - claude: "/prodigy-merge-worktree ${merge.source_branch}"
  timeout: 600
</code></pre>
<p><strong>Available merge variables:</strong></p>
<ul>
<li><code>${merge.worktree}</code> - Worktree name</li>
<li><code>${merge.source_branch}</code> - Source branch (worktree branch)</li>
<li><code>${merge.target_branch}</code> - Target branch (usually main/master)</li>
<li><code>${merge.session_id}</code> - Session ID</li>
</ul>
<h2 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h2>
<p>Here’s a complete workflow combining multiple features:</p>
<pre><code class="language-yaml"># Environment configuration
env:
  RUST_BACKTRACE: 1

env_files:
  - .env

profiles:
  ci:
    CI: "true"
    VERBOSE: "true"

# Workflow commands
commands:
  - shell: "cargo fmt --check"
  - shell: "cargo clippy -- -D warnings"
  - shell: "cargo test --all"
  - claude: "/prodigy-lint"

# Custom merge workflow
merge:
  - shell: "cargo test"
  - claude: "/prodigy-merge-worktree ${merge.source_branch}"
  timeout: 300
</code></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>Now that you understand basic workflows, explore these topics:</p>
<ul>
<li><strong><a href="command-reference.html">Command Reference</a></strong> - Detailed guide to all command types and options</li>
<li><strong><a href="environment.html">Environment Variables</a></strong> - Advanced environment configuration</li>
<li><strong><a href="error-handling.html">Error Handling</a></strong> - Handle failures gracefully</li>
<li><strong><a href="mapreduce.html">MapReduce Workflows</a></strong> - Parallel processing for large-scale tasks</li>
<li><strong><a href="conditionals.html">Conditional Execution</a></strong> - Run commands based on conditions</li>
<li><strong><a href="output-capture.html">Output Capture</a></strong> - Capture and use command outputs</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mapreduce-workflows"><a class="header" href="#mapreduce-workflows">MapReduce Workflows</a></h1>
<h2 id="complete-structure"><a class="header" href="#complete-structure">Complete Structure</a></h2>
<pre><code class="language-yaml">name: parallel-processing
mode: mapreduce

# Optional setup phase
setup:
  - shell: "generate-work-items.sh"
  - shell: "debtmap analyze . --output items.json"

# Map phase: Process items in parallel
map:
  # Input source (JSON file or command)
  input: "items.json"

  # JSONPath expression to extract items
  json_path: "$.items[*]"

  # Agent template (commands run for each item)
  # Modern syntax: Commands directly under agent_template
  agent_template:
    - claude: "/process '${item}'"
    - shell: "test ${item.path}"
      on_failure:
        claude: "/fix-issue '${item}'"

  # DEPRECATED: Nested 'commands' syntax (still supported)
  # agent_template:
  #   commands:
  #     - claude: "/process '${item}'"

  # Maximum parallel agents
  max_parallel: 10

  # Optional: Filter items
  filter: "item.score &gt;= 5"

  # Optional: Sort items
  sort_by: "item.priority DESC"

  # Optional: Limit number of items
  max_items: 100

  # Optional: Skip items
  offset: 10

  # Optional: Deduplicate by field
  distinct: "item.id"

  # Optional: Agent timeout in seconds
  agent_timeout_secs: 300

# Reduce phase: Aggregate results
# Modern syntax: Commands directly under reduce
reduce:
  - claude: "/summarize ${map.results}"
  - shell: "echo 'Processed ${map.successful}/${map.total} items'"

# DEPRECATED: Nested 'commands' syntax (still supported)
# reduce:
#   commands:
#     - claude: "/summarize ${map.results}"

# Optional: Custom merge workflow (supports two formats)
merge:
  # Simple array format
  - shell: "git fetch origin"
  - claude: "/merge-worktree ${merge.source_branch}"
  - shell: "cargo test"

# OR full format with timeout
# merge:
#   commands:
#     - shell: "git fetch origin"
#     - claude: "/merge-worktree ${merge.source_branch}"
#   timeout: 600  # Timeout in seconds

# Error handling policy
error_policy:
  on_item_failure: dlq  # dlq, retry, skip, stop, or custom handler name
  continue_on_failure: true
  max_failures: 5
  failure_threshold: 0.2  # 20% failure rate
  error_collection: aggregate  # aggregate, immediate, or batched:N

  # Circuit breaker configuration
  circuit_breaker:
    failure_threshold: 5      # Open circuit after N failures
    success_threshold: 2      # Close circuit after N successes
    timeout: 60              # Seconds before attempting half-open
    half_open_requests: 3    # Test requests in half-open state

  # Retry configuration with backoff
  retry_config:
    max_attempts: 3
    backoff:
      type: exponential      # fixed, linear, exponential, fibonacci
      initial: 1000          # Initial delay in ms
      multiplier: 2          # For exponential
      max_delay: 30000       # Maximum delay in ms

# Convenience fields (alternative to nested error_policy)
# These top-level fields map to error_policy for simpler syntax
on_item_failure: dlq
continue_on_failure: true
max_failures: 5
</code></pre>
<h2 id="setup-phase-advanced"><a class="header" href="#setup-phase-advanced">Setup Phase (Advanced)</a></h2>
<p>The setup phase supports two formats: simple array OR full configuration object.</p>
<pre><code class="language-yaml"># Simple array format
setup:
  - shell: "prepare-data.sh"
  - shell: "analyze-codebase.sh"

# Full configuration format with timeout and capture
setup:
  commands:
    - shell: "prepare-data.sh"
    - shell: "analyze-codebase.sh"

  # Timeout for entire setup phase (seconds)
  timeout: 300

  # Capture outputs from setup commands
  capture_outputs:
    # Simple format (legacy - just index)
    file_count: 0  # Capture from command at index 0

    # Full CaptureConfig format
    analysis_result:
      command_index: 1
      format: json  # string, number, json, lines, boolean
</code></pre>
<p><strong>Setup Phase Fields:</strong></p>
<ul>
<li><code>commands</code> - Array of commands to execute (or use simple array format at top level)</li>
<li><code>timeout</code> - Timeout for entire setup phase in seconds</li>
<li><code>capture_outputs</code> - Map of variable names to command outputs (supports Simple(index) or full CaptureConfig)</li>
</ul>
<h2 id="global-storage-architecture"><a class="header" href="#global-storage-architecture">Global Storage Architecture</a></h2>
<p>MapReduce workflows use a global storage architecture located in <code>~/.prodigy/</code> (not <code>.prodigy/</code> in your project). This enables:</p>
<ul>
<li><strong>Cross-worktree event aggregation</strong>: Multiple worktrees working on the same job share event logs</li>
<li><strong>Persistent state management</strong>: Job checkpoints survive worktree cleanup</li>
<li><strong>Centralized monitoring</strong>: All job data accessible from a single location</li>
<li><strong>Efficient storage</strong>: Deduplication across worktrees</li>
</ul>
<h3 id="storage-locations"><a class="header" href="#storage-locations">Storage Locations</a></h3>
<pre><code>~/.prodigy/
├── events/
│   └── {repo_name}/          # Events grouped by repository
│       └── {job_id}/         # Job-specific events
│           └── events-{timestamp}.jsonl  # Event log files
├── dlq/
│   └── {repo_name}/          # DLQ grouped by repository
│       └── {job_id}/         # Job-specific failed items
└── state/
    └── {repo_name}/          # State grouped by repository
        └── mapreduce/        # MapReduce job states
            └── jobs/
                └── {job_id}/ # Job-specific checkpoints
</code></pre>
<h2 id="event-tracking"><a class="header" href="#event-tracking">Event Tracking</a></h2>
<p>All MapReduce execution events are logged to <code>~/.prodigy/events/{repo_name}/{job_id}/</code> for debugging and monitoring:</p>
<p><strong>Events Tracked:</strong></p>
<ul>
<li>Agent lifecycle events (started, completed, failed)</li>
<li>Work item processing status</li>
<li>Checkpoint saves for resumption</li>
<li>Error details with correlation IDs</li>
<li>Cross-worktree event aggregation for parallel jobs</li>
</ul>
<p><strong>Event Log Format:</strong>
Events are stored in JSONL (JSON Lines) format, with each line representing a single event:</p>
<pre><code class="language-json">{"timestamp":"2024-01-01T12:00:00Z","event_type":"agent_started","agent_id":"agent-1","item_id":"item-001"}
{"timestamp":"2024-01-01T12:05:00Z","event_type":"agent_completed","agent_id":"agent-1","item_id":"item-001","status":"success"}
</code></pre>
<p><strong>Viewing Events:</strong></p>
<pre><code class="language-bash"># View all events for a job
prodigy events &lt;job_id&gt;

# Stream events in real-time
prodigy events &lt;job_id&gt; --follow
</code></pre>
<h2 id="checkpoint-and-resume"><a class="header" href="#checkpoint-and-resume">Checkpoint and Resume</a></h2>
<p>MapReduce workflows automatically save checkpoints to enable resumption after interruption.</p>
<h3 id="checkpoint-structure"><a class="header" href="#checkpoint-structure">Checkpoint Structure</a></h3>
<p>Checkpoints are stored in <code>~/.prodigy/state/{repo_name}/mapreduce/jobs/{job_id}/</code> and contain:</p>
<pre><code class="language-json">{
  "job_id": "mapreduce-1234567890",
  "workflow_file": "workflow.yml",
  "phase": "map",
  "items_processed": 45,
  "items_total": 100,
  "items_remaining": ["item-046", "item-047", "..."],
  "successful_items": 43,
  "failed_items": 2,
  "started_at": "2024-01-01T12:00:00Z",
  "last_checkpoint_at": "2024-01-01T12:30:00Z"
}
</code></pre>
<h3 id="resume-behavior"><a class="header" href="#resume-behavior">Resume Behavior</a></h3>
<p>When resuming a MapReduce job:</p>
<ol>
<li><strong>Checkpoint Loading</strong>: Prodigy loads the most recent checkpoint from <code>~/.prodigy/state/</code></li>
<li><strong>Work Item Recovery</strong>: Items marked as “in progress” are reset to “pending”</li>
<li><strong>Failed Item Handling</strong>: Previously failed items are moved to DLQ (not retried automatically)</li>
<li><strong>Partial Results</strong>: Successfully processed items are preserved</li>
<li><strong>Phase Continuation</strong>: Job resumes from the phase it was interrupted in</li>
</ol>
<p><strong>Resume Command:</strong></p>
<pre><code class="language-bash"># Resume from checkpoint
prodigy resume-job &lt;job_id&gt;

# Resume with different parallelism
prodigy resume-job &lt;job_id&gt; --max-parallel 20

# Resume and show detailed logs
prodigy resume-job &lt;job_id&gt; -v
</code></pre>
<h2 id="dead-letter-queue-dlq"><a class="header" href="#dead-letter-queue-dlq">Dead Letter Queue (DLQ)</a></h2>
<p>Failed work items are automatically stored in the DLQ for review and retry.</p>
<h3 id="dlq-storage"><a class="header" href="#dlq-storage">DLQ Storage</a></h3>
<p>Failed items are stored in <code>~/.prodigy/dlq/{repo_name}/{job_id}/</code> with this structure:</p>
<pre><code class="language-json">{
  "item_id": "item-047",
  "item_data": {
    "path": "src/module.rs",
    "score": 8,
    "priority": "high"
  },
  "failure_reason": "Command failed: cargo test",
  "error_details": "test failed: expected X but got Y",
  "failed_at": "2024-01-01T12:15:00Z",
  "attempt_count": 3,
  "correlation_id": "agent-7-item-047"
}
</code></pre>
<h3 id="dlq-retry"><a class="header" href="#dlq-retry">DLQ Retry</a></h3>
<p>The <code>prodigy dlq retry</code> command allows you to reprocess failed items:</p>
<pre><code class="language-bash"># Retry all failed items for a job
prodigy dlq retry &lt;job_id&gt;

# Retry with custom parallelism (default: 5)
prodigy dlq retry &lt;job_id&gt; --max-parallel 10

# Dry run to see what would be retried
prodigy dlq retry &lt;job_id&gt; --dry-run

# Verbose output for debugging
prodigy dlq retry &lt;job_id&gt; -v
</code></pre>
<p><strong>DLQ Retry Features:</strong></p>
<ul>
<li>Streams items to avoid memory issues with large queues</li>
<li>Respects original workflow’s <code>max_parallel</code> setting</li>
<li>Preserves correlation IDs for tracking</li>
<li>Updates DLQ state (removes successful, keeps failed)</li>
<li>Supports interruption and resumption</li>
<li>Retried items inherit original workflow configuration</li>
</ul>
<p><strong>DLQ Retry Workflow:</strong></p>
<ol>
<li>Load failed items from <code>~/.prodigy/dlq/{repo_name}/{job_id}/</code></li>
<li>Process items using original workflow’s agent template</li>
<li>Successfully processed items are removed from DLQ</li>
<li>Still-failing items remain in DLQ with updated attempt count</li>
<li>New failures during retry are logged and added to DLQ</li>
</ol>
<h3 id="viewing-dlq-contents"><a class="header" href="#viewing-dlq-contents">Viewing DLQ Contents</a></h3>
<pre><code class="language-bash"># List all failed items
prodigy dlq list &lt;job_id&gt;

# Show details for specific item
prodigy dlq show &lt;job_id&gt; &lt;item_id&gt;

# Clear DLQ after manual fixes
prodigy dlq clear &lt;job_id&gt;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="command-types-1"><a class="header" href="#command-types-1">Command Types</a></h1>
<h2 id="1-shell-commands"><a class="header" href="#1-shell-commands">1. Shell Commands</a></h2>
<pre><code class="language-yaml"># Simple shell command
- shell: "cargo test"

# With output capture
- shell: "ls -la | wc -l"
  capture: "file_count"

# With failure handling
- shell: "cargo clippy"
  on_failure:
    claude: "/fix-warnings ${shell.output}"

# With timeout
- shell: "cargo bench"
  timeout: 600  # seconds

# With conditional execution
- shell: "cargo build --release"
  when: "${tests_passed}"
</code></pre>
<h2 id="2-claude-commands"><a class="header" href="#2-claude-commands">2. Claude Commands</a></h2>
<pre><code class="language-yaml"># Simple Claude command
- claude: "/prodigy-analyze"

# With arguments
- claude: "/prodigy-implement-spec ${spec_file}"

# With commit requirement
- claude: "/prodigy-fix-bugs"
  commit_required: true

# With output capture
- claude: "/prodigy-generate-plan"
  capture: "implementation_plan"
</code></pre>
<h2 id="3-goal-seeking-commands"><a class="header" href="#3-goal-seeking-commands">3. Goal-Seeking Commands</a></h2>
<p>Iteratively refine code until a validation threshold is met.</p>
<pre><code class="language-yaml">- goal_seek:
    goal: "Achieve 90% test coverage"
    claude: "/prodigy-coverage --improve"
    validate: "cargo tarpaulin --print-summary | grep 'Coverage' | sed 's/.*Coverage=\\([0-9]*\\).*/score: \\1/'"
    threshold: 90
    max_attempts: 5
    timeout_seconds: 300
    fail_on_incomplete: true
  commit_required: true
</code></pre>
<p><strong>Fields:</strong></p>
<ul>
<li><code>goal</code>: Human-readable description</li>
<li><code>claude</code> or <code>shell</code>: Command to execute for refinement</li>
<li><code>validate</code>: Command that outputs <code>score: N</code> (0-100)</li>
<li><code>threshold</code>: Minimum score to consider complete</li>
<li><code>max_attempts</code>: Maximum refinement iterations</li>
<li><code>timeout_seconds</code>: Optional timeout per attempt</li>
<li><code>fail_on_incomplete</code>: Whether to fail workflow if threshold not met</li>
</ul>
<h2 id="4-foreach-commands"><a class="header" href="#4-foreach-commands">4. Foreach Commands</a></h2>
<p>Iterate over a list with optional parallelism.</p>
<pre><code class="language-yaml">- foreach:
    input: "find . -name '*.rs' -type f"  # Command
    # OR
    # input: ["file1.rs", "file2.rs"]    # List

    parallel: 5  # Number of parallel executions (or true/false)

    do:
      - claude: "/analyze-file ${item}"
      - shell: "cargo check ${item}"

    continue_on_error: true
    max_items: 50
</code></pre>
<h2 id="5-validation-commands"><a class="header" href="#5-validation-commands">5. Validation Commands</a></h2>
<p>Validate implementation completeness with automatic retry.</p>
<pre><code class="language-yaml">- claude: "/implement-auth-spec"
  validate:
    shell: "debtmap validate --spec auth.md --output result.json"
    # DEPRECATED: 'command' field (use 'shell' instead)
    result_file: "result.json"
    threshold: 95  # Percentage completion required (default: 100.0)
    timeout: 60
    expected_schema: "validation-schema.json"  # Optional JSON schema

    # What to do if incomplete
    on_incomplete:
      claude: "/complete-implementation ${validation.gaps}"
      max_attempts: 3
      fail_workflow: true
      commit_required: true
      prompt: "Implementation incomplete. Continue?"  # Optional interactive prompt
</code></pre>
<p><strong>ValidationConfig Fields:</strong></p>
<ul>
<li><code>shell</code> or <code>claude</code> - Single validation command (use <code>shell</code>, not deprecated <code>command</code>)</li>
<li><code>commands</code> - Array of commands for multi-step validation</li>
<li><code>result_file</code> - Path to JSON file with validation results</li>
<li><code>threshold</code> - Minimum completion percentage (default: 100.0)</li>
<li><code>timeout</code> - Timeout in seconds</li>
<li><code>expected_schema</code> - JSON schema for validation output structure</li>
</ul>
<p><strong>OnIncompleteConfig Fields:</strong></p>
<ul>
<li><code>shell</code> or <code>claude</code> - Single gap-filling command</li>
<li><code>commands</code> - Array of commands for multi-step gap filling</li>
<li><code>max_attempts</code> - Maximum retry attempts</li>
<li><code>fail_workflow</code> - Whether to fail workflow if validation incomplete</li>
<li><code>commit_required</code> - Whether to require commit after gap filling</li>
<li><code>prompt</code> - Optional interactive prompt for user guidance</li>
<li><code>retry_original</code> - Whether to retry the original command (default: false). When true, re-executes the original command instead of gap-filling commands</li>
<li><code>strategy</code> - Retry strategy configuration (similar to OnFailureConfig strategy)</li>
</ul>
<p><strong>Alternative: Array format for multi-step validation</strong></p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    # When using array format, ValidationConfig uses default threshold (100.0)
    # and creates a commands array
    - shell: "run-tests.sh"
    - shell: "check-coverage.sh"
    - claude: "/validate-implementation --output validation.json"
      result_file: "validation.json"
</code></pre>
<p><strong>Alternative: Multi-step gap filling</strong></p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    shell: "validate.sh"
    result_file: "result.json"
    on_incomplete:
      commands:
        - claude: "/analyze-gaps ${validation.gaps}"
        - shell: "run-fix-script.sh"
        - claude: "/verify-fixes"
      max_attempts: 2
</code></pre>
<p><strong>Alternative: Retry original command on incomplete</strong></p>
<pre><code class="language-yaml">- claude: "/implement-auth"
  validate:
    shell: "validate-auth.sh"
    result_file: "result.json"
    threshold: 95
    on_incomplete:
      retry_original: true  # Re-run "/implement-auth" instead of gap-filling
      max_attempts: 3
      fail_workflow: true
</code></pre>
<hr />
<h2 id="command-reference"><a class="header" href="#command-reference">Command Reference</a></h2>
<h3 id="command-fields"><a class="header" href="#command-fields">Command Fields</a></h3>
<p>All command types support these common fields:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>id</code></td><td>string</td><td>Unique identifier for referencing outputs</td></tr>
<tr><td><code>timeout</code></td><td>number</td><td>Command timeout in seconds</td></tr>
<tr><td><code>commit_required</code></td><td>boolean</td><td>Whether command should create a git commit</td></tr>
<tr><td><code>when</code></td><td>string</td><td>Conditional execution expression</td></tr>
<tr><td><code>capture</code></td><td>string</td><td>Variable name to capture output (replaces deprecated <code>capture_output: true/false</code>)</td></tr>
<tr><td><code>capture_format</code></td><td>enum</td><td>Format: <code>string</code> (default), <code>number</code>, <code>json</code>, <code>lines</code>, <code>boolean</code> (see examples below)</td></tr>
<tr><td><code>capture_streams</code></td><td>object</td><td>Configure which streams to capture (see CaptureStreams section below)</td></tr>
<tr><td><code>on_success</code></td><td>object</td><td>Command to run on success</td></tr>
<tr><td><code>on_failure</code></td><td>object</td><td>OnFailureConfig with nested command, max_attempts, fail_workflow, strategy</td></tr>
<tr><td><code>on_exit_code</code></td><td>map</td><td>Maps exit codes to full WorkflowStep objects (e.g., <code>101: {claude: "/fix"}</code>)</td></tr>
<tr><td><code>validate</code></td><td>object</td><td>Validation configuration</td></tr>
<tr><td><code>handler</code></td><td>object</td><td>HandlerStep for modular command handlers</td></tr>
<tr><td><code>retry</code></td><td>object</td><td>RetryConfig for enhanced retry with exponential backoff and jitter</td></tr>
<tr><td><code>working_dir</code></td><td>string</td><td>Working directory for command execution</td></tr>
<tr><td><code>env</code></td><td>map</td><td>Command-level environment variables (HashMap&lt;String, String&gt;)</td></tr>
<tr><td><code>output_file</code></td><td>string</td><td>Redirect command output to a file</td></tr>
<tr><td><code>auto_commit</code></td><td>boolean</td><td>Automatically create commit if changes detected (default: false)</td></tr>
<tr><td><code>commit_config</code></td><td>object</td><td>Advanced CommitConfig for commit control</td></tr>
<tr><td><code>step_validate</code></td><td>object</td><td>StepValidationSpec for post-execution validation</td></tr>
<tr><td><code>skip_validation</code></td><td>boolean</td><td>Skip step validation (default: false)</td></tr>
<tr><td><code>validation_timeout</code></td><td>number</td><td>Timeout in seconds for validation operations</td></tr>
<tr><td><code>ignore_validation_failure</code></td><td>boolean</td><td>Continue workflow even if validation fails (default: false)</td></tr>
</tbody></table>
</div>
<h3 id="capturestreams-configuration"><a class="header" href="#capturestreams-configuration">CaptureStreams Configuration</a></h3>
<p>The <code>capture_streams</code> field controls which output streams are captured:</p>
<pre><code class="language-yaml">- shell: "cargo test"
  capture: "test_results"
  capture_streams:
    stdout: true      # Capture standard output (default: true)
    stderr: false     # Capture standard error (default: false)
    exit_code: true   # Capture exit code (default: true)
    success: true     # Capture success boolean (default: true)
    duration: true    # Capture execution duration (default: true)
</code></pre>
<p><strong>Examples:</strong></p>
<pre><code class="language-yaml"># Capture only stdout and stderr
- shell: "build.sh"
  capture: "build_output"
  capture_streams:
    stdout: true
    stderr: true
    exit_code: false
    success: false
    duration: false

# Capture only timing information
- shell: "benchmark.sh"
  capture: "bench_time"
  capture_streams:
    stdout: false
    stderr: false
    exit_code: false
    success: false
    duration: true
</code></pre>
<h3 id="capture-format-examples"><a class="header" href="#capture-format-examples">Capture Format Examples</a></h3>
<p>The <code>capture_format</code> field controls how captured output is parsed:</p>
<pre><code class="language-yaml"># String format (default) - raw text output
- shell: "git rev-parse HEAD"
  capture: "commit_hash"
  capture_format: "string"

# Number format - parses numeric output
- shell: "wc -l &lt; file.txt"
  capture: "line_count"
  capture_format: "number"

# JSON format - parses JSON output
- shell: "cargo metadata --format-version 1"
  capture: "project_metadata"
  capture_format: "json"

# Lines format - splits output into array of lines
- shell: "git diff --name-only"
  capture: "changed_files"
  capture_format: "lines"

# Boolean format - true if command succeeds, false otherwise
- shell: "grep -q 'pattern' file.txt"
  capture: "pattern_found"
  capture_format: "boolean"
</code></pre>
<h3 id="deprecated-fields"><a class="header" href="#deprecated-fields">Deprecated Fields</a></h3>
<p>These fields are deprecated but still supported for backward compatibility:</p>
<ul>
<li><code>test:</code> - Use <code>shell:</code> with <code>on_failure:</code> instead</li>
<li><code>command:</code> in ValidationConfig - Use <code>shell:</code> instead</li>
<li>Nested <code>commands:</code> in <code>agent_template</code> and <code>reduce</code> - Use direct array format instead</li>
<li>Legacy variable aliases (<code>$ARG</code>, <code>$ARGUMENT</code>, <code>$FILE</code>, <code>$FILE_PATH</code>) - Use modern <code>${item.*}</code> syntax</li>
</ul>
<p><strong>Migration: capture_output to capture</strong></p>
<p>Old syntax (deprecated):</p>
<pre><code class="language-yaml">- shell: "ls -la | wc -l"
  capture_output: true
</code></pre>
<p>New syntax (recommended):</p>
<pre><code class="language-yaml">- shell: "ls -la | wc -l"
  capture: "file_count"
</code></pre>
<p>The modern <code>capture</code> field allows you to specify a variable name, making output references clearer and more maintainable</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="variable-interpolation"><a class="header" href="#variable-interpolation">Variable Interpolation</a></h1>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>Prodigy provides two complementary variable systems:</p>
<ol>
<li><strong>Built-in Variables</strong>: Automatically available based on workflow context (workflow state, step info, work items, etc.)</li>
<li><strong>Custom Captured Variables</strong>: User-defined variables created via the <code>capture:</code> field in commands</li>
</ol>
<p>Both systems use the same <code>${variable.name}</code> interpolation syntax and can be freely mixed in your workflows.</p>
<h2 id="variable-availability-by-phase"><a class="header" href="#variable-availability-by-phase">Variable Availability by Phase</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Variable Category</th><th>Setup</th><th>Map</th><th>Reduce</th><th>Merge</th></tr></thead><tbody>
<tr><td>Standard Variables</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr>
<tr><td>Output Variables</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr>
<tr><td>Item Variables (<code>${item.*}</code>)</td><td>✗</td><td>✓</td><td>✗</td><td>✗</td></tr>
<tr><td>Map Aggregation (<code>${map.total}</code>, etc.)</td><td>✗</td><td>✗</td><td>✓</td><td>✗</td></tr>
<tr><td>Merge Variables</td><td>✗</td><td>✗</td><td>✗</td><td>✓</td></tr>
<tr><td>Custom Captured Variables</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr>
</tbody></table>
</div>
<h2 id="available-variables"><a class="header" href="#available-variables">Available Variables</a></h2>
<h3 id="standard-variables"><a class="header" href="#standard-variables">Standard Variables</a></h3>
<ul>
<li><code>${workflow.name}</code> - Workflow name</li>
<li><code>${workflow.id}</code> - Workflow unique identifier</li>
<li><code>${workflow.iteration}</code> - Current iteration number</li>
<li><code>${step.name}</code> - Current step name</li>
<li><code>${step.index}</code> - Current step index</li>
<li><code>${step.files_changed}</code> - Files changed in current step</li>
<li><code>${workflow.files_changed}</code> - All files changed in workflow</li>
</ul>
<h3 id="output-variables"><a class="header" href="#output-variables">Output Variables</a></h3>
<p><strong>Primary Output Variables:</strong></p>
<ul>
<li><code>${shell.output}</code> - Output (stdout) from last shell command</li>
<li><code>${claude.output}</code> - Output from last Claude command</li>
<li><code>${last.output}</code> - Output from last executed command (any type)</li>
<li><code>${last.exit_code}</code> - Exit code from last command</li>
</ul>
<p><strong>Note</strong>: <code>${shell.output}</code> is the correct variable name for shell command output. The code uses <code>shell.output</code>, not <code>shell.stdout</code>.</p>
<p><strong>Legacy/Specialized Output Variables:</strong></p>
<ul>
<li><code>${handler.output}</code> - Output from handler command (used in error handling)</li>
<li><code>${test.output}</code> - Output from test command (used in validation)</li>
<li><code>${goal_seek.output}</code> - Output from goal-seeking command</li>
</ul>
<p><strong>Best Practice</strong>: For most workflows, use custom capture variables (via <code>capture:</code> field) instead of relying on these automatic output variables. This provides explicit naming and better readability.</p>
<h3 id="mapreduce-variables"><a class="header" href="#mapreduce-variables">MapReduce Variables</a></h3>
<p><strong>Map Phase Variables</strong> (available in <code>agent_template:</code> commands):</p>
<ul>
<li><code>${item}</code> - Current work item in map phase (scope: map phase only)</li>
<li><code>${item.value}</code> - Value of current item (for simple items)</li>
<li><code>${item.path}</code> - Path field of current item</li>
<li><code>${item.name}</code> - Name field of current item</li>
<li><code>${item.*}</code> - Access any item field using wildcard pattern (e.g., <code>${item.id}</code>, <code>${item.priority}</code>)</li>
<li><code>${item_index}</code> - Index of current item in the list</li>
<li><code>${item_total}</code> - Total number of items being processed</li>
<li><code>${map.key}</code> - Current map key</li>
<li><code>${worker.id}</code> - ID of the current worker agent</li>
</ul>
<p><strong>Reduce Phase Variables</strong> (available in <code>reduce:</code> commands):</p>
<ul>
<li><code>${map.total}</code> - Total items processed across all map agents</li>
<li><code>${map.successful}</code> - Number of successfully processed items</li>
<li><code>${map.failed}</code> - Number of failed items</li>
<li><code>${map.results}</code> - Aggregated results from all map agents (JSON array)</li>
</ul>
<p><strong>Note</strong>: <code>${item}</code> and related item variables are only available within the map phase. The aggregation variables (<code>${map.total}</code>, <code>${map.successful}</code>, <code>${map.failed}</code>, <code>${map.results}</code>) are only available in the reduce phase.</p>
<h3 id="merge-variables"><a class="header" href="#merge-variables">Merge Variables</a></h3>
<ul>
<li><code>${merge.worktree}</code> - Worktree name</li>
<li><code>${merge.source_branch}</code> - Source branch</li>
<li><code>${merge.target_branch}</code> - Target branch</li>
<li><code>${merge.session_id}</code> - Session ID</li>
</ul>
<h3 id="validation-variables"><a class="header" href="#validation-variables">Validation Variables</a></h3>
<ul>
<li><code>${validation.completion}</code> - Completion percentage</li>
<li><code>${validation.completion_percentage}</code> - Completion percentage (numeric)</li>
<li><code>${validation.implemented}</code> - List of implemented features</li>
<li><code>${validation.missing}</code> - Missing requirements</li>
<li><code>${validation.gaps}</code> - Gap details</li>
<li><code>${validation.status}</code> - Status (complete/incomplete/failed)</li>
</ul>
<h3 id="git-context-variables"><a class="header" href="#git-context-variables">Git Context Variables</a></h3>
<ul>
<li><code>${step.commits}</code> - Commits in current step (array of commit objects)</li>
<li><code>${workflow.commits}</code> - All workflow commits (array of commit objects)</li>
</ul>
<p><strong>Note</strong>: These are arrays of commit data. Use in foreach loops or access individual commits with array indexing. Each commit object contains fields like hash, message, timestamp, etc.</p>
<h3 id="legacy-variable-aliases"><a class="header" href="#legacy-variable-aliases">Legacy Variable Aliases</a></h3>
<p>These legacy aliases are supported for backward compatibility but should be replaced with modern equivalents:</p>
<ul>
<li><code>$ARG</code> / <code>$ARGUMENT</code> - Legacy aliases for <code>${item.value}</code> (available in WithArguments mode)</li>
<li><code>$FILE</code> / <code>$FILE_PATH</code> - Legacy aliases for <code>${item.path}</code> (available in WithFilePattern mode)</li>
</ul>
<p><strong>Note:</strong> Use the modern <code>${item.*}</code> syntax in new workflows instead of legacy aliases.</p>
<hr />
<h2 id="custom-variable-capture"><a class="header" href="#custom-variable-capture">Custom Variable Capture</a></h2>
<p>Custom capture variables allow you to save command output with explicit names for later use. This is the recommended approach for most workflows instead of relying on automatic output variables.</p>
<h3 id="basic-capture-examples"><a class="header" href="#basic-capture-examples">Basic Capture Examples</a></h3>
<pre><code class="language-yaml"># Capture to custom variable
- shell: "ls -la | wc -l"
  capture: "file_count"
  capture_format: number  # Default: string

# Use in next command
- shell: "echo 'Found ${file_count} files'"
</code></pre>
<h3 id="capture-formats"><a class="header" href="#capture-formats">Capture Formats</a></h3>
<p>The <code>capture_format</code> field determines how output is parsed and stored:</p>
<pre><code class="language-yaml"># String format (default) - stores raw output
- shell: "echo 'Hello World'"
  capture: "greeting"
  capture_format: string
# Access: ${greeting} → "Hello World"

# Number format - parses numeric output
- shell: "echo 42"
  capture: "answer"
  capture_format: number
# Access: ${answer} → 42 (as number, not string)

# Boolean format - converts to true/false
- shell: "[ -f README.md ] &amp;&amp; echo true || echo false"
  capture: "has_readme"
  capture_format: boolean
# Access: ${has_readme} → true or false

# JSON format - parses JSON output
- shell: "echo '{\"name\": \"project\", \"version\": \"1.0\"}'"
  capture: "package_info"
  capture_format: json
# Access nested fields: ${package_info.name} → "project"
# Access nested fields: ${package_info.version} → "1.0"

# Lines format - splits into array by newlines
- shell: "ls *.md"
  capture: "markdown_files"
  capture_format: lines
# Access: ${markdown_files} → array of filenames
</code></pre>
<h3 id="capture-streams"><a class="header" href="#capture-streams">Capture Streams</a></h3>
<p>Control which output streams to capture (useful for detailed command analysis):</p>
<pre><code class="language-yaml"># Capture specific streams
- shell: "cargo test 2&gt;&amp;1"
  capture: "test_results"
  capture_streams:
    stdout: true      # Default: true
    stderr: true      # Default: false
    exit_code: true   # Default: true
    success: true     # Default: true
    duration: true    # Default: true

# Access captured stream data
- shell: "echo 'Exit code: ${test_results.exit_code}'"
- shell: "echo 'Success: ${test_results.success}'"
- shell: "echo 'Duration: ${test_results.duration}s'"
</code></pre>
<p><strong>Default Behavior</strong>: By default, <code>stdout</code>, <code>exit_code</code>, <code>success</code>, and <code>duration</code> are captured (all <code>true</code>). Set <code>stderr: true</code> to also capture error output.</p>
<h3 id="nested-json-field-access"><a class="header" href="#nested-json-field-access">Nested JSON Field Access</a></h3>
<p>For JSON-formatted captures, use dot notation to access nested fields:</p>
<pre><code class="language-yaml"># Example: API response with nested data
- shell: "curl -s https://api.example.com/user/123"
  capture: "user"
  capture_format: json

# Access nested fields with dot notation
- shell: "echo 'Name: ${user.profile.name}'"
- shell: "echo 'Email: ${user.contact.email}'"
- shell: "echo 'City: ${user.address.city}'"
</code></pre>
<h3 id="variable-scope-and-precedence"><a class="header" href="#variable-scope-and-precedence">Variable Scope and Precedence</a></h3>
<p>Variables follow a parent/child scope hierarchy:</p>
<ol>
<li><strong>Local Scope</strong>: Variables defined in the current command block</li>
<li><strong>Parent Scope</strong>: Variables from enclosing blocks (foreach, map phase, etc.)</li>
<li><strong>Built-in Variables</strong>: Standard workflow context variables</li>
</ol>
<p><strong>Precedence</strong>: Local variables override parent scope variables, which override built-in variables.</p>
<pre><code class="language-yaml"># Parent scope
- shell: "echo 'outer'"
  capture: "message"

# Child scope (foreach creates new scope)
- foreach:
    items: [1, 2, 3]
    commands:
      # This creates a local 'message' that shadows parent
      - shell: "echo 'inner-${item}'"
        capture: "message"
      - shell: "echo ${message}"  # Uses local 'message'

# After foreach, parent 'message' is still accessible
- shell: "echo ${message}"  # Uses parent 'message' → "outer"
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="environment-configuration-1"><a class="header" href="#environment-configuration-1">Environment Configuration</a></h1>
<p>Prodigy provides flexible environment configuration for workflows, allowing you to manage environment variables, secrets, profiles, and step-specific settings. This chapter explains the user-facing configuration options available in workflow YAML files.</p>
<h2 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h2>
<p>Prodigy uses a two-layer architecture for environment management:</p>
<ol>
<li><strong>WorkflowConfig</strong>: User-facing YAML configuration with <code>env</code>, <code>secrets</code>, <code>profiles</code>, and <code>env_files</code> fields</li>
<li><strong>EnvironmentConfig</strong>: Internal runtime configuration that extends workflow config with additional features</li>
</ol>
<p>This chapter documents the user-facing WorkflowConfig layer - what you write in your workflow YAML files.</p>
<hr />
<h2 id="global-environment-variables-1"><a class="header" href="#global-environment-variables-1">Global Environment Variables</a></h2>
<p>Define static environment variables that apply to all commands in your workflow:</p>
<pre><code class="language-yaml"># Global environment variables (static strings only)
env:
  NODE_ENV: production
  PORT: "3000"
  API_URL: https://api.example.com
  DEBUG: "false"

commands:
  - shell: "echo $NODE_ENV"  # Uses global environment
</code></pre>
<p><strong>Important:</strong> The <code>env</code> field at the workflow level only supports static string values. Dynamic or conditional environment variables are handled internally by the runtime but are not directly exposed in workflow YAML.</p>
<p><strong>Environment Inheritance:</strong> Parent process environment variables are always inherited by default. All global environment variables are merged with the parent environment.</p>
<hr />
<h2 id="environment-files-1"><a class="header" href="#environment-files-1">Environment Files</a></h2>
<p>Load environment variables from <code>.env</code> files:</p>
<pre><code class="language-yaml"># Environment files to load
env_files:
  - .env
  - .env.local
  - config/.env.production

commands:
  - shell: "echo $DATABASE_URL"
</code></pre>
<p><strong>Environment File Format:</strong></p>
<p>Environment files use the standard <code>.env</code> format with <code>KEY=value</code> pairs:</p>
<pre><code class="language-bash"># .env file example
DATABASE_URL=postgresql://localhost:5432/mydb
REDIS_HOST=localhost
REDIS_PORT=6379

# Comments are supported
API_KEY=secret-key-here

# Multi-line values use quotes
PRIVATE_KEY="-----BEGIN PRIVATE KEY-----
MIIEvQIBADANBg...
-----END PRIVATE KEY-----"
</code></pre>
<p><strong>Loading Order and Precedence:</strong></p>
<ol>
<li>Files are loaded in the order specified in <code>env_files</code></li>
<li>Later files override earlier files</li>
<li>Step-level <code>env</code> overrides environment files</li>
<li>Global <code>env</code> overrides environment files</li>
</ol>
<hr />
<h2 id="secrets-management"><a class="header" href="#secrets-management">Secrets Management</a></h2>
<p>Store sensitive values securely using secret providers:</p>
<pre><code class="language-yaml">secrets:
  # Provider-based secrets (recommended)
  AWS_SECRET:
    provider: aws
    key: "my-app/api-key"

  VAULT_SECRET:
    provider: vault
    key: "secret/data/myapp"
    version: "v2"  # Optional version

  # Environment variable reference
  API_KEY:
    provider: env
    key: "SECRET_API_KEY"

  # File-based secret
  DB_PASSWORD:
    provider: file
    key: "~/.secrets/db.pass"

  # Custom provider (extensible)
  CUSTOM_SECRET:
    provider:
      custom: "my-custom-provider"
    key: "secret-id"

commands:
  - shell: "echo $API_KEY"  # Secrets are available as environment variables
</code></pre>
<p><strong>Supported Secret Providers:</strong></p>
<ul>
<li><code>env</code> - Reference another environment variable</li>
<li><code>file</code> - Read secret from a file</li>
<li><code>vault</code> - HashiCorp Vault integration (requires Vault setup)</li>
<li><code>aws</code> - AWS Secrets Manager (requires AWS credentials)</li>
<li><code>custom</code> - Custom provider (extensible for your own secret backends)</li>
</ul>
<p><strong>Security Notes:</strong></p>
<ul>
<li>Secrets are masked in logs and output</li>
<li>Secret values are only resolved at runtime</li>
<li>Use secrets for API keys, passwords, tokens, and other sensitive data</li>
</ul>
<hr />
<h2 id="environment-profiles-1"><a class="header" href="#environment-profiles-1">Environment Profiles</a></h2>
<p>Define named environment configurations for different contexts:</p>
<pre><code class="language-yaml"># Define profiles with environment variables
profiles:
  development:
    description: "Development environment with debug enabled"
    NODE_ENV: development
    DEBUG: "true"
    API_URL: http://localhost:3000

  production:
    description: "Production environment configuration"
    NODE_ENV: production
    DEBUG: "false"
    API_URL: https://api.example.com

# Global environment still applies
env:
  APP_NAME: "my-app"

commands:
  - shell: "npm run build"
</code></pre>
<p><strong>Profile Structure:</strong></p>
<p>Profiles use a flat structure where environment variables are defined directly at the profile level (not nested under an <code>env:</code> key). The <code>description</code> field is optional and helps document the profile’s purpose.</p>
<pre><code class="language-yaml">profiles:
  staging:
    description: "Staging environment"  # Optional
    NODE_ENV: staging                   # Direct key-value pairs
    API_URL: https://staging.api.com
    DEBUG: "true"
</code></pre>
<p><strong>Note:</strong> Profile activation is managed internally by the runtime environment manager. The selection mechanism is not currently exposed in WorkflowConfig YAML. Profiles are defined for future use and internal runtime configuration.</p>
<hr />
<h2 id="step-level-environment"><a class="header" href="#step-level-environment">Step-Level Environment</a></h2>
<p>Commands can specify their own environment variables and working directory:</p>
<pre><code class="language-yaml">commands:
  # Basic step-level environment variables
  - shell: "echo $API_URL"
    env:
      API_URL: "https://api.staging.com"
      DEBUG: "true"

  # Step with custom working directory
  - shell: "pwd &amp;&amp; ls -la"
    working_dir: "/tmp/sandbox"
    env:
      TEMP_VAR: "value"

  # Step overrides global environment
  - shell: "echo $NODE_ENV"
    env:
      NODE_ENV: "test"  # Overrides global NODE_ENV
</code></pre>
<p><strong>Available Step-Level Fields:</strong></p>
<ul>
<li>
<p><code>env</code> - Step-specific environment variables (HashMap&lt;String, String&gt;)</p>
<ul>
<li>Merged with global environment</li>
<li>Step env overrides global env for conflicting keys</li>
<li>Supports variable interpolation with <code>${variable}</code> syntax</li>
</ul>
</li>
<li>
<p><code>working_dir</code> - Working directory for command execution</p>
<ul>
<li>Can be an absolute or relative path</li>
<li>Relative paths are resolved from the workflow root</li>
<li>Default: workflow root directory</li>
</ul>
</li>
</ul>
<p><strong>Variable Interpolation:</strong></p>
<p>Step environment variables support interpolation from the workflow variable context:</p>
<pre><code class="language-yaml">commands:
  - shell: "echo 'Version: $APP_VERSION'"
    env:
      APP_VERSION: "${VERSION}"  # Interpolate from workflow variables
      BUILD_TAG: "build-${BUILD_NUMBER}"
</code></pre>
<hr />
<h2 id="environment-precedence"><a class="header" href="#environment-precedence">Environment Precedence</a></h2>
<p>Environment variables are resolved in the following order (highest to lowest precedence):</p>
<ol>
<li><strong>Step-level <code>env</code></strong> - Defined on individual commands</li>
<li><strong>Active profile</strong> - If a profile is activated (internal)</li>
<li><strong>Global <code>env</code></strong> - Defined at workflow level</li>
<li><strong>Environment files</strong> - Loaded from <code>env_files</code> (in order)</li>
<li><strong>Parent environment</strong> - Inherited from the parent process</li>
</ol>
<p>Example demonstrating precedence:</p>
<pre><code class="language-yaml"># Parent environment: NODE_ENV=local

env_files:
  - .env  # Contains: NODE_ENV=development

env:
  NODE_ENV: production  # Overrides .env file

profiles:
  test:
    NODE_ENV: test  # Overrides global env when profile is active

commands:
  - shell: "echo $NODE_ENV"  # Prints: production (global env)

  - shell: "echo $NODE_ENV"  # Prints: staging (step env overrides global)
    env:
      NODE_ENV: staging
</code></pre>
<hr />
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="1-use-environment-files-for-configuration"><a class="header" href="#1-use-environment-files-for-configuration">1. Use Environment Files for Configuration</a></h3>
<p>Store configuration in <code>.env</code> files instead of hardcoding in YAML:</p>
<pre><code class="language-yaml"># Good: Load from files
env_files:
  - .env
  - .env.${ENVIRONMENT}

# Avoid: Hardcoding sensitive values
env:
  API_KEY: "hardcoded-key-here"  # Don't do this!
</code></pre>
<h3 id="2-use-secrets-for-sensitive-data"><a class="header" href="#2-use-secrets-for-sensitive-data">2. Use Secrets for Sensitive Data</a></h3>
<p>Always use the <code>secrets</code> field for sensitive information:</p>
<pre><code class="language-yaml"># Good: Use secrets provider
secrets:
  DATABASE_PASSWORD:
    provider: vault
    key: "db/password"

# Bad: Sensitive data in plain env
env:
  DATABASE_PASSWORD: "my-password"  # Don't do this!
</code></pre>
<h3 id="3-leverage-profiles-for-environments"><a class="header" href="#3-leverage-profiles-for-environments">3. Leverage Profiles for Environments</a></h3>
<p>Define profiles for different deployment environments:</p>
<pre><code class="language-yaml">profiles:
  development:
    NODE_ENV: development
    LOG_LEVEL: debug
    API_URL: http://localhost:3000

  production:
    NODE_ENV: production
    LOG_LEVEL: error
    API_URL: https://api.example.com
</code></pre>
<h3 id="4-use-step-environment-for-overrides"><a class="header" href="#4-use-step-environment-for-overrides">4. Use Step Environment for Overrides</a></h3>
<p>Override global settings for specific commands:</p>
<pre><code class="language-yaml">env:
  RUST_LOG: info

commands:
  # Most commands use info level
  - shell: "cargo run"

  # But this command needs debug level
  - shell: "cargo run --verbose"
    env:
      RUST_LOG: debug
</code></pre>
<h3 id="5-document-your-environment-variables"><a class="header" href="#5-document-your-environment-variables">5. Document Your Environment Variables</a></h3>
<p>Add comments to explain environment variables:</p>
<pre><code class="language-yaml">env:
  # Number of worker threads (adjust based on CPU cores)
  WORKER_COUNT: "4"

  # API rate limit (requests per minute)
  RATE_LIMIT: "1000"

  # Feature flags
  ENABLE_BETA_FEATURES: "false"
</code></pre>
<hr />
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="multi-environment-workflows"><a class="header" href="#multi-environment-workflows">Multi-Environment Workflows</a></h3>
<pre><code class="language-yaml"># Load environment-specific configuration
env_files:
  - .env.${ENVIRONMENT}

env:
  APP_NAME: "my-app"

commands:
  - shell: "npm run deploy"
</code></pre>
<h3 id="secrets-with-fallbacks"><a class="header" href="#secrets-with-fallbacks">Secrets with Fallbacks</a></h3>
<pre><code class="language-yaml">secrets:
  # Try Vault first, fall back to environment variable
  API_KEY:
    provider: vault
    key: "api/key"

env:
  # Fallback for local development
  API_KEY: "${API_KEY:-default-key}"
</code></pre>
<h3 id="build-matrix-with-profiles"><a class="header" href="#build-matrix-with-profiles">Build Matrix with Profiles</a></h3>
<pre><code class="language-yaml">profiles:
  debug:
    CARGO_PROFILE: debug
    RUST_BACKTRACE: "1"

  release:
    CARGO_PROFILE: release
    RUST_BACKTRACE: "0"

commands:
  - shell: "cargo build --profile ${CARGO_PROFILE}"
</code></pre>
<h3 id="temporary-environment-changes"><a class="header" href="#temporary-environment-changes">Temporary Environment Changes</a></h3>
<pre><code class="language-yaml">commands:
  # Set PATH for this command only
  - shell: "./node_modules/.bin/webpack"
    working_dir: "frontend"
    env:
      PATH: "${PWD}/node_modules/.bin:${PATH}"

  # PATH is back to normal for subsequent commands
  - shell: "echo $PATH"
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h1>
<p>This chapter covers advanced workflow features for building sophisticated automation pipelines. These features enable conditional execution, parallel processing, validation, and complex control flow.</p>
<hr />
<h2 id="conditional-execution"><a class="header" href="#conditional-execution">Conditional Execution</a></h2>
<p>Control when commands execute based on expressions or previous command results.</p>
<h3 id="expression-based-conditions"><a class="header" href="#expression-based-conditions">Expression-Based Conditions</a></h3>
<p>Use the <code>when</code> field to conditionally execute commands based on variable values:</p>
<pre><code class="language-yaml"># Execute only when variable is true
- shell: "cargo build --release"
  when: "${tests_passed}"

# Execute based on complex expression
- shell: "deploy.sh"
  when: "${environment == 'production' &amp;&amp; tests_passed}"
</code></pre>
<h3 id="on-success-handlers"><a class="header" href="#on-success-handlers">On Success Handlers</a></h3>
<p>Execute follow-up commands when a command succeeds:</p>
<pre><code class="language-yaml">- shell: "cargo test"
  on_success:
    shell: "cargo bench"
</code></pre>
<h3 id="on-failure-handlers"><a class="header" href="#on-failure-handlers">On Failure Handlers</a></h3>
<p>Handle failures with automatic remediation:</p>
<pre><code class="language-yaml">- shell: "cargo clippy"
  on_failure:
    claude: "/fix-warnings"
    max_attempts: 3
    fail_workflow: false
</code></pre>
<p>The <code>on_failure</code> configuration supports:</p>
<ul>
<li><code>max_attempts</code>: Maximum retry attempts (default: 1)</li>
<li><code>fail_workflow</code>: Whether to fail entire workflow on final failure (default: true)</li>
</ul>
<h3 id="nested-conditionals"><a class="header" href="#nested-conditionals">Nested Conditionals</a></h3>
<p>Chain multiple levels of conditional execution:</p>
<pre><code class="language-yaml">- shell: "cargo check"
  on_success:
    shell: "cargo build --release"
    on_success:
      shell: "cargo test --release"
      on_failure:
        claude: "/debug-failures '${shell.output}'"
</code></pre>
<hr />
<h2 id="output-capture-and-variable-management"><a class="header" href="#output-capture-and-variable-management">Output Capture and Variable Management</a></h2>
<p>Capture command output in different formats for use in subsequent steps.</p>
<h3 id="capture-variable"><a class="header" href="#capture-variable">Capture Variable</a></h3>
<p>Capture output to a named variable using the <code>capture_output</code> field:</p>
<pre><code class="language-yaml"># Capture as string (backward compatible)
- shell: "git rev-parse HEAD"
  capture_output: "commit_hash"

# Reference in later steps
- shell: "echo 'Commit: ${commit_hash}'"
</code></pre>
<h3 id="capture-formats-1"><a class="header" href="#capture-formats-1">Capture Formats</a></h3>
<p>Control how output is parsed with <code>capture_format</code>:</p>
<pre><code class="language-yaml"># String (default) - trimmed output as single string
- shell: "git rev-parse HEAD"
  capture_output: "commit_hash"
  capture_format: "string"

# Number - parse output as number
- shell: "wc -l &lt; file.txt"
  capture_output: "line_count"
  capture_format: "number"

# JSON - parse output as JSON object
- shell: "cargo metadata --format-version 1"
  capture_output: "metadata"
  capture_format: "json"

# Lines - split output into array of lines
- shell: "find . -name '*.rs'"
  capture_output: "rust_files"
  capture_format: "lines"

# Boolean - parse "true"/"false" as boolean
- shell: "test -f README.md &amp;&amp; echo true || echo false"
  capture_output: "has_readme"
  capture_format: "boolean"
</code></pre>
<h3 id="stream-capture-control"><a class="header" href="#stream-capture-control">Stream Capture Control</a></h3>
<p>Control which streams to capture using <code>capture_streams</code>:</p>
<pre><code class="language-yaml"># Capture only stdout (default)
- shell: "cargo build"
  capture_output: "build_log"
  capture_streams: "stdout"

# Capture only stderr
- shell: "cargo test"
  capture_output: "errors"
  capture_streams: "stderr"

# Capture both streams
- shell: "npm install"
  capture_output: "full_output"
  capture_streams: "both"
</code></pre>
<h3 id="output-file-redirection"><a class="header" href="#output-file-redirection">Output File Redirection</a></h3>
<p>Write command output directly to a file:</p>
<pre><code class="language-yaml"># Redirect output to file
- shell: "cargo test --verbose"
  output_file: "test-results.txt"

# File is written to working directory
# Can be combined with capture_output to save and use output
</code></pre>
<hr />
<h2 id="step-identification"><a class="header" href="#step-identification">Step Identification</a></h2>
<p>Assign unique IDs to steps for referencing their outputs:</p>
<pre><code class="language-yaml">- shell: "cargo test"
  id: "test-step"
  capture_output: "test_results"

# Reference step output by ID
- shell: "echo 'Tests: ${test-step.output}'"
</code></pre>
<hr />
<h2 id="timeout-configuration"><a class="header" href="#timeout-configuration">Timeout Configuration</a></h2>
<p>Set execution timeouts at the command level:</p>
<pre><code class="language-yaml"># Command-level timeout (in seconds)
- shell: "cargo bench"
  timeout: 600  # 10 minutes

# Timeout for long-running operations
- claude: "/analyze-codebase"
  timeout: 1800  # 30 minutes
</code></pre>
<p><strong>Note</strong>: Timeouts are only supported at the individual command level, not for MapReduce agents.</p>
<hr />
<h2 id="implementation-validation"><a class="header" href="#implementation-validation">Implementation Validation</a></h2>
<p>Validate that implementations meet requirements using the <code>validate</code> field.</p>
<h3 id="basic-validation"><a class="header" href="#basic-validation">Basic Validation</a></h3>
<p>Run validation commands after a step completes:</p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    shell: "cargo test"
    threshold: 100  # Require 100% completion
</code></pre>
<h3 id="validation-with-claude"><a class="header" href="#validation-with-claude">Validation with Claude</a></h3>
<p>Use Claude to validate implementation quality:</p>
<pre><code class="language-yaml">- shell: "generate-code.sh"
  validate:
    claude: "/verify-implementation"
    threshold: 95
</code></pre>
<h3 id="multi-step-validation"><a class="header" href="#multi-step-validation">Multi-Step Validation</a></h3>
<p>Run multiple validation commands in sequence:</p>
<pre><code class="language-yaml">- claude: "/refactor"
  validate:
    commands:
      - shell: "cargo test"
      - shell: "cargo clippy"
      - shell: "cargo fmt --check"
    threshold: 100
</code></pre>
<h3 id="validation-with-result-files"><a class="header" href="#validation-with-result-files">Validation with Result Files</a></h3>
<p>Read validation results from a file instead of stdout:</p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    shell: "run-validator.sh"
    result_file: "validation-results.json"
    threshold: 95
</code></pre>
<h3 id="handling-incomplete-implementations"><a class="header" href="#handling-incomplete-implementations">Handling Incomplete Implementations</a></h3>
<p>Automatically remediate when validation fails:</p>
<pre><code class="language-yaml">- claude: "/implement-spec"
  validate:
    shell: "check-completeness.sh"
    threshold: 100
    on_incomplete:
      claude: "/fill-gaps"
      max_attempts: 3
      fail_workflow: true
</code></pre>
<p>The <code>on_incomplete</code> configuration supports:</p>
<ul>
<li><code>claude</code>: Claude command to execute for gap-filling</li>
<li><code>shell</code>: Shell command to execute for gap-filling</li>
<li><code>commands</code>: Array of commands to execute</li>
<li><code>max_attempts</code>: Maximum remediation attempts (default: 1)</li>
<li><code>fail_workflow</code>: Whether to fail workflow if remediation fails (default: true)</li>
<li><code>commit_required</code>: Whether remediation command should create a commit (default: false)</li>
</ul>
<hr />
<h2 id="parallel-iteration-with-foreach"><a class="header" href="#parallel-iteration-with-foreach">Parallel Iteration with Foreach</a></h2>
<p>Process multiple items in parallel using the <code>foreach</code> command.</p>
<h3 id="basic-foreach"><a class="header" href="#basic-foreach">Basic Foreach</a></h3>
<p>Iterate over a list of items:</p>
<pre><code class="language-yaml">- foreach:
    foreach: ["a", "b", "c"]
    do:
      - shell: "process ${item}"
</code></pre>
<h3 id="dynamic-item-lists"><a class="header" href="#dynamic-item-lists">Dynamic Item Lists</a></h3>
<p>Generate items from a command:</p>
<pre><code class="language-yaml">- foreach:
    foreach: "find . -name '*.rs'"
    do:
      - shell: "rustfmt ${item}"
</code></pre>
<h3 id="parallel-execution"><a class="header" href="#parallel-execution">Parallel Execution</a></h3>
<p>Control parallelism with the <code>parallel</code> field:</p>
<pre><code class="language-yaml">- foreach:
    foreach: "ls *.txt"
    parallel: 5  # Process 5 items concurrently
    do:
      - shell: "analyze ${item}"
</code></pre>
<h3 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h3>
<p>Continue processing remaining items on failure:</p>
<pre><code class="language-yaml">- foreach:
    foreach: ["test1", "test2", "test3"]
    continue_on_error: true
    do:
      - shell: "run-test ${item}"
</code></pre>
<h3 id="limiting-items"><a class="header" href="#limiting-items">Limiting Items</a></h3>
<p>Process only a subset of items:</p>
<pre><code class="language-yaml">- foreach:
    foreach: "find . -name '*.log'"
    max_items: 10  # Process first 10 items only
    do:
      - shell: "compress ${item}"
</code></pre>
<hr />
<h2 id="goal-seeking-operations"><a class="header" href="#goal-seeking-operations">Goal-Seeking Operations</a></h2>
<p>Iteratively refine implementations until they meet validation criteria.</p>
<h3 id="basic-goal-seek"><a class="header" href="#basic-goal-seek">Basic Goal Seek</a></h3>
<p>Define a goal and validation command:</p>
<pre><code class="language-yaml">- goal_seek:
    goal: "All tests pass"
    command: "cargo fix"
    validate: "cargo test"
    threshold: 100
</code></pre>
<p>The goal-seeking operation will:</p>
<ol>
<li>Run the command</li>
<li>Run the validation</li>
<li>Retry if validation threshold not met</li>
<li>Stop when goal achieved or max attempts reached</li>
</ol>
<h3 id="advanced-goal-seek-configuration"><a class="header" href="#advanced-goal-seek-configuration">Advanced Goal Seek Configuration</a></h3>
<p>Control iteration behavior:</p>
<pre><code class="language-yaml">- goal_seek:
    goal: "Code passes all quality checks"
    command: "auto-fix.sh"
    validate: "quality-check.sh"
    threshold: 95
    max_attempts: 5
    timeout: 300
    fail_on_incomplete: true
</code></pre>
<hr />
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="1-use-meaningful-variable-names"><a class="header" href="#1-use-meaningful-variable-names">1. Use Meaningful Variable Names</a></h3>
<pre><code class="language-yaml"># Good
- shell: "cargo test --format json"
  capture_output: "test_results"
  capture_format: "json"

# Avoid
- shell: "cargo test --format json"
  capture_output: "x"
</code></pre>
<h3 id="2-set-appropriate-timeouts"><a class="header" href="#2-set-appropriate-timeouts">2. Set Appropriate Timeouts</a></h3>
<pre><code class="language-yaml"># Set timeouts for potentially long-running operations
- shell: "npm install"
  timeout: 300

- claude: "/analyze-large-codebase"
  timeout: 1800
</code></pre>
<h3 id="3-handle-failures-gracefully"><a class="header" href="#3-handle-failures-gracefully">3. Handle Failures Gracefully</a></h3>
<pre><code class="language-yaml"># Provide automatic remediation
- shell: "cargo test"
  on_failure:
    claude: "/fix-failing-tests"
    max_attempts: 2
    fail_workflow: true
</code></pre>
<h3 id="4-validate-critical-changes"><a class="header" href="#4-validate-critical-changes">4. Validate Critical Changes</a></h3>
<pre><code class="language-yaml"># Ensure implementation meets requirements
- claude: "/implement-feature"
  validate:
    commands:
      - shell: "cargo test"
      - shell: "cargo clippy -- -D warnings"
    threshold: 100
    on_incomplete:
      claude: "/fix-issues"
      max_attempts: 3
</code></pre>
<h3 id="5-use-step-ids-for-complex-workflows"><a class="header" href="#5-use-step-ids-for-complex-workflows">5. Use Step IDs for Complex Workflows</a></h3>
<pre><code class="language-yaml"># Make output references explicit
- shell: "git diff --stat"
  id: "git-changes"
  capture_output: "diff"

- claude: "/review-changes '${git-changes.output}'"
  id: "code-review"
</code></pre>
<hr />
<h2 id="common-patterns-1"><a class="header" href="#common-patterns-1">Common Patterns</a></h2>
<h3 id="test-fix-verify-loop"><a class="header" href="#test-fix-verify-loop">Test-Fix-Verify Loop</a></h3>
<pre><code class="language-yaml">- shell: "cargo test"
  on_failure:
    claude: "/fix-tests"
    on_success:
      shell: "cargo test --release"
</code></pre>
<h3 id="parallel-processing-with-aggregation"><a class="header" href="#parallel-processing-with-aggregation">Parallel Processing with Aggregation</a></h3>
<pre><code class="language-yaml">- foreach:
    foreach: "find src -name '*.rs'"
    parallel: 10
    do:
      - shell: "analyze-file ${item}"
        capture_output: "analysis_${item}"

- shell: "aggregate-results.sh"
</code></pre>
<h3 id="gradual-quality-improvement"><a class="header" href="#gradual-quality-improvement">Gradual Quality Improvement</a></h3>
<pre><code class="language-yaml">- goal_seek:
    goal: "Code quality score above 90"
    command: "auto-improve.sh"
    validate: "quality-check.sh"
    threshold: 90
    max_attempts: 5
  on_success:
    shell: "git commit -m 'Improved code quality'"
</code></pre>
<h3 id="conditional-deployment"><a class="header" href="#conditional-deployment">Conditional Deployment</a></h3>
<pre><code class="language-yaml">- shell: "cargo test"
  capture_output: "test_results"
  capture_format: "json"

- shell: "deploy.sh"
  when: "${test_results.passed == test_results.total}"
  on_success:
    shell: "notify-success.sh"
  on_failure:
    shell: "rollback.sh"
</code></pre>
<h3 id="multi-stage-validation"><a class="header" href="#multi-stage-validation">Multi-Stage Validation</a></h3>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    commands:
      - shell: "cargo build"
      - shell: "cargo test"
      - shell: "cargo clippy"
      - shell: "cargo fmt --check"
    threshold: 100
    on_incomplete:
      commands:
        - claude: "/fix-build-errors"
        - shell: "cargo fmt"
      max_attempts: 3
      fail_workflow: true
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h1>
<p>Prodigy provides comprehensive error handling at both the workflow level (for MapReduce jobs) and the command level (for individual workflow steps). This chapter covers the practical features available for handling failures gracefully.</p>
<hr />
<h2 id="command-level-error-handling"><a class="header" href="#command-level-error-handling">Command-Level Error Handling</a></h2>
<p>Command-level error handling allows you to specify what happens when a single workflow step fails. Use the <code>on_failure</code> configuration to define recovery, cleanup, or fallback strategies.</p>
<h3 id="simple-forms"><a class="header" href="#simple-forms">Simple Forms</a></h3>
<p>For basic error handling, use the simplest form that meets your needs:</p>
<pre><code class="language-yaml"># Ignore errors - don't fail the workflow
- shell: "optional-cleanup.sh"
  on_failure: true

# Single recovery command (shell or claude)
- shell: "npm install"
  on_failure: "npm cache clean --force"

- shell: "cargo clippy"
  on_failure: "/fix-warnings"

# Multiple recovery commands
- shell: "build-project"
  on_failure:
    - "cleanup-artifacts"
    - "/diagnose-build-errors"
    - "retry-build"
</code></pre>
<h3 id="advanced-configuration"><a class="header" href="#advanced-configuration">Advanced Configuration</a></h3>
<p>For more control over error handling behavior:</p>
<pre><code class="language-yaml">- shell: "cargo clippy"
  on_failure:
    claude: "/fix-warnings ${shell.output}"
    fail_workflow: false     # Continue workflow even if handler fails
    max_attempts: 3          # Retry original command up to 3 times (alias: max_retries)
</code></pre>
<p><strong>Available Fields:</strong></p>
<ul>
<li><code>shell</code> - Shell command to run on failure</li>
<li><code>claude</code> - Claude command to run on failure</li>
<li><code>fail_workflow</code> - Whether to fail the entire workflow (default: <code>false</code>)</li>
<li><code>max_attempts</code> - Maximum retry attempts for the original command (default: <code>1</code>, alias: <code>max_retries</code>)</li>
</ul>
<p><strong>Notes:</strong></p>
<ul>
<li>If <code>max_attempts &gt; 1</code>, Prodigy will retry the original command after running the failure handler</li>
<li>You can specify both <code>shell</code> and <code>claude</code> commands - they will execute in sequence</li>
<li>By default, having a handler means the workflow continues even if the step fails</li>
</ul>
<h3 id="detailed-handler-configuration"><a class="header" href="#detailed-handler-configuration">Detailed Handler Configuration</a></h3>
<p>For complex error handling scenarios with multiple commands and fine-grained control:</p>
<pre><code class="language-yaml">- shell: "deploy-production"
  on_failure:
    strategy: recovery        # Options: recovery, fallback, cleanup, custom
    timeout: 300             # Handler timeout in seconds
    handler_failure_fatal: true  # Fail workflow if handler fails
    fail_workflow: false     # Don't fail workflow if step fails
    commands:
      - shell: "rollback-deployment"
        continue_on_error: true
      - claude: "/analyze-deployment-failure"
      - shell: "notify-team"
</code></pre>
<p><strong>Handler Strategies:</strong></p>
<ul>
<li><code>recovery</code> - Try to fix the problem and retry (default)</li>
<li><code>fallback</code> - Use an alternative approach</li>
<li><code>cleanup</code> - Clean up resources</li>
<li><code>custom</code> - Custom handler logic</li>
</ul>
<p><strong>Handler Command Fields:</strong></p>
<ul>
<li><code>shell</code> or <code>claude</code> - The command to execute</li>
<li><code>continue_on_error</code> - Continue to next handler command even if this fails</li>
</ul>
<h3 id="success-handling"><a class="header" href="#success-handling">Success Handling</a></h3>
<p>Execute commands when a step succeeds:</p>
<pre><code class="language-yaml">- shell: "deploy-staging"
  on_success:
    shell: "notify-success"
    claude: "/update-deployment-docs"
</code></pre>
<h3 id="commit-requirements"><a class="header" href="#commit-requirements">Commit Requirements</a></h3>
<p>Specify whether a workflow step must create a git commit:</p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  commit_required: true   # Fail if no commit is made
</code></pre>
<p>This is useful for ensuring that Claude commands that are expected to make code changes actually do so.</p>
<hr />
<h2 id="workflow-level-error-policy-mapreduce"><a class="header" href="#workflow-level-error-policy-mapreduce">Workflow-Level Error Policy (MapReduce)</a></h2>
<p>For MapReduce workflows, you can configure workflow-level error policies that control how the entire job responds to failures. This is separate from command-level error handling and only applies to MapReduce mode.</p>
<h3 id="basic-configuration"><a class="header" href="#basic-configuration">Basic Configuration</a></h3>
<pre><code class="language-yaml">name: process-items
mode: mapreduce

error_policy:
  # What to do when a work item fails
  on_item_failure: dlq      # Options: dlq, retry, skip, stop, custom:&lt;handler_name&gt;

  # Continue processing after failures
  continue_on_failure: true

  # Stop after this many failures
  max_failures: 10

  # Stop if failure rate exceeds threshold (0.0 to 1.0)
  failure_threshold: 0.2    # Stop if 20% of items fail

  # How to report errors
  error_collection: aggregate  # Options: aggregate, immediate, batched
</code></pre>
<p><strong>Item Failure Actions:</strong></p>
<ul>
<li><code>dlq</code> - Send failed items to Dead Letter Queue for later retry (default)</li>
<li><code>retry</code> - Retry the item immediately with backoff (if retry_config is set)</li>
<li><code>skip</code> - Skip the failed item and continue</li>
<li><code>stop</code> - Stop the entire workflow on first failure</li>
<li><code>custom:&lt;name&gt;</code> - Use a custom failure handler (not yet implemented)</li>
</ul>
<p><strong>Error Collection Strategies:</strong></p>
<ul>
<li><code>aggregate</code> - Collect all errors and report at the end (default)</li>
<li><code>immediate</code> - Report errors as they occur</li>
<li><code>batched: {size: N}</code> - Report errors in batches of N items</li>
</ul>
<h3 id="circuit-breaker"><a class="header" href="#circuit-breaker">Circuit Breaker</a></h3>
<p>Prevent cascading failures by opening a circuit after consecutive failures:</p>
<pre><code class="language-yaml">error_policy:
  circuit_breaker:
    failure_threshold: 5      # Open circuit after 5 consecutive failures
    success_threshold: 2      # Close circuit after 2 successes
    timeout: 30s             # Time before attempting half-open state
    half_open_requests: 3    # Test requests in half-open state
</code></pre>
<p><strong>Note:</strong> Use duration format for timeout (e.g., <code>30s</code>, <code>1m</code>, <code>500ms</code>)</p>
<h3 id="retry-configuration-with-backoff"><a class="header" href="#retry-configuration-with-backoff">Retry Configuration with Backoff</a></h3>
<p>Configure automatic retry behavior for failed items:</p>
<pre><code class="language-yaml">error_policy:
  on_item_failure: retry
  retry_config:
    max_attempts: 3
    backoff:
      type: exponential
      initial: 1s            # Initial delay (duration format)
      multiplier: 2          # Double delay each retry
</code></pre>
<p><strong>Backoff Strategy Options:</strong></p>
<pre><code class="language-yaml"># Fixed delay between retries
backoff:
  type: fixed
  delay: 1s

# Linear increase in delay
backoff:
  type: linear
  initial: 1s
  increment: 500ms

# Exponential backoff (recommended)
backoff:
  type: exponential
  initial: 1s
  multiplier: 2

# Fibonacci sequence delays
backoff:
  type: fibonacci
  initial: 1s
</code></pre>
<p><strong>Important:</strong> All duration values use humantime format (e.g., <code>1s</code>, <code>100ms</code>, <code>2m</code>, <code>30s</code>), not milliseconds.</p>
<h3 id="error-metrics"><a class="header" href="#error-metrics">Error Metrics</a></h3>
<p>Prodigy automatically tracks error metrics for MapReduce jobs:</p>
<ul>
<li><strong>Counts:</strong> total_items, successful, failed, skipped</li>
<li><strong>Rates:</strong> failure_rate (0.0 to 1.0)</li>
<li><strong>Patterns:</strong> Detects recurring error types with suggested remediation</li>
<li><strong>Error types:</strong> Frequency of each error category</li>
</ul>
<p>Access metrics during execution or after completion to understand job health.</p>
<hr />
<h2 id="dead-letter-queue-dlq-1"><a class="header" href="#dead-letter-queue-dlq-1">Dead Letter Queue (DLQ)</a></h2>
<p>The Dead Letter Queue stores failed work items from MapReduce jobs for later retry or analysis. This is only available for MapReduce workflows, not regular workflows.</p>
<h3 id="sending-items-to-dlq"><a class="header" href="#sending-items-to-dlq">Sending Items to DLQ</a></h3>
<p>Configure your MapReduce workflow to use DLQ:</p>
<pre><code class="language-yaml">mode: mapreduce
error_policy:
  on_item_failure: dlq
</code></pre>
<p>Failed items are automatically sent to the DLQ with:</p>
<ul>
<li>Original work item data</li>
<li>Failure reason and error message</li>
<li>Timestamp of failure</li>
<li>Attempt history</li>
</ul>
<h3 id="retrying-failed-items"><a class="header" href="#retrying-failed-items">Retrying Failed Items</a></h3>
<p>Use the CLI to retry failed items:</p>
<pre><code class="language-bash"># Retry all failed items for a job
prodigy dlq retry &lt;job_id&gt;

# Retry with custom parallelism (default: 5)
prodigy dlq retry &lt;job_id&gt; --max-parallel 10

# Dry run to see what would be retried
prodigy dlq retry &lt;job_id&gt; --dry-run
</code></pre>
<p><strong>DLQ Retry Features:</strong></p>
<ul>
<li>Streams items to avoid memory issues with large queues</li>
<li>Respects original workflow’s max_parallel setting (unless overridden)</li>
<li>Preserves correlation IDs for tracking</li>
<li>Updates DLQ state (removes successful, keeps failed)</li>
<li>Supports interruption and resumption</li>
<li>Shared across worktrees for centralized failure tracking</li>
</ul>
<h3 id="dlq-storage-1"><a class="header" href="#dlq-storage-1">DLQ Storage</a></h3>
<p>DLQ data is stored in:</p>
<pre><code>~/.prodigy/dlq/{repo_name}/{job_id}/
</code></pre>
<p>This centralized storage allows multiple worktrees to share the same DLQ.</p>
<hr />
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="when-to-use-command-level-error-handling"><a class="header" href="#when-to-use-command-level-error-handling">When to Use Command-Level Error Handling</a></h3>
<ul>
<li><strong>Recovery:</strong> Use <code>on_failure</code> to fix issues and retry (e.g., clearing cache before reinstalling)</li>
<li><strong>Cleanup:</strong> Use <code>strategy: cleanup</code> to clean up resources after failures</li>
<li><strong>Fallback:</strong> Use <code>strategy: fallback</code> for alternative approaches</li>
<li><strong>Notifications:</strong> Use handler commands to notify teams of failures</li>
</ul>
<h3 id="when-to-use-workflow-level-error-policy"><a class="header" href="#when-to-use-workflow-level-error-policy">When to Use Workflow-Level Error Policy</a></h3>
<ul>
<li><strong>MapReduce jobs:</strong> Use error_policy for consistent failure handling across all work items</li>
<li><strong>Failure thresholds:</strong> Use max_failures or failure_threshold to prevent runaway jobs</li>
<li><strong>Circuit breakers:</strong> Use when external dependencies might fail cascading</li>
<li><strong>DLQ:</strong> Use for large batch jobs where you want to retry failures separately</li>
</ul>
<h3 id="error-information-available"><a class="header" href="#error-information-available">Error Information Available</a></h3>
<p>When a command fails, you can access error information in handler commands:</p>
<pre><code class="language-yaml">- shell: "risky-command"
  on_failure:
    claude: "/analyze-error ${shell.output}"
</code></pre>
<p>The <code>${shell.output}</code> variable contains the command’s stdout/stderr output.</p>
<h3 id="common-patterns-2"><a class="header" href="#common-patterns-2">Common Patterns</a></h3>
<p><strong>Cleanup and Retry:</strong></p>
<pre><code class="language-yaml">- shell: "npm install"
  on_failure:
    - "npm cache clean --force"
    - "rm -rf node_modules"
    - "npm install"
</code></pre>
<p><strong>Conditional Recovery:</strong></p>
<pre><code class="language-yaml">- shell: "cargo test"
  on_failure:
    claude: "/fix-failing-tests"
  max_attempts: 3
  fail_workflow: false
</code></pre>
<p><strong>Critical Step with Notification:</strong></p>
<pre><code class="language-yaml">- shell: "deploy-production"
  on_failure:
    commands:
      - shell: "rollback-deployment"
      - shell: "notify-team 'Deployment failed'"
    fail_workflow: true   # Still fail workflow after cleanup
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="examples"><a class="header" href="#examples">Examples</a></h1>
<h2 id="example-1-simple-build-and-test"><a class="header" href="#example-1-simple-build-and-test">Example 1: Simple Build and Test</a></h2>
<pre><code class="language-yaml">- shell: "cargo build"
- shell: "cargo test"
  on_failure:
    claude: "/fix-failing-tests"
- shell: "cargo clippy"
</code></pre>
<hr />
<h2 id="example-2-coverage-improvement-with-goal-seeking"><a class="header" href="#example-2-coverage-improvement-with-goal-seeking">Example 2: Coverage Improvement with Goal Seeking</a></h2>
<pre><code class="language-yaml">- goal_seek:
    goal: "Achieve 80% test coverage"
    claude: "/improve-coverage"
    validate: |
      coverage=$(cargo tarpaulin | grep 'Coverage' | sed 's/.*: \([0-9.]*\)%.*/\1/')
      echo "score: ${coverage%.*}"
    threshold: 80
    max_attempts: 5
  commit_required: true
</code></pre>
<hr />
<h2 id="example-3-parallel-code-review"><a class="header" href="#example-3-parallel-code-review">Example 3: Parallel Code Review</a></h2>
<pre><code class="language-yaml">name: parallel-code-review
mode: mapreduce

setup:
  - shell: "find src -name '*.rs' &gt; files.txt"
  - shell: "jq -R -s -c 'split(\"\n\") | map(select(length &gt; 0) | {path: .})' files.txt &gt; items.json"

map:
  input: items.json
  json_path: "$[*]"  # Process all items
  agent_template:
    - claude: "/review-file ${item.path}"
    - shell: "cargo check ${item.path}"
  max_parallel: 5

reduce:
  - claude: "/summarize-reviews ${map.results}"
</code></pre>
<hr />
<h2 id="example-4-conditional-deployment"><a class="header" href="#example-4-conditional-deployment">Example 4: Conditional Deployment</a></h2>
<pre><code class="language-yaml">- shell: "cargo test --quiet &amp;&amp; echo true || echo false"
  outputs:
    tests_passed:
      from_output: true
      format: boolean

- shell: "cargo build --release"
  when: "${tests_passed}"

- shell: "docker build -t myapp ."
  when: "${tests_passed}"
  on_success:
    shell: "docker push myapp:latest"
</code></pre>
<hr />
<h2 id="example-5-multi-step-validation"><a class="header" href="#example-5-multi-step-validation">Example 5: Multi-Step Validation</a></h2>
<pre><code class="language-yaml">- claude: "/implement-feature auth"
  commit_required: true
  validate:
    commands:
      - shell: "cargo test auth"
      - shell: "cargo clippy -- -D warnings"
      - claude: "/validate-implementation --output validation.json"
    result_file: "validation.json"
    threshold: 90
    on_incomplete:
      claude: "/complete-gaps ${validation.gaps}"
      commit_required: true
      max_attempts: 2
</code></pre>
<hr />
<h2 id="example-6-environment-aware-workflow"><a class="header" href="#example-6-environment-aware-workflow">Example 6: Environment-Aware Workflow</a></h2>
<pre><code class="language-yaml"># Environment configuration with conditional logic
environment:
  global_env:
    DEPLOY_ENV:
      condition: "${branch} == 'main'"
      when_true: "production"
      when_false: "staging"

  profiles:
    production:
      env:
        API_URL: https://api.production.com
    staging:
      env:
        API_URL: https://api.staging.com

  # Activate profile based on DEPLOY_ENV
  active_profile: "${DEPLOY_ENV}"

# Workflow commands
commands:
  - shell: "cargo build --release"
  - shell: "echo 'Deploying to ${DEPLOY_ENV} at ${API_URL}'"
  - shell: "deploy.sh ${DEPLOY_ENV}"
</code></pre>
<hr />
<h2 id="example-7-complex-mapreduce-with-error-handling"><a class="header" href="#example-7-complex-mapreduce-with-error-handling">Example 7: Complex MapReduce with Error Handling</a></h2>
<pre><code class="language-yaml">name: tech-debt-elimination
mode: mapreduce

setup:
  - shell: "debtmap analyze . --output debt.json"

map:
  input: debt.json
  json_path: "$.items[*]"
  filter: "item.severity == 'critical'"
  sort_by: "item.priority DESC"
  max_items: 20
  max_parallel: 5

  agent_template:
    - claude: "/fix-debt-item '${item.description}'"
      commit_required: true
    - shell: "cargo test"
      on_failure:
        claude: "/debug-and-fix"

reduce:
  - shell: "debtmap analyze . --output debt-after.json"
  - claude: "/compare-debt-reports --before debt.json --after debt-after.json"

error_policy:
  on_item_failure: dlq
  continue_on_failure: true
  max_failures: 5
  failure_threshold: 0.3
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h1>
<h2 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h2>
<h3 id="1-variables-not-interpolating"><a class="header" href="#1-variables-not-interpolating">1. Variables not interpolating</a></h3>
<p><strong>Symptom:</strong> Variables appear as literal <code>${variable_name}</code> in output instead of their values.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Incorrect syntax (missing <code>${}</code> wrapper)</li>
<li>Variable not defined or not in scope</li>
<li>Typo in variable name</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Ensure proper <code>${}</code> syntax: <code>${workflow.name}</code>, not <code>$workflow.name</code></li>
<li>Check variable is defined before use</li>
<li>Verify variable is available in current context (e.g., <code>${item.*}</code> only available in map phase)</li>
<li>Use echo to debug: <code>- shell: "echo 'Variable value: ${my_var}'"</code></li>
</ul>
<hr />
<h3 id="2-capture-not-working"><a class="header" href="#2-capture-not-working">2. Capture not working</a></h3>
<p><strong>Symptom:</strong> Captured variables are empty or contain unexpected data.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Incorrect <code>capture_format</code> for output type</li>
<li>Command output not in expected format</li>
<li>Missing or incorrect <code>capture_streams</code> configuration</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Match <code>capture_format</code> to output type and how it transforms output:
<ul>
<li><code>string</code> - Captures raw text output as-is</li>
<li><code>number</code> - Parses output as numeric value (int or float)</li>
<li><code>json</code> - Parses JSON and allows JSONPath queries on the result</li>
<li><code>lines</code> - Splits multi-line output into an array</li>
<li><code>boolean</code> - Evaluates to true/false based on success status</li>
</ul>
</li>
<li>Test command output manually first</li>
<li>Capture all streams for debugging:
<pre><code class="language-yaml">- shell: "cargo test 2&gt;&amp;1"
  capture: "test_output"
  capture_streams:
    stdout: true      # Capture standard output
    stderr: true      # Capture error output
    exit_code: true   # Capture exit code
    success: true     # Capture success boolean
    duration: true    # Capture execution duration
</code></pre>
</li>
</ul>
<hr />
<h3 id="3-validation-failing"><a class="header" href="#3-validation-failing">3. Validation failing</a></h3>
<p><strong>Symptom:</strong> Goal-seeking or validation commands fail to recognize completion.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Validate command not outputting <code>score: N</code> format</li>
<li>Threshold too high</li>
<li>Score calculation incorrect</li>
<li>Validation command not configured correctly</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Ensure validate command outputs exactly <code>score: N</code> (where N is 0-100)</li>
<li>Validation is part of goal_seek commands with these fields:
<ul>
<li><code>validate</code> - Command that outputs score</li>
<li><code>threshold</code> - Minimum score to consider success (0-100)</li>
<li><code>max_iterations</code> - Maximum attempts before giving up</li>
<li><code>on_incomplete</code> - Commands to run when score below threshold</li>
</ul>
</li>
<li>Test validate command independently</li>
<li>Lower threshold temporarily for debugging</li>
<li>Example correct format:
<pre><code class="language-yaml">- goal_seek:
    validate: |
      result=$(run-checks.sh | grep 'Percentage' | sed 's/.*: \([0-9]*\)%.*/\1/')
      echo "score: $result"
    threshold: 80
    max_iterations: 5
    on_incomplete:
      - claude: "/fix-issues"
</code></pre>
</li>
</ul>
<hr />
<h3 id="4-mapreduce-items-not-found"><a class="header" href="#4-mapreduce-items-not-found">4. MapReduce items not found</a></h3>
<p><strong>Symptom:</strong> Map phase finds zero items or wrong items.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Incorrect JSONPath expression</li>
<li>Input file format doesn’t match expectations</li>
<li>Input file not generated in setup phase</li>
<li>JSONPath syntax errors</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Test JSONPath expression with actual data using <code>jq</code>:
<pre><code class="language-bash">jq '$.items[*]' items.json
</code></pre>
</li>
<li>Verify input file exists and contains expected structure</li>
<li>Check setup phase completed successfully</li>
<li>Use simpler JSONPath first: <code>$[*]</code> to get all items</li>
<li>Common JSONPath mistakes:
<ul>
<li>Wrong bracket syntax: Use <code>$.items[*]</code> not <code>$.items[]</code></li>
<li>Missing root <code>$</code>: Always start with <code>$</code></li>
<li>Incorrect filter syntax: <code>$[?(@.score &gt;= 5)]</code> for filtering</li>
<li>Nested paths: <code>$.data.items[*].field</code> for deep structures</li>
</ul>
</li>
</ul>
<hr />
<h3 id="5-timeout-errors"><a class="header" href="#5-timeout-errors">5. Timeout errors</a></h3>
<p><strong>Symptom:</strong> Commands or workflows fail with timeout errors.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Commands take longer than expected</li>
<li>Default timeout too short</li>
<li>Infinite loops or hanging processes</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Increase timeout values using duration strings:
<pre><code class="language-yaml">- shell: "slow-command.sh"
  timeout: "600s"  # or "10m" - uses humantime duration format
</code></pre>
</li>
<li>For MapReduce, increase agent timeout (note: this uses seconds as a number):
<pre><code class="language-yaml">map:
  agent_timeout_secs: 600  # Takes a number (seconds) not a duration string
</code></pre>
</li>
<li><strong>Note:</strong> <code>agent_timeout_secs</code> takes a number (seconds) while most other timeout fields use duration strings like “10m”</li>
<li>Debug hanging commands by running them manually</li>
<li>Add logging to identify slow steps</li>
</ul>
<hr />
<h3 id="6-environment-variables-not-set"><a class="header" href="#6-environment-variables-not-set">6. Environment variables not set</a></h3>
<p><strong>Symptom:</strong> Commands fail because required environment variables are missing.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Environment not inherited from parent process</li>
<li>Typo in variable name</li>
<li>Profile not activated</li>
<li>Secret not loaded</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Ensure <code>inherit: true</code> in workflow config (default)</li>
<li>Verify profile activation:
<pre><code class="language-yaml">active_profile: "development"
</code></pre>
</li>
<li>Check secrets are properly configured:
<pre><code class="language-yaml">secrets:
  API_KEY: "${env:SECRET_API_KEY}"
</code></pre>
</li>
<li>Debug with: <code>- shell: "env | grep VARIABLE_NAME"</code></li>
</ul>
<hr />
<h3 id="7-merge-workflow-not-running"><a class="header" href="#7-merge-workflow-not-running">7. Merge workflow not running</a></h3>
<p><strong>Symptom:</strong> Custom merge commands not executed when merging worktree.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Merge block not properly formatted</li>
<li>Syntax error in merge commands</li>
<li>Merge workflow timeout too short</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>
<p>Both merge formats are valid - choose based on needs:</p>
<p><strong>Simplified format (direct list of commands):</strong></p>
<pre><code class="language-yaml">merge:
  - shell: "git fetch origin"
  - claude: "/merge-worktree ${merge.source_branch}"
</code></pre>
<p><strong>Full format (with timeout configuration):</strong></p>
<pre><code class="language-yaml">merge:
  commands:
    - shell: "slow-merge-validation.sh"
  timeout: "600s"  # Duration string format
</code></pre>
</li>
<li>
<p>Use the full format when you need to set a custom timeout</p>
</li>
<li>
<p>Check logs for merge execution errors</p>
</li>
</ul>
<hr />
<h3 id="8-commands-failing-without-error-handler"><a class="header" href="#8-commands-failing-without-error-handler">8. Commands failing without error handler</a></h3>
<p><strong>Symptom:</strong> Command fails and workflow stops immediately without recovery.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>No <code>on_failure</code> handler configured</li>
<li>Error not being caught by handler</li>
<li>Handler itself failing</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Add <code>on_failure</code> handler to commands that might fail:
<pre><code class="language-yaml">- shell: "risky-command.sh"
  on_failure:
    - shell: "echo 'Command failed, attempting recovery'"
    - claude: "/fix-issue"
</code></pre>
</li>
<li>Commands without <code>on_failure</code> will stop the workflow on first error</li>
<li>Check that your handler commands don’t also fail</li>
<li>Use shell exit codes to control failure: <code>command || exit 0</code> to ignore failures</li>
</ul>
<hr />
<h3 id="9-error-policy-configuration-issues"><a class="header" href="#9-error-policy-configuration-issues">9. Error policy configuration issues</a></h3>
<p><strong>Symptom:</strong> Retry, backoff, or circuit breaker not working as expected.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Incorrect Duration format for timeouts</li>
<li>Wrong BackoffStrategy enum variant</li>
<li>Invalid retry_config structure</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Use Duration strings for all timeout values:
<pre><code class="language-yaml">error_policy:
  retry_config:
    max_attempts: 3
    initial_delay: "1s"    # Not 1000
    max_delay: "30s"       # Use duration strings
  circuit_breaker:
    timeout: "60s"         # Not 60
    failure_threshold: 5
</code></pre>
</li>
<li>Valid BackoffStrategy values:
<ul>
<li><code>constant</code> - Same delay every time</li>
<li><code>linear</code> - Increases linearly</li>
<li><code>exponential</code> - Doubles each time</li>
<li><code>fibonacci</code> - Fibonacci sequence</li>
</ul>
</li>
<li>Circuit breaker requires both timeout and failure_threshold</li>
</ul>
<hr />
<h2 id="debug-tips"><a class="header" href="#debug-tips">Debug Tips</a></h2>
<h3 id="use-verbosity-flags-for-debugging"><a class="header" href="#use-verbosity-flags-for-debugging">Use verbosity flags for debugging</a></h3>
<p>Prodigy supports multiple verbosity levels for debugging:</p>
<pre><code class="language-bash"># Default: Clean output, no Claude streaming
prodigy run workflow.yml

# -v: Shows Claude streaming JSON output (useful for debugging Claude interactions)
prodigy run workflow.yml -v

# -vv: Adds debug-level logs
prodigy run workflow.yml -vv

# -vvv: Adds trace-level logs (very detailed)
prodigy run workflow.yml -vvv

# Force Claude streaming regardless of verbosity
PRODIGY_CLAUDE_CONSOLE_OUTPUT=true prodigy run workflow.yml
</code></pre>
<h3 id="enable-verbose-output-in-shell-commands"><a class="header" href="#enable-verbose-output-in-shell-commands">Enable verbose output in shell commands</a></h3>
<pre><code class="language-yaml">- shell: "set -x; your-command"
</code></pre>
<h3 id="inspect-variables"><a class="header" href="#inspect-variables">Inspect variables</a></h3>
<pre><code class="language-yaml">- shell: "echo 'Variable value: ${my_var}'"
- shell: "echo 'Item fields: path=${item.path} name=${item.name}'"
</code></pre>
<h3 id="capture-all-streams-for-debugging"><a class="header" href="#capture-all-streams-for-debugging">Capture all streams for debugging</a></h3>
<pre><code class="language-yaml">- shell: "cargo test 2&gt;&amp;1"
  capture: "test_output"
  capture_streams:
    stdout: true
    stderr: true
    exit_code: true
    success: true
    duration: true

# Then inspect
- shell: "echo 'Exit code: ${test_output.exit_code}'"
- shell: "echo 'Success: ${test_output.success}'"
- shell: "echo 'Duration: ${test_output.duration}s'"
</code></pre>
<h3 id="test-jsonpath-expressions"><a class="header" href="#test-jsonpath-expressions">Test JSONPath expressions</a></h3>
<pre><code class="language-bash"># Manually test your JSONPath
jq '$.items[*]' items.json

# Test with filter
jq '$.items[] | select(.score &gt;= 5)' items.json
</code></pre>
<h3 id="validate-workflow-syntax"><a class="header" href="#validate-workflow-syntax">Validate workflow syntax</a></h3>
<pre><code class="language-bash"># Workflows are validated automatically when loaded
# Check for syntax errors by attempting to run
prodigy run workflow.yml

# View the validation result file (if workflow validation completed)
cat .prodigy/validation-result.json
</code></pre>
<h3 id="check-dlq-for-failed-items"><a class="header" href="#check-dlq-for-failed-items">Check DLQ for failed items</a></h3>
<pre><code class="language-bash"># List failed items
prodigy dlq list &lt;job_id&gt;

# View failure details
prodigy dlq inspect &lt;job_id&gt;

# Retry failed items (primary recovery operation)
prodigy dlq retry &lt;job_id&gt;

# Retry with custom parallelism
prodigy dlq retry &lt;job_id&gt; --max-parallel 10

# Dry run to see what would be retried
prodigy dlq retry &lt;job_id&gt; --dry-run
</code></pre>
<h3 id="monitor-mapreduce-progress"><a class="header" href="#monitor-mapreduce-progress">Monitor MapReduce progress</a></h3>
<pre><code class="language-bash"># View events
prodigy events &lt;job_id&gt;

# Check checkpoints
prodigy checkpoints list

# View event logs directly
ls ~/.prodigy/events/

# Check session state
cat .prodigy/session_state.json
</code></pre>
<hr />
<h2 id="faq"><a class="header" href="#faq">FAQ</a></h2>
<h3 id="q-why-are-my-changes-not-being-committed"><a class="header" href="#q-why-are-my-changes-not-being-committed">Q: Why are my changes not being committed?</a></h3>
<p><strong>A:</strong> Add <code>commit_required: true</code> to your command or use <code>auto_commit: true</code> for automatic commits when changes are detected. Note: <code>auto_commit</code> can be set at the workflow level (applies to all steps) or per-step. When true, Prodigy creates commits automatically when git diff detects changes.</p>
<h3 id="q-how-do-i-retry-failed-mapreduce-items"><a class="header" href="#q-how-do-i-retry-failed-mapreduce-items">Q: How do I retry failed MapReduce items?</a></h3>
<p><strong>A:</strong> Use the DLQ retry command:</p>
<pre><code class="language-bash">prodigy dlq retry &lt;job_id&gt;
</code></pre>
<h3 id="q-can-i-use-environment-variables-in-jsonpath-expressions"><a class="header" href="#q-can-i-use-environment-variables-in-jsonpath-expressions">Q: Can I use environment variables in JSONPath expressions?</a></h3>
<p><strong>A:</strong> No, JSONPath expressions are evaluated against the input data, not the environment. Use variables in command arguments instead.</p>
<h3 id="q-how-do-i-skip-items-in-mapreduce"><a class="header" href="#q-how-do-i-skip-items-in-mapreduce">Q: How do I skip items in MapReduce?</a></h3>
<p><strong>A:</strong> Use the <code>filter</code> field:</p>
<pre><code class="language-yaml">map:
  filter: "item.score &gt;= 5"
</code></pre>
<h3 id="q-whats-the-difference-between-on_failure-and-on_incomplete"><a class="header" href="#q-whats-the-difference-between-on_failure-and-on_incomplete">Q: What’s the difference between <code>on_failure</code> and <code>on_incomplete</code>?</a></h3>
<p><strong>A:</strong> <code>on_failure</code> runs when a command exits with a non-zero code. <code>on_incomplete</code> is used in goal_seek commands and runs when the validation score is below the threshold.</p>
<h3 id="q-how-do-i-run-commands-in-parallel"><a class="header" href="#q-how-do-i-run-commands-in-parallel">Q: How do I run commands in parallel?</a></h3>
<p><strong>A:</strong> Use MapReduce mode with <code>max_parallel</code>:</p>
<pre><code class="language-yaml">mode: mapreduce
map:
  max_parallel: 5
</code></pre>
<h3 id="q-can-i-nest-workflows"><a class="header" href="#q-can-i-nest-workflows">Q: Can I nest workflows?</a></h3>
<p><strong>A:</strong> Not directly, but you can use <code>shell</code> commands to invoke other workflows:</p>
<pre><code class="language-yaml">- shell: "prodigy run other-workflow.yml"
</code></pre>
<hr />
<h2 id="common-error-messages"><a class="header" href="#common-error-messages">Common Error Messages</a></h2>
<h3 id="mapreduceerror-types"><a class="header" href="#mapreduceerror-types">MapReduceError Types</a></h3>
<p>Prodigy uses structured errors to help diagnose issues:</p>
<p><strong>Job-level errors:</strong></p>
<ul>
<li><code>JobNotFound</code> - Job ID doesn’t exist, check job_id spelling or if job was cleaned up</li>
<li><code>InvalidJobConfiguration</code> - Workflow YAML has configuration errors</li>
<li><code>WorktreeSetupFailed</code> - Failed to create git worktree, check disk space and git status</li>
</ul>
<p><strong>Agent-level errors:</strong></p>
<ul>
<li><code>AgentFailed</code> - Individual agent execution failed, check DLQ for details</li>
<li><code>AgentTimeout</code> - Agent exceeded timeout, increase agent_timeout_secs</li>
<li><code>CommandExecutionFailed</code> - Shell or Claude command failed in agent</li>
</ul>
<p><strong>Resource errors:</strong></p>
<ul>
<li><code>WorktreeMergeConflict</code> - Git merge conflict when merging agent results</li>
<li><code>ResourceExhausted</code> - Out of disk space, memory, or other resources</li>
<li><code>StorageError</code> - Failed to read/write to storage, check permissions</li>
</ul>
<p><strong>Recovery actions:</strong></p>
<ul>
<li>Check event logs: <code>prodigy events &lt;job_id&gt;</code></li>
<li>Review DLQ: <code>prodigy dlq list &lt;job_id&gt;</code></li>
<li>View detailed state: <code>cat ~/.prodigy/state/{repo}/mapreduce/jobs/{job_id}/checkpoint.json</code></li>
</ul>
<h3 id="checkpoint-and-resume-errors"><a class="header" href="#checkpoint-and-resume-errors">Checkpoint and Resume Errors</a></h3>
<p><strong>“Checkpoint not found”</strong></p>
<ul>
<li>Cause: No checkpoint file exists for this job</li>
<li>Solution: Job may have completed or checkpoint was deleted, start fresh</li>
</ul>
<p><strong>“Failed to resume from checkpoint”</strong></p>
<ul>
<li>Cause: Checkpoint file is corrupted or format changed</li>
<li>Solution: Check checkpoint JSON syntax, may need to start over</li>
</ul>
<p><strong>“Worktree conflicts during merge”</strong></p>
<ul>
<li>Cause: Git merge conflicts when combining agent results</li>
<li>Solution: Resolve conflicts manually in worktree, then retry merge</li>
</ul>
<h3 id="variable-and-capture-errors"><a class="header" href="#variable-and-capture-errors">Variable and Capture Errors</a></h3>
<p><strong>“Variable not found: ${variable_name}”</strong></p>
<ul>
<li>Cause: Variable not defined or out of scope</li>
<li>Solution: Check variable is defined before use, verify scope (workflow vs item vs capture)</li>
</ul>
<p><strong>“Failed to parse capture output as {format}”</strong></p>
<ul>
<li>Cause: Command output doesn’t match capture_format</li>
<li>Solution: Check output manually, adjust capture_format or command output</li>
</ul>
<p><strong>“JSONPath expression failed”</strong></p>
<ul>
<li>Cause: Invalid JSONPath syntax or doesn’t match data structure</li>
<li>Solution: Test with <code>jq</code> command, simplify expression, check input data format</li>
</ul>
<hr />
<h2 id="best-practices-for-debugging"><a class="header" href="#best-practices-for-debugging">Best Practices for Debugging</a></h2>
<ol>
<li><strong>Start simple</strong>: Test commands individually before adding to workflow</li>
<li><strong>Use verbosity flags</strong>: Use <code>-v</code> to see Claude interactions, <code>-vv</code> for debug logs, <code>-vvv</code> for trace</li>
<li><strong>Use echo liberally</strong>: Debug variable values with echo statements</li>
<li><strong>Check logs and state</strong>: Review event logs (<code>~/.prodigy/events/</code>) and session state (<code>.prodigy/session_state.json</code>)</li>
<li><strong>Test incrementally</strong>: Add commands one at a time and test after each</li>
<li><strong>Validate input data</strong>: Ensure JSON files and data formats are correct before MapReduce</li>
<li><strong>Check DLQ regularly</strong>: Monitor failed items with <code>prodigy dlq list</code> and retry when appropriate</li>
<li><strong>Monitor resources</strong>: Check disk space, memory, and CPU during execution</li>
<li><strong>Version control</strong>: Commit working workflows before making changes</li>
<li><strong>Read error messages carefully</strong>: MapReduceError types indicate specific failure modes</li>
<li><strong>Ask for help</strong>: Include full error messages, workflow config, and verbosity output when seeking support</li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
