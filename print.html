<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Prodigy Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="AI-powered workflow orchestration for development teams">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Prodigy Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/iepathos/prodigy" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Prodigy is an AI-powered workflow orchestration tool that enables development teams to automate complex tasks using Claude AI through structured YAML workflows.</p>
<h2 id="what-is-prodigy"><a class="header" href="#what-is-prodigy">What is Prodigy?</a></h2>
<p>Prodigy combines the power of Claude AI with workflow orchestration to:</p>
<ul>
<li><strong>Automate repetitive development tasks</strong> - Code reviews, refactoring, testing</li>
<li><strong>Process work in parallel</strong> - MapReduce-style parallel execution across git worktrees</li>
<li><strong>Maintain quality</strong> - Built-in validation, error handling, and retry mechanisms</li>
<li><strong>Track changes</strong> - Full git integration with automatic commits and merge workflows</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<p>Create a simple workflow in <code>workflow.yml</code>:</p>
<pre><code class="language-yaml">- shell: "cargo build"
- shell: "cargo test"
  on_failure:
    claude: "/fix-failing-tests"
- shell: "cargo clippy"
</code></pre>
<p>Run it:</p>
<pre><code class="language-bash">prodigy run workflow.yml
</code></pre>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<ul>
<li><strong>Workflows</strong>: YAML files defining sequences of commands</li>
<li><strong>Commands</strong>: Shell commands, Claude AI invocations, or control flow</li>
<li><strong>Variables</strong>: Dynamic values captured and interpolated across steps</li>
<li><strong>MapReduce</strong>: Parallel processing across multiple git worktrees</li>
<li><strong>Validation</strong>: Automatic testing and quality checks</li>
</ul>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li><a href="workflow-basics.html">Workflow Basics</a> - Learn workflow fundamentals</li>
<li><a href="commands.html">Command Types</a> - Explore available command types</li>
<li><a href="examples.html">Examples</a> - See real-world workflows</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="workflow-basics"><a class="header" href="#workflow-basics">Workflow Basics</a></h1>
<p>This chapter covers the fundamentals of creating Prodigy workflows. You’ll learn about workflow structure, basic commands, and configuration options.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Prodigy workflows are YAML files that define a sequence of commands to execute. They can be as simple as a list of shell commands or as complex as parallel MapReduce jobs.</p>
<p><strong>Two Main Workflow Types:</strong></p>
<ul>
<li><strong>Standard Workflows</strong>: Sequential command execution (covered here)</li>
<li><strong>MapReduce Workflows</strong>: Parallel processing with map/reduce phases (see <a href="mapreduce.html">MapReduce chapter</a>)</li>
</ul>
<h2 id="simple-workflows"><a class="header" href="#simple-workflows">Simple Workflows</a></h2>
<p>The simplest workflow is just an array of commands:</p>
<pre><code class="language-yaml"># Simple array format - just list your commands
- shell: "echo 'Starting workflow...'"
- claude: "/prodigy-analyze"
- shell: "cargo test"
</code></pre>
<p>This executes each command sequentially. No additional configuration needed.</p>
<h2 id="full-workflow-structure"><a class="header" href="#full-workflow-structure">Full Workflow Structure</a></h2>
<p>For more complex workflows, use the full format with explicit configuration:</p>
<pre><code class="language-yaml"># Full format with environment and merge configuration
commands:
  - shell: "cargo build"
  - claude: "/prodigy-test"

# Global environment variables (available to all commands)
env:
  NODE_ENV: production
  API_URL: https://api.example.com

# Secret environment variables (masked in logs)
secrets:
  API_KEY: "${env:SECRET_API_KEY}"

# Environment files to load (.env format)
env_files:
  - .env.production

# Environment profiles (switch contexts easily)
profiles:
  development:
    NODE_ENV: development
    DEBUG: "true"

# Custom merge workflow (for worktree integration)
merge:
  - shell: "git fetch origin"
  - claude: "/merge-worktree ${merge.source_branch}"
  timeout: 600  # Optional timeout in seconds
</code></pre>
<h2 id="available-fields"><a class="header" href="#available-fields">Available Fields</a></h2>
<p>Standard workflows support these top-level fields:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td><code>commands</code></td><td>Array</td><td>Yes*</td><td>List of commands to execute sequentially</td></tr>
<tr><td><code>env</code></td><td>Map</td><td>No</td><td>Global environment variables</td></tr>
<tr><td><code>secrets</code></td><td>Map</td><td>No</td><td>Secret environment variables (masked in logs)</td></tr>
<tr><td><code>env_files</code></td><td>Array</td><td>No</td><td>Paths to .env files to load</td></tr>
<tr><td><code>profiles</code></td><td>Map</td><td>No</td><td>Named environment profiles</td></tr>
<tr><td><code>merge</code></td><td>Object</td><td>No</td><td>Custom merge workflow for worktree integration</td></tr>
</tbody></table>
</div>
<p><strong>Note:</strong> <code>commands</code> is only required in the full format. Simple array format doesn’t use the <code>commands</code> key.</p>
<h2 id="command-types"><a class="header" href="#command-types">Command Types</a></h2>
<p>Prodigy supports several types of commands in workflows:</p>
<h3 id="core-commands"><a class="header" href="#core-commands">Core Commands</a></h3>
<p><strong><code>shell:</code></strong> - Execute shell commands</p>
<pre><code class="language-yaml">- shell: "cargo build --release"
- shell: "npm install"
</code></pre>
<p><strong><code>claude:</code></strong> - Invoke Claude Code commands</p>
<pre><code class="language-yaml">- claude: "/prodigy-lint"
- claude: "/analyze codebase"
</code></pre>
<h3 id="advanced-commands"><a class="header" href="#advanced-commands">Advanced Commands</a></h3>
<ul>
<li><strong><code>goal_seek:</code></strong> - Goal-seeking operations with validation (see <a href="advanced.html">Advanced Features</a>)</li>
<li><strong><code>foreach:</code></strong> - Iterate over lists with nested commands (see <a href="advanced.html">Advanced Features</a>)</li>
<li><strong><code>validate:</code></strong> - Validation steps with configurable thresholds (see <a href="commands.html">Commands</a>)</li>
</ul>
<p><strong>Deprecated:</strong></p>
<ul>
<li><strong><code>test:</code></strong> - Deprecated in favor of <code>shell:</code> with <code>on_failure:</code> handlers</li>
</ul>
<p>For detailed information on each command type and their fields, see the <a href="commands.html">Command Types chapter</a>.</p>
<h2 id="command-level-options"><a class="header" href="#command-level-options">Command-Level Options</a></h2>
<p>All command types support additional fields for advanced control:</p>
<h3 id="basic-options"><a class="header" href="#basic-options">Basic Options</a></h3>
<pre><code class="language-yaml">- shell: "cargo test"
  id: "run-tests"              # Step identifier for output referencing
  commit_required: true        # Expect git commit after this step
  timeout: 300                 # Timeout in seconds
</code></pre>
<h3 id="conditional-execution"><a class="header" href="#conditional-execution">Conditional Execution</a></h3>
<p>Run commands based on conditions:</p>
<pre><code class="language-yaml">- shell: "deploy.sh"
  when: "${branch} == 'main'"  # Only run on main branch
</code></pre>
<h3 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h3>
<p>Handle failures gracefully:</p>
<pre><code class="language-yaml">- shell: "risky-command"
  on_failure:
    shell: "cleanup.sh"        # Run on failure
  on_success:
    shell: "notify.sh"         # Run on success
</code></pre>
<h3 id="output-capture"><a class="header" href="#output-capture">Output Capture</a></h3>
<p>Capture command output to variables:</p>
<pre><code class="language-yaml">- shell: "git rev-parse HEAD"
  id: "get-commit"
  capture: "commit_hash"       # Capture to variable
  capture_format: "string"     # Format: string|json|lines|number|boolean
</code></pre>
<p>For comprehensive coverage of these options, see:</p>
<ul>
<li><a href="advanced.html">Advanced Features</a> - Conditional execution, output capture, timeouts</li>
<li><a href="error-handling.html">Error Handling</a> - on_failure and on_success handlers</li>
<li><a href="variables.html">Variables</a> - Variable interpolation and capture formats</li>
</ul>
<h2 id="environment-configuration"><a class="header" href="#environment-configuration">Environment Configuration</a></h2>
<p>Environment variables can be configured at multiple levels:</p>
<h3 id="global-environment-variables"><a class="header" href="#global-environment-variables">Global Environment Variables</a></h3>
<pre><code class="language-yaml">env:
  NODE_ENV: production
  DATABASE_URL: postgres://localhost/mydb
</code></pre>
<h3 id="secret-variables"><a class="header" href="#secret-variables">Secret Variables</a></h3>
<p>Secret variables are masked in logs for security:</p>
<pre><code class="language-yaml">secrets:
  API_KEY: "${env:SECRET_API_KEY}"
  DB_PASSWORD: "${env:DATABASE_PASSWORD}"
</code></pre>
<h3 id="environment-files"><a class="header" href="#environment-files">Environment Files</a></h3>
<p>Load variables from .env files:</p>
<pre><code class="language-yaml">env_files:
  - .env
  - .env.production
</code></pre>
<h3 id="environment-profiles"><a class="header" href="#environment-profiles">Environment Profiles</a></h3>
<p>Switch between different environment contexts:</p>
<pre><code class="language-yaml">profiles:
  development:
    NODE_ENV: development
    DEBUG: "true"
    API_URL: http://localhost:3000

  production:
    NODE_ENV: production
    DEBUG: "false"
    API_URL: https://api.example.com
</code></pre>
<p>Activate a profile with: <code>prodigy run --profile development</code></p>
<p>For more details, see the <a href="environment.html">Environment Variables chapter</a>.</p>
<h2 id="merge-workflows"><a class="header" href="#merge-workflows">Merge Workflows</a></h2>
<p>Merge workflows execute when merging worktree changes back to the main branch. This feature enables custom validation, testing, and conflict resolution before integrating changes.</p>
<p><strong>When to use merge workflows:</strong></p>
<ul>
<li>Run tests before merging</li>
<li>Validate code quality</li>
<li>Handle merge conflicts automatically</li>
<li>Sync with upstream changes</li>
</ul>
<pre><code class="language-yaml">merge:
  commands:
    - shell: "git fetch origin"
    - shell: "git merge origin/main"
    - shell: "cargo test"
    - claude: "/prodigy-merge-worktree ${merge.source_branch}"
  timeout: 600  # Optional: overall timeout for merge workflow
</code></pre>
<p><strong>Available merge variables:</strong></p>
<ul>
<li><code>${merge.worktree}</code> - Worktree name (e.g., “prodigy-session-abc123”)</li>
<li><code>${merge.source_branch}</code> - Source branch (worktree branch)</li>
<li><code>${merge.target_branch}</code> - Target branch (usually main/master)</li>
<li><code>${merge.session_id}</code> - Session ID for correlation</li>
</ul>
<p>These variables are only available within the merge workflow context.</p>
<h2 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h2>
<p>Here’s a complete workflow combining multiple features:</p>
<pre><code class="language-yaml"># Environment configuration
env:
  RUST_BACKTRACE: 1

env_files:
  - .env

profiles:
  ci:
    CI: "true"
    VERBOSE: "true"

# Workflow commands
commands:
  - shell: "cargo fmt --check"
  - shell: "cargo clippy -- -D warnings"
  - shell: "cargo test --all"
  - claude: "/prodigy-lint"

# Custom merge workflow
merge:
  commands:
    - shell: "cargo test"
    - claude: "/prodigy-merge-worktree ${merge.source_branch}"
  timeout: 300
</code></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>Now that you understand basic workflows, explore these topics:</p>
<ul>
<li><strong><a href="command-reference.html">Command Reference</a></strong> - Detailed guide to all command types and options</li>
<li><strong><a href="environment.html">Environment Variables</a></strong> - Advanced environment configuration</li>
<li><strong><a href="error-handling.html">Error Handling</a></strong> - Handle failures gracefully</li>
<li><strong><a href="mapreduce.html">MapReduce Workflows</a></strong> - Parallel processing for large-scale tasks</li>
<li><strong><a href="conditionals.html">Conditional Execution</a></strong> - Run commands based on conditions</li>
<li><strong><a href="output-capture.html">Output Capture</a></strong> - Capture and use command outputs</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mapreduce-workflows"><a class="header" href="#mapreduce-workflows">MapReduce Workflows</a></h1>
<h2 id="complete-structure"><a class="header" href="#complete-structure">Complete Structure</a></h2>
<pre><code class="language-yaml">name: parallel-processing
mode: mapreduce

# Optional setup phase
setup:
  - shell: "generate-work-items.sh"
  - shell: "debtmap analyze . --output items.json"

# Map phase: Process items in parallel
map:
  # Input source (JSON file or command)
  input: "items.json"

  # JSONPath expression to extract items
  json_path: "$.items[*]"

  # Agent template (commands run for each item)
  # Modern syntax: Commands directly under agent_template
  agent_template:
    - claude: "/process '${item}'"
    - shell: "test ${item.path}"
      on_failure:
        claude: "/fix-issue '${item}'"

  # DEPRECATED: Nested 'commands' syntax (still supported)
  # agent_template:
  #   commands:
  #     - claude: "/process '${item}'"

  # Maximum parallel agents
  max_parallel: 10

  # Optional: Filter items
  filter: "item.score &gt;= 5"

  # Optional: Sort items
  sort_by: "item.priority DESC"

  # Optional: Limit number of items
  max_items: 100

  # Optional: Skip items
  offset: 10

  # Optional: Deduplicate by field
  distinct: "item.id"

  # Optional: Agent timeout in seconds
  agent_timeout_secs: 300

# Reduce phase: Aggregate results
# Modern syntax: Commands directly under reduce
reduce:
  - claude: "/summarize ${map.results}"
  - shell: "echo 'Processed ${map.successful}/${map.total} items'"

# DEPRECATED: Nested 'commands' syntax (still supported)
# reduce:
#   commands:
#     - claude: "/summarize ${map.results}"

# Optional: Custom merge workflow (supports two formats)
merge:
  # Simple array format
  - shell: "git fetch origin"
  - claude: "/merge-worktree ${merge.source_branch}"
  - shell: "cargo test"

# OR full format with timeout
# merge:
#   commands:
#     - shell: "git fetch origin"
#     - claude: "/merge-worktree ${merge.source_branch}"
#   timeout: 600  # Timeout in seconds

# Error handling policy
error_policy:
  on_item_failure: dlq  # dlq, retry, skip, stop, or custom handler name
  continue_on_failure: true
  max_failures: 5
  failure_threshold: 0.2  # 20% failure rate
  error_collection: aggregate  # aggregate, immediate, or batched:N

  # Circuit breaker configuration
  circuit_breaker:
    failure_threshold: 5      # Open circuit after N failures
    success_threshold: 2      # Close circuit after N successes
    timeout: "60s"           # Duration before attempting half-open (e.g., "60s", "1m", "5m")
    half_open_requests: 3    # Test requests in half-open state

  # Retry configuration with backoff
  retry_config:
    max_attempts: 3
    backoff:
      type: exponential      # fixed, linear, exponential, fibonacci
      initial: "1s"          # Initial delay (e.g., "1s", "500ms")
      multiplier: 2          # For exponential
      # Note: max_delay is NOT supported - use max_attempts to limit retries

# Convenience fields (alternative to nested error_policy)
# These top-level fields map to error_policy for simpler syntax
on_item_failure: dlq
continue_on_failure: true
max_failures: 5
</code></pre>
<h2 id="setup-phase-advanced"><a class="header" href="#setup-phase-advanced">Setup Phase (Advanced)</a></h2>
<p>The setup phase supports two formats: simple array OR full configuration object.</p>
<pre><code class="language-yaml"># Simple array format
setup:
  - shell: "prepare-data.sh"
  - shell: "analyze-codebase.sh"

# Full configuration format with timeout and capture
setup:
  commands:
    - shell: "prepare-data.sh"
    - shell: "analyze-codebase.sh"

  # Timeout for entire setup phase (seconds)
  timeout: 300

  # Capture outputs from setup commands
  capture_outputs:
    # Simple format (legacy - just index)
    file_count: 0  # Capture from command at index 0

    # Full CaptureConfig format
    analysis_result:
      command_index: 1
      format: json  # string, number, json, lines, boolean
</code></pre>
<p><strong>Setup Phase Fields:</strong></p>
<ul>
<li><code>commands</code> - Array of commands to execute (or use simple array format at top level)</li>
<li><code>timeout</code> - Timeout for entire setup phase in seconds</li>
<li><code>capture_outputs</code> - Map of variable names to command outputs (supports Simple(index) or full CaptureConfig)</li>
</ul>
<h2 id="global-storage-architecture"><a class="header" href="#global-storage-architecture">Global Storage Architecture</a></h2>
<p>MapReduce workflows use a global storage architecture located in <code>~/.prodigy/</code> (not <code>.prodigy/</code> in your project). This enables:</p>
<ul>
<li><strong>Cross-worktree event aggregation</strong>: Multiple worktrees working on the same job share event logs</li>
<li><strong>Persistent state management</strong>: Job checkpoints survive worktree cleanup</li>
<li><strong>Centralized monitoring</strong>: All job data accessible from a single location</li>
<li><strong>Efficient storage</strong>: Deduplication across worktrees</li>
</ul>
<h3 id="storage-locations"><a class="header" href="#storage-locations">Storage Locations</a></h3>
<pre><code>~/.prodigy/
├── events/
│   └── {repo_name}/          # Events grouped by repository
│       └── {job_id}/         # Job-specific events
│           └── events-{timestamp}.jsonl  # Event log files
├── dlq/
│   └── {repo_name}/          # DLQ grouped by repository
│       └── {job_id}/         # Job-specific failed items
└── state/
    └── {repo_name}/          # State grouped by repository
        └── mapreduce/        # MapReduce job states
            └── jobs/
                └── {job_id}/ # Job-specific checkpoints
</code></pre>
<h2 id="event-tracking"><a class="header" href="#event-tracking">Event Tracking</a></h2>
<p>All MapReduce execution events are logged to <code>~/.prodigy/events/{repo_name}/{job_id}/</code> for debugging and monitoring:</p>
<p><strong>Events Tracked:</strong></p>
<ul>
<li>Agent lifecycle events (started, completed, failed)</li>
<li>Work item processing status</li>
<li>Checkpoint saves for resumption</li>
<li>Error details with correlation IDs</li>
<li>Cross-worktree event aggregation for parallel jobs</li>
</ul>
<p><strong>Event Log Format:</strong>
Events are stored in JSONL (JSON Lines) format, with each line representing a single event:</p>
<pre><code class="language-json">{"timestamp":"2024-01-01T12:00:00Z","event_type":"agent_started","agent_id":"agent-1","item_id":"item-001"}
{"timestamp":"2024-01-01T12:05:00Z","event_type":"agent_completed","agent_id":"agent-1","item_id":"item-001","status":"success"}
</code></pre>
<p><strong>Viewing Events:</strong></p>
<pre><code class="language-bash"># View all events for a job
prodigy events &lt;job_id&gt;

# Stream events in real-time
prodigy events &lt;job_id&gt; --follow
</code></pre>
<h2 id="checkpoint-and-resume"><a class="header" href="#checkpoint-and-resume">Checkpoint and Resume</a></h2>
<p>MapReduce workflows automatically save checkpoints to enable resumption after interruption.</p>
<h3 id="checkpoint-structure"><a class="header" href="#checkpoint-structure">Checkpoint Structure</a></h3>
<p>Checkpoints are stored in <code>~/.prodigy/state/{repo_name}/mapreduce/jobs/{job_id}/</code> and contain:</p>
<pre><code class="language-json">{
  "job_id": "mapreduce-1234567890",
  "workflow_file": "workflow.yml",
  "phase": "map",
  "items_processed": 45,
  "items_total": 100,
  "items_remaining": ["item-046", "item-047", "..."],
  "successful_items": 43,
  "failed_items": 2,
  "started_at": "2024-01-01T12:00:00Z",
  "last_checkpoint_at": "2024-01-01T12:30:00Z"
}
</code></pre>
<h3 id="resume-behavior"><a class="header" href="#resume-behavior">Resume Behavior</a></h3>
<p>When resuming a MapReduce job:</p>
<ol>
<li><strong>Checkpoint Loading</strong>: Prodigy loads the most recent checkpoint from <code>~/.prodigy/state/</code></li>
<li><strong>Work Item Recovery</strong>: Items marked as “in progress” are reset to “pending”</li>
<li><strong>Failed Item Handling</strong>: Previously failed items are moved to DLQ (not retried automatically)</li>
<li><strong>Partial Results</strong>: Successfully processed items are preserved</li>
<li><strong>Phase Continuation</strong>: Job resumes from the phase it was interrupted in</li>
</ol>
<p><strong>Resume Command:</strong></p>
<pre><code class="language-bash"># Resume from checkpoint
prodigy resume-job &lt;job_id&gt;

# Resume with different parallelism
prodigy resume-job &lt;job_id&gt; --max-parallel 20

# Resume and show detailed logs
prodigy resume-job &lt;job_id&gt; -v
</code></pre>
<h2 id="dead-letter-queue-dlq"><a class="header" href="#dead-letter-queue-dlq">Dead Letter Queue (DLQ)</a></h2>
<p>Failed work items are automatically stored in the DLQ for review and retry.</p>
<h3 id="dlq-storage"><a class="header" href="#dlq-storage">DLQ Storage</a></h3>
<p>Failed items are stored in <code>~/.prodigy/dlq/{repo_name}/{job_id}/</code> with this structure:</p>
<pre><code class="language-json">{
  "item_id": "item-047",
  "item_data": {
    "path": "src/module.rs",
    "score": 8,
    "priority": "high"
  },
  "failure_reason": "Command failed: cargo test",
  "error_details": "test failed: expected X but got Y",
  "failed_at": "2024-01-01T12:15:00Z",
  "attempt_count": 3,
  "correlation_id": "agent-7-item-047"
}
</code></pre>
<h3 id="dlq-retry"><a class="header" href="#dlq-retry">DLQ Retry</a></h3>
<p>The <code>prodigy dlq retry</code> command allows you to reprocess failed items:</p>
<pre><code class="language-bash"># Retry all failed items for a job
prodigy dlq retry &lt;job_id&gt;

# Retry with custom parallelism (default: 5)
prodigy dlq retry &lt;job_id&gt; --max-parallel 10

# Dry run to see what would be retried
prodigy dlq retry &lt;job_id&gt; --dry-run

# Verbose output for debugging
prodigy dlq retry &lt;job_id&gt; -v
</code></pre>
<p><strong>DLQ Retry Features:</strong></p>
<ul>
<li>Streams items to avoid memory issues with large queues</li>
<li>Respects original workflow’s <code>max_parallel</code> setting</li>
<li>Preserves correlation IDs for tracking</li>
<li>Updates DLQ state (removes successful, keeps failed)</li>
<li>Supports interruption and resumption</li>
<li>Retried items inherit original workflow configuration</li>
</ul>
<p><strong>DLQ Retry Workflow:</strong></p>
<ol>
<li>Load failed items from <code>~/.prodigy/dlq/{repo_name}/{job_id}/</code></li>
<li>Process items using original workflow’s agent template</li>
<li>Successfully processed items are removed from DLQ</li>
<li>Still-failing items remain in DLQ with updated attempt count</li>
<li>New failures during retry are logged and added to DLQ</li>
</ol>
<h3 id="viewing-dlq-contents"><a class="header" href="#viewing-dlq-contents">Viewing DLQ Contents</a></h3>
<pre><code class="language-bash"># List all failed items
prodigy dlq list &lt;job_id&gt;

# Show details for specific item
prodigy dlq show &lt;job_id&gt; &lt;item_id&gt;

# Clear DLQ after manual fixes
prodigy dlq clear &lt;job_id&gt;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="command-types-1"><a class="header" href="#command-types-1">Command Types</a></h1>
<h2 id="1-shell-commands"><a class="header" href="#1-shell-commands">1. Shell Commands</a></h2>
<pre><code class="language-yaml"># Simple shell command
- shell: "cargo test"

# With output capture
- shell: "ls -la | wc -l"
  capture: "file_count"

# With failure handling
- shell: "cargo clippy"
  on_failure:
    claude: "/fix-warnings ${shell.output}"

# With timeout
- shell: "cargo bench"
  timeout: 600  # seconds

# With conditional execution
- shell: "cargo build --release"
  when: "${tests_passed}"
</code></pre>
<h2 id="2-claude-commands"><a class="header" href="#2-claude-commands">2. Claude Commands</a></h2>
<pre><code class="language-yaml"># Simple Claude command
- claude: "/prodigy-analyze"

# With arguments
- claude: "/prodigy-implement-spec ${spec_file}"

# With commit requirement
- claude: "/prodigy-fix-bugs"
  commit_required: true

# With output capture
- claude: "/prodigy-generate-plan"
  capture: "implementation_plan"
</code></pre>
<h2 id="3-goal-seeking-commands"><a class="header" href="#3-goal-seeking-commands">3. Goal-Seeking Commands</a></h2>
<p>Iteratively refine code until a validation threshold is met.</p>
<pre><code class="language-yaml">- goal_seek:
    goal: "Achieve 90% test coverage"
    claude: "/prodigy-coverage --improve"
    validate: "cargo tarpaulin --print-summary | grep 'Coverage' | sed 's/.*Coverage=\\([0-9]*\\).*/score: \\1/'"
    threshold: 90
    max_attempts: 5
    timeout_seconds: 300
    fail_on_incomplete: true
  commit_required: true
</code></pre>
<p><strong>Fields:</strong></p>
<ul>
<li><code>goal</code>: Human-readable description</li>
<li><code>claude</code> or <code>shell</code>: Command to execute for refinement</li>
<li><code>validate</code>: Command that outputs <code>score: N</code> (0-100)</li>
<li><code>threshold</code>: Minimum score to consider complete</li>
<li><code>max_attempts</code>: Maximum refinement iterations</li>
<li><code>timeout_seconds</code>: Optional timeout per attempt</li>
<li><code>fail_on_incomplete</code>: Whether to fail workflow if threshold not met</li>
</ul>
<h2 id="4-foreach-commands"><a class="header" href="#4-foreach-commands">4. Foreach Commands</a></h2>
<p>Iterate over a list with optional parallelism.</p>
<pre><code class="language-yaml">- foreach:
    input: "find . -name '*.rs' -type f"  # Command
    # OR
    # input: ["file1.rs", "file2.rs"]    # List

    parallel: 5  # Number of parallel executions (or true/false)

    do:
      - claude: "/analyze-file ${item}"
      - shell: "cargo check ${item}"

    continue_on_error: true
    max_items: 50
</code></pre>
<h2 id="5-validation-commands"><a class="header" href="#5-validation-commands">5. Validation Commands</a></h2>
<p>Validate implementation completeness with automatic retry.</p>
<pre><code class="language-yaml">- claude: "/implement-auth-spec"
  validate:
    shell: "debtmap validate --spec auth.md --output result.json"
    # DEPRECATED: 'command' field (use 'shell' instead)
    result_file: "result.json"
    threshold: 95  # Percentage completion required (default: 100.0)
    timeout: 60
    expected_schema: "validation-schema.json"  # Optional JSON schema

    # What to do if incomplete
    on_incomplete:
      claude: "/complete-implementation ${validation.gaps}"
      max_attempts: 3
      fail_workflow: true
      commit_required: true
      prompt: "Implementation incomplete. Continue?"  # Optional interactive prompt
</code></pre>
<p><strong>ValidationConfig Fields:</strong></p>
<ul>
<li><code>shell</code> or <code>claude</code> - Single validation command (use <code>shell</code>, not deprecated <code>command</code>)</li>
<li><code>commands</code> - Array of commands for multi-step validation</li>
<li><code>result_file</code> - Path to JSON file with validation results</li>
<li><code>threshold</code> - Minimum completion percentage (default: 100.0)</li>
<li><code>timeout</code> - Timeout in seconds</li>
<li><code>expected_schema</code> - JSON schema for validation output structure</li>
</ul>
<p><strong>OnIncompleteConfig Fields:</strong></p>
<ul>
<li><code>shell</code> or <code>claude</code> - Single gap-filling command</li>
<li><code>commands</code> - Array of commands for multi-step gap filling</li>
<li><code>max_attempts</code> - Maximum retry attempts</li>
<li><code>fail_workflow</code> - Whether to fail workflow if validation incomplete</li>
<li><code>commit_required</code> - Whether to require commit after gap filling</li>
<li><code>prompt</code> - Optional interactive prompt for user guidance</li>
<li><code>retry_original</code> - Whether to retry the original command (default: false). When true, re-executes the original command instead of gap-filling commands</li>
<li><code>strategy</code> - Retry strategy configuration (similar to OnFailureConfig strategy)</li>
</ul>
<p><strong>Alternative: Array format for multi-step validation</strong></p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    # When using array format, ValidationConfig uses default threshold (100.0)
    # and creates a commands array
    - shell: "run-tests.sh"
    - shell: "check-coverage.sh"
    - claude: "/validate-implementation --output validation.json"
      result_file: "validation.json"
</code></pre>
<p><strong>Alternative: Multi-step gap filling</strong></p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    shell: "validate.sh"
    result_file: "result.json"
    on_incomplete:
      commands:
        - claude: "/analyze-gaps ${validation.gaps}"
        - shell: "run-fix-script.sh"
        - claude: "/verify-fixes"
      max_attempts: 2
</code></pre>
<p><strong>Alternative: Retry original command on incomplete</strong></p>
<pre><code class="language-yaml">- claude: "/implement-auth"
  validate:
    shell: "validate-auth.sh"
    result_file: "result.json"
    threshold: 95
    on_incomplete:
      retry_original: true  # Re-run "/implement-auth" instead of gap-filling
      max_attempts: 3
      fail_workflow: true
</code></pre>
<hr />
<h2 id="command-reference"><a class="header" href="#command-reference">Command Reference</a></h2>
<h3 id="command-fields"><a class="header" href="#command-fields">Command Fields</a></h3>
<p>All command types support these common fields:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>id</code></td><td>string</td><td>Unique identifier for referencing outputs</td></tr>
<tr><td><code>timeout</code></td><td>number</td><td>Command timeout in seconds</td></tr>
<tr><td><code>commit_required</code></td><td>boolean</td><td>Whether command should create a git commit</td></tr>
<tr><td><code>when</code></td><td>string</td><td>Conditional execution expression</td></tr>
<tr><td><code>capture</code></td><td>string</td><td>Variable name to capture output (replaces deprecated <code>capture_output: true/false</code>)</td></tr>
<tr><td><code>capture_format</code></td><td>enum</td><td>Format: <code>string</code> (default), <code>number</code>, <code>json</code>, <code>lines</code>, <code>boolean</code> (see examples below)</td></tr>
<tr><td><code>capture_streams</code></td><td>object</td><td>Configure which streams to capture (see CaptureStreams section below)</td></tr>
<tr><td><code>on_success</code></td><td>object</td><td>Command to run on success</td></tr>
<tr><td><code>on_failure</code></td><td>object</td><td>OnFailureConfig with nested command, max_attempts, fail_workflow, strategy</td></tr>
<tr><td><code>on_exit_code</code></td><td>map</td><td>Maps exit codes to full WorkflowStep objects (e.g., <code>101: {claude: "/fix"}</code>)</td></tr>
<tr><td><code>validate</code></td><td>object</td><td>Validation configuration</td></tr>
<tr><td><code>output_file</code></td><td>string</td><td>Redirect command output to a file</td></tr>
</tbody></table>
</div>
<p><strong>Note:</strong> The following fields exist in internal structs but are NOT exposed in WorkflowStepCommand YAML:</p>
<ul>
<li><code>handler</code> - Internal HandlerStep (not user-facing)</li>
<li><code>retry</code> - Internal RetryConfig (not user-facing)</li>
<li><code>working_dir</code> - Not available (use shell <code>cd</code> command instead)</li>
<li><code>env</code> - Not available (use shell environment syntax: <code>ENV=value command</code>)</li>
<li><code>auto_commit</code> - Not in WorkflowStepCommand</li>
<li><code>commit_config</code> - Not in WorkflowStepCommand</li>
<li><code>step_validate</code> - Not in WorkflowStepCommand</li>
<li><code>skip_validation</code> - Not in WorkflowStepCommand</li>
<li><code>validation_timeout</code> - Not in WorkflowStepCommand</li>
<li><code>ignore_validation_failure</code> - Not in WorkflowStepCommand</li>
</ul>
<h3 id="capturestreams-configuration"><a class="header" href="#capturestreams-configuration">CaptureStreams Configuration</a></h3>
<p>The <code>capture_streams</code> field controls which output streams are captured:</p>
<pre><code class="language-yaml">- shell: "cargo test"
  capture: "test_results"
  capture_streams:
    stdout: true      # Capture standard output (default: true)
    stderr: false     # Capture standard error (default: false)
    exit_code: true   # Capture exit code (default: true)
    success: true     # Capture success boolean (default: true)
    duration: true    # Capture execution duration (default: true)
</code></pre>
<p><strong>Examples:</strong></p>
<pre><code class="language-yaml"># Capture only stdout and stderr
- shell: "build.sh"
  capture: "build_output"
  capture_streams:
    stdout: true
    stderr: true
    exit_code: false
    success: false
    duration: false

# Capture only timing information
- shell: "benchmark.sh"
  capture: "bench_time"
  capture_streams:
    stdout: false
    stderr: false
    exit_code: false
    success: false
    duration: true
</code></pre>
<h3 id="capture-format-examples"><a class="header" href="#capture-format-examples">Capture Format Examples</a></h3>
<p>The <code>capture_format</code> field controls how captured output is parsed:</p>
<pre><code class="language-yaml"># String format (default) - raw text output
- shell: "git rev-parse HEAD"
  capture: "commit_hash"
  capture_format: "string"

# Number format - parses numeric output
- shell: "wc -l &lt; file.txt"
  capture: "line_count"
  capture_format: "number"

# JSON format - parses JSON output
- shell: "cargo metadata --format-version 1"
  capture: "project_metadata"
  capture_format: "json"

# Lines format - splits output into array of lines
- shell: "git diff --name-only"
  capture: "changed_files"
  capture_format: "lines"

# Boolean format - true if command succeeds, false otherwise
- shell: "grep -q 'pattern' file.txt"
  capture: "pattern_found"
  capture_format: "boolean"
</code></pre>
<h3 id="deprecated-fields"><a class="header" href="#deprecated-fields">Deprecated Fields</a></h3>
<p>These fields are deprecated but still supported for backward compatibility:</p>
<ul>
<li><code>test:</code> - Use <code>shell:</code> with <code>on_failure:</code> instead</li>
<li><code>command:</code> in ValidationConfig - Use <code>shell:</code> instead</li>
<li>Nested <code>commands:</code> in <code>agent_template</code> and <code>reduce</code> - Use direct array format instead</li>
<li>Legacy variable aliases (<code>$ARG</code>, <code>$ARGUMENT</code>, <code>$FILE</code>, <code>$FILE_PATH</code>) - Use modern <code>${item.*}</code> syntax</li>
</ul>
<p><strong>Migration: capture_output to capture</strong></p>
<p>Old syntax (deprecated):</p>
<pre><code class="language-yaml">- shell: "ls -la | wc -l"
  capture_output: true
</code></pre>
<p>New syntax (recommended):</p>
<pre><code class="language-yaml">- shell: "ls -la | wc -l"
  capture: "file_count"
</code></pre>
<p>The modern <code>capture</code> field allows you to specify a variable name, making output references clearer and more maintainable</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="variable-interpolation"><a class="header" href="#variable-interpolation">Variable Interpolation</a></h1>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>Prodigy provides two complementary variable systems:</p>
<ol>
<li><strong>Built-in Variables</strong>: Automatically available based on workflow context (workflow state, step info, work items, etc.)</li>
<li><strong>Custom Captured Variables</strong>: User-defined variables created via the <code>capture:</code> field in commands</li>
</ol>
<p>Both systems use the same <code>${variable.name}</code> interpolation syntax and can be freely mixed in your workflows.</p>
<h2 id="variable-availability-by-phase"><a class="header" href="#variable-availability-by-phase">Variable Availability by Phase</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Variable Category</th><th>Setup</th><th>Map</th><th>Reduce</th><th>Merge</th></tr></thead><tbody>
<tr><td>Standard Variables</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr>
<tr><td>Output Variables</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr>
<tr><td>Item Variables (<code>${item.*}</code>)</td><td>✗</td><td>✓</td><td>✗</td><td>✗</td></tr>
<tr><td>Map Aggregation (<code>${map.total}</code>, etc.)</td><td>✗</td><td>✗</td><td>✓</td><td>✗</td></tr>
<tr><td>Merge Variables</td><td>✗</td><td>✗</td><td>✗</td><td>✓</td></tr>
<tr><td>Custom Captured Variables</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr>
</tbody></table>
</div>
<h2 id="available-variables"><a class="header" href="#available-variables">Available Variables</a></h2>
<h3 id="standard-variables"><a class="header" href="#standard-variables">Standard Variables</a></h3>
<ul>
<li><code>${workflow.name}</code> - Workflow name</li>
<li><code>${workflow.id}</code> - Workflow unique identifier</li>
<li><code>${workflow.iteration}</code> - Current iteration number</li>
<li><code>${step.name}</code> - Current step name</li>
<li><code>${step.index}</code> - Current step index</li>
<li><code>${step.files_changed}</code> - Files changed in current step</li>
<li><code>${workflow.files_changed}</code> - All files changed in workflow</li>
</ul>
<h3 id="output-variables"><a class="header" href="#output-variables">Output Variables</a></h3>
<p><strong>Primary Output Variables:</strong></p>
<ul>
<li><code>${shell.output}</code> - Output (stdout) from last shell command</li>
<li><code>${claude.output}</code> - Output from last Claude command</li>
<li><code>${last.output}</code> - Output from last executed command (any type)</li>
<li><code>${last.exit_code}</code> - Exit code from last command</li>
</ul>
<p><strong>Note</strong>: <code>${shell.output}</code> is the correct variable name for shell command output. The code uses <code>shell.output</code>, not <code>shell.stdout</code>.</p>
<p><strong>Legacy/Specialized Output Variables:</strong></p>
<ul>
<li><code>${handler.output}</code> - Output from handler command (used in error handling)</li>
<li><code>${test.output}</code> - Output from test command (used in validation)</li>
<li><code>${goal_seek.output}</code> - Output from goal-seeking command</li>
</ul>
<p><strong>Best Practice</strong>: For most workflows, use custom capture variables (via <code>capture:</code> field) instead of relying on these automatic output variables. This provides explicit naming and better readability.</p>
<h3 id="mapreduce-variables"><a class="header" href="#mapreduce-variables">MapReduce Variables</a></h3>
<p><strong>Map Phase Variables</strong> (available in <code>agent_template:</code> commands):</p>
<ul>
<li><code>${item}</code> - Current work item in map phase (scope: map phase only)</li>
<li><code>${item.value}</code> - Value of current item (for simple items)</li>
<li><code>${item.path}</code> - Path field of current item</li>
<li><code>${item.name}</code> - Name field of current item</li>
<li><code>${item.*}</code> - Access any item field using wildcard pattern (e.g., <code>${item.id}</code>, <code>${item.priority}</code>)</li>
<li><code>${item_index}</code> - Index of current item in the list</li>
<li><code>${item_total}</code> - Total number of items being processed</li>
<li><code>${map.key}</code> - Current map key</li>
<li><code>${worker.id}</code> - ID of the current worker agent</li>
</ul>
<p><strong>Reduce Phase Variables</strong> (available in <code>reduce:</code> commands):</p>
<ul>
<li><code>${map.total}</code> - Total items processed across all map agents</li>
<li><code>${map.successful}</code> - Number of successfully processed items</li>
<li><code>${map.failed}</code> - Number of failed items</li>
<li><code>${map.results}</code> - Aggregated results from all map agents (JSON array)</li>
</ul>
<p><strong>Note</strong>: <code>${item}</code> and related item variables are only available within the map phase. The aggregation variables (<code>${map.total}</code>, <code>${map.successful}</code>, <code>${map.failed}</code>, <code>${map.results}</code>) are only available in the reduce phase.</p>
<h3 id="merge-variables"><a class="header" href="#merge-variables">Merge Variables</a></h3>
<ul>
<li><code>${merge.worktree}</code> - Worktree name</li>
<li><code>${merge.source_branch}</code> - Source branch</li>
<li><code>${merge.target_branch}</code> - Target branch</li>
<li><code>${merge.session_id}</code> - Session ID</li>
</ul>
<h3 id="validation-variables"><a class="header" href="#validation-variables">Validation Variables</a></h3>
<ul>
<li><code>${validation.completion}</code> - Completion percentage</li>
<li><code>${validation.completion_percentage}</code> - Completion percentage (numeric)</li>
<li><code>${validation.implemented}</code> - List of implemented features</li>
<li><code>${validation.missing}</code> - Missing requirements</li>
<li><code>${validation.gaps}</code> - Gap details</li>
<li><code>${validation.status}</code> - Status (complete/incomplete/failed)</li>
</ul>
<h3 id="git-context-variables"><a class="header" href="#git-context-variables">Git Context Variables</a></h3>
<ul>
<li><code>${step.commits}</code> - Commits in current step (array of commit objects)</li>
<li><code>${workflow.commits}</code> - All workflow commits (array of commit objects)</li>
</ul>
<p><strong>Note</strong>: These are arrays of commit data. Use in foreach loops or access individual commits with array indexing. Each commit object contains fields like hash, message, timestamp, etc.</p>
<h3 id="legacy-variable-aliases"><a class="header" href="#legacy-variable-aliases">Legacy Variable Aliases</a></h3>
<p>These legacy aliases are supported for backward compatibility but should be replaced with modern equivalents:</p>
<ul>
<li><code>$ARG</code> / <code>$ARGUMENT</code> - Legacy aliases for <code>${item.value}</code> (available in WithArguments mode)</li>
<li><code>$FILE</code> / <code>$FILE_PATH</code> - Legacy aliases for <code>${item.path}</code> (available in WithFilePattern mode)</li>
</ul>
<p><strong>Note:</strong> Use the modern <code>${item.*}</code> syntax in new workflows instead of legacy aliases.</p>
<hr />
<h2 id="custom-variable-capture"><a class="header" href="#custom-variable-capture">Custom Variable Capture</a></h2>
<p>Custom capture variables allow you to save command output with explicit names for later use. This is the recommended approach for most workflows instead of relying on automatic output variables.</p>
<h3 id="basic-capture-examples"><a class="header" href="#basic-capture-examples">Basic Capture Examples</a></h3>
<pre><code class="language-yaml"># Capture to custom variable
- shell: "ls -la | wc -l"
  capture: "file_count"
  capture_format: number  # Default: string

# Use in next command
- shell: "echo 'Found ${file_count} files'"
</code></pre>
<h3 id="capture-formats"><a class="header" href="#capture-formats">Capture Formats</a></h3>
<p>The <code>capture_format</code> field determines how output is parsed and stored:</p>
<pre><code class="language-yaml"># String format (default) - stores raw output
- shell: "echo 'Hello World'"
  capture: "greeting"
  capture_format: string
# Access: ${greeting} → "Hello World"

# Number format - parses numeric output
- shell: "echo 42"
  capture: "answer"
  capture_format: number
# Access: ${answer} → 42 (as number, not string)

# Boolean format - converts to true/false
- shell: "[ -f README.md ] &amp;&amp; echo true || echo false"
  capture: "has_readme"
  capture_format: boolean
# Access: ${has_readme} → true or false

# JSON format - parses JSON output
- shell: "echo '{\"name\": \"project\", \"version\": \"1.0\"}'"
  capture: "package_info"
  capture_format: json
# Access nested fields: ${package_info.name} → "project"
# Access nested fields: ${package_info.version} → "1.0"

# Lines format - splits into array by newlines
- shell: "ls *.md"
  capture: "markdown_files"
  capture_format: lines
# Access: ${markdown_files} → array of filenames
</code></pre>
<h3 id="capture-streams"><a class="header" href="#capture-streams">Capture Streams</a></h3>
<p>Control which output streams to capture (useful for detailed command analysis):</p>
<pre><code class="language-yaml"># Capture specific streams
- shell: "cargo test 2&gt;&amp;1"
  capture: "test_results"
  capture_streams:
    stdout: true      # Default: true
    stderr: true      # Default: false
    exit_code: true   # Default: true
    success: true     # Default: true
    duration: true    # Default: true

# Access captured stream data
- shell: "echo 'Exit code: ${test_results.exit_code}'"
- shell: "echo 'Success: ${test_results.success}'"
- shell: "echo 'Duration: ${test_results.duration}s'"
</code></pre>
<p><strong>Default Behavior</strong>: By default, <code>stdout</code>, <code>exit_code</code>, <code>success</code>, and <code>duration</code> are captured (all <code>true</code>). Set <code>stderr: true</code> to also capture error output.</p>
<h3 id="nested-json-field-access"><a class="header" href="#nested-json-field-access">Nested JSON Field Access</a></h3>
<p>For JSON-formatted captures, use dot notation to access nested fields:</p>
<pre><code class="language-yaml"># Example: API response with nested data
- shell: "curl -s https://api.example.com/user/123"
  capture: "user"
  capture_format: json

# Access nested fields with dot notation
- shell: "echo 'Name: ${user.profile.name}'"
- shell: "echo 'Email: ${user.contact.email}'"
- shell: "echo 'City: ${user.address.city}'"
</code></pre>
<h3 id="variable-scope-and-precedence"><a class="header" href="#variable-scope-and-precedence">Variable Scope and Precedence</a></h3>
<p>Variables follow a parent/child scope hierarchy:</p>
<ol>
<li><strong>Local Scope</strong>: Variables defined in the current command block</li>
<li><strong>Parent Scope</strong>: Variables from enclosing blocks (foreach, map phase, etc.)</li>
<li><strong>Built-in Variables</strong>: Standard workflow context variables</li>
</ol>
<p><strong>Precedence</strong>: Local variables override parent scope variables, which override built-in variables.</p>
<pre><code class="language-yaml"># Parent scope
- shell: "echo 'outer'"
  capture: "message"

# Child scope (foreach creates new scope)
- foreach:
    items: [1, 2, 3]
    commands:
      # This creates a local 'message' that shadows parent
      - shell: "echo 'inner-${item}'"
        capture: "message"
      - shell: "echo ${message}"  # Uses local 'message'

# After foreach, parent 'message' is still accessible
- shell: "echo ${message}"  # Uses parent 'message' → "outer"
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="environment-configuration-1"><a class="header" href="#environment-configuration-1">Environment Configuration</a></h1>
<p>Prodigy provides flexible environment configuration for workflows, allowing you to manage environment variables, secrets, profiles, and step-specific settings. This chapter explains the user-facing configuration options available in workflow YAML files.</p>
<h2 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h2>
<p>Prodigy uses a two-layer architecture for environment management:</p>
<ol>
<li><strong>WorkflowConfig</strong>: User-facing YAML configuration with <code>env</code>, <code>secrets</code>, <code>profiles</code>, and <code>env_files</code> fields</li>
<li><strong>EnvironmentConfig</strong>: Internal runtime configuration that extends workflow config with additional features</li>
</ol>
<p>This chapter documents the user-facing WorkflowConfig layer - what you write in your workflow YAML files.</p>
<p><strong>Note on Internal Features:</strong> The <code>EnvironmentConfig</code> runtime layer includes a <code>StepEnvironment</code> struct with fields like <code>env</code>, <code>working_dir</code>, <code>clear_env</code>, and <code>temporary</code>. These are internal implementation details not exposed in <code>WorkflowStepCommand</code> YAML syntax. Per-command environment changes must use shell syntax (e.g., <code>ENV=value command</code>).</p>
<hr />
<h2 id="global-environment-variables-1"><a class="header" href="#global-environment-variables-1">Global Environment Variables</a></h2>
<p>Define static environment variables that apply to all commands in your workflow:</p>
<pre><code class="language-yaml"># Global environment variables (static strings only)
env:
  NODE_ENV: production
  PORT: "3000"
  API_URL: https://api.example.com
  DEBUG: "false"

commands:
  - shell: "echo $NODE_ENV"  # Uses global environment
</code></pre>
<p><strong>Important:</strong> The <code>env</code> field at the workflow level only supports static string values. Dynamic or conditional environment variables are handled internally by the runtime but are not directly exposed in workflow YAML.</p>
<p><strong>Environment Inheritance:</strong> Parent process environment variables are always inherited by default. All global environment variables are merged with the parent environment.</p>
<hr />
<h2 id="mapreduce-environment-variables"><a class="header" href="#mapreduce-environment-variables">MapReduce Environment Variables</a></h2>
<p>In MapReduce workflows, environment variables provide powerful parameterization across all phases (setup, map, reduce, and merge). This enables workflows to be reusable across different projects and configurations.</p>
<h3 id="defining-environment-variables-in-mapreduce"><a class="header" href="#defining-environment-variables-in-mapreduce">Defining Environment Variables in MapReduce</a></h3>
<p>Environment variables for MapReduce workflows follow the same global <code>env</code> field structure:</p>
<pre><code class="language-yaml">name: mapreduce-workflow
mode: mapreduce

env:
  # Plain variables for parameterization
  PROJECT_NAME: "prodigy"
  PROJECT_CONFIG: "prodigy.yml"
  FEATURES_PATH: "specs/"
  OUTPUT_DIR: "results"

  # Workflow-specific settings
  MAX_RETRIES: "3"
  TIMEOUT_SECONDS: "300"

setup:
  - shell: "echo Starting $PROJECT_NAME workflow"
  - shell: "mkdir -p $OUTPUT_DIR"

map:
  input: "${FEATURES_PATH}/items.json"
  agent_template:
    - claude: "/process '${item.name}' --config $PROJECT_CONFIG"
    - shell: "test -f $PROJECT_NAME/${item.path}"

reduce:
  - shell: "echo Processed ${map.total} items for $PROJECT_NAME"
  - shell: "cp results.json $OUTPUT_DIR/"

merge:
  commands:
    - shell: "echo Merging $PROJECT_NAME changes"
</code></pre>
<h3 id="variable-interpolation-in-mapreduce"><a class="header" href="#variable-interpolation-in-mapreduce">Variable Interpolation in MapReduce</a></h3>
<p>MapReduce workflows support two interpolation syntaxes:</p>
<ol>
<li><strong><code>$VAR</code></strong> - Shell-style variable reference</li>
<li><strong><code>${VAR}</code></strong> - Bracketed reference (recommended for clarity)</li>
</ol>
<p>Both syntaxes work throughout all workflow phases:</p>
<pre><code class="language-yaml">env:
  PROJECT_NAME: "myproject"
  CONFIG_FILE: "config.yml"

setup:
  - shell: "echo $PROJECT_NAME"           # Shell-style
  - shell: "echo ${PROJECT_NAME}"         # Bracketed
  - shell: "test -f ${CONFIG_FILE}"       # Recommended in paths

map:
  agent_template:
    - claude: "/analyze '${item}' --project $PROJECT_NAME"
</code></pre>
<h3 id="environment-variables-in-all-mapreduce-phases"><a class="header" href="#environment-variables-in-all-mapreduce-phases">Environment Variables in All MapReduce Phases</a></h3>
<h4 id="setup-phase"><a class="header" href="#setup-phase">Setup Phase</a></h4>
<p>Environment variables are available for initialization:</p>
<pre><code class="language-yaml">env:
  WORKSPACE_DIR: "/tmp/workspace"
  INPUT_SOURCE: "https://api.example.com/data"

setup:
  - shell: "mkdir -p $WORKSPACE_DIR"
  - shell: "curl $INPUT_SOURCE -o items.json"
  - shell: "echo Setup complete for ${WORKSPACE_DIR}"
</code></pre>
<h4 id="map-phase"><a class="header" href="#map-phase">Map Phase</a></h4>
<p>Variables are available in agent templates:</p>
<pre><code class="language-yaml">env:
  PROJECT_ROOT: "/path/to/project"
  CONFIG_PATH: "config/settings.yml"

map:
  agent_template:
    - claude: "/analyze ${item.file} --config $CONFIG_PATH"
    - shell: "test -f $PROJECT_ROOT/${item.file}"
    - shell: "cp ${item.file} $OUTPUT_DIR/"
</code></pre>
<h4 id="reduce-phase"><a class="header" href="#reduce-phase">Reduce Phase</a></h4>
<p>Variables work in aggregation commands:</p>
<pre><code class="language-yaml">env:
  PROJECT_NAME: "myproject"
  REPORT_DIR: "reports"

reduce:
  - claude: "/summarize ${map.results} --project $PROJECT_NAME"
  - shell: "mkdir -p $REPORT_DIR"
  - shell: "cp summary.json $REPORT_DIR/${PROJECT_NAME}-summary.json"
</code></pre>
<h4 id="merge-phase"><a class="header" href="#merge-phase">Merge Phase</a></h4>
<p>Variables are available during merge operations:</p>
<pre><code class="language-yaml">env:
  PROJECT_NAME: "myproject"
  NOTIFY_WEBHOOK: "https://hooks.example.com/notify"

merge:
  commands:
    - shell: "echo Merging $PROJECT_NAME changes"
    - claude: "/validate-merge --branch ${merge.source_branch}"
    - shell: "curl -X POST $NOTIFY_WEBHOOK -d 'project=$PROJECT_NAME'"
</code></pre>
<h3 id="secrets-in-mapreduce"><a class="header" href="#secrets-in-mapreduce">Secrets in MapReduce</a></h3>
<p>Sensitive data can be marked as secrets to enable automatic masking:</p>
<pre><code class="language-yaml">env:
  PROJECT_NAME: "myproject"

secrets:
  API_TOKEN:
    provider: env
    key: "GITHUB_TOKEN"

  WEBHOOK_SECRET:
    provider: file
    key: "~/.secrets/webhook.key"

setup:
  - shell: "curl -H 'Authorization: Bearer $API_TOKEN' https://api.github.com/repos"

map:
  agent_template:
    - shell: "curl -X POST $WEBHOOK_URL -H 'X-Secret: $WEBHOOK_SECRET'"
</code></pre>
<p>Secrets are automatically masked in:</p>
<ul>
<li>Command output logs</li>
<li>Error messages</li>
<li>Event logs</li>
<li>Checkpoint files</li>
</ul>
<h3 id="profile-support-in-mapreduce"><a class="header" href="#profile-support-in-mapreduce">Profile Support in MapReduce</a></h3>
<p>Profiles enable different configurations for different environments:</p>
<pre><code class="language-yaml">env:
  PROJECT_NAME: "myproject"

profiles:
  development:
    description: "Development environment"
    API_URL: "http://localhost:3000"
    DEBUG: "true"
    TIMEOUT_SECONDS: "60"

  production:
    description: "Production environment"
    API_URL: "https://api.example.com"
    DEBUG: "false"
    TIMEOUT_SECONDS: "300"

map:
  agent_template:
    - shell: "curl $API_URL/data"
    - shell: "timeout ${TIMEOUT_SECONDS}s ./process.sh"
</code></pre>
<p>Activate a profile:</p>
<pre><code class="language-bash">prodigy run workflow.yml --profile production
</code></pre>
<h3 id="reusable-workflows-with-environment-variables"><a class="header" href="#reusable-workflows-with-environment-variables">Reusable Workflows with Environment Variables</a></h3>
<p>Environment variables enable the same workflow to work for different projects:</p>
<pre><code class="language-yaml"># This workflow works for both Prodigy and Debtmap
name: check-book-docs-drift
mode: mapreduce

env:
  # Override these when running the workflow
  PROJECT_NAME: "prodigy"              # or "debtmap"
  PROJECT_CONFIG: "prodigy.yml"        # or "debtmap.yml"
  FEATURES_PATH: "specs/"              # or "features/"

setup:
  - shell: "echo Checking $PROJECT_NAME documentation"
  - shell: "./${PROJECT_NAME} generate-book-items --output items.json"

map:
  input: "items.json"
  agent_template:
    - claude: "/check-drift '${item}' --config $PROJECT_CONFIG"
    - shell: "git diff --exit-code ${item.doc_path}"

reduce:
  - claude: "/summarize-drift ${map.results} --project $PROJECT_NAME"
</code></pre>
<p>Run for different projects:</p>
<pre><code class="language-bash"># For Prodigy
prodigy run workflow.yml

# For Debtmap
env PROJECT_NAME=debtmap PROJECT_CONFIG=debtmap.yml FEATURES_PATH=features/ \
  prodigy run workflow.yml
</code></pre>
<h3 id="best-practices-for-mapreduce-environment-variables"><a class="header" href="#best-practices-for-mapreduce-environment-variables">Best Practices for MapReduce Environment Variables</a></h3>
<ol>
<li>
<p><strong>Parameterize project-specific values</strong>:</p>
<pre><code class="language-yaml">env:
  PROJECT_NAME: "myproject"
  PROJECT_ROOT: "/workspace"
  CONFIG_FILE: "config.yml"
</code></pre>
</li>
<li>
<p><strong>Use consistent naming</strong>:</p>
<ul>
<li>Use UPPER_CASE for environment variables</li>
<li>Use descriptive names (PROJECT_NAME not PN)</li>
<li>Group related variables with prefixes (AWS_<em>, DB_</em>)</li>
</ul>
</li>
<li>
<p><strong>Document variables</strong>:</p>
<pre><code class="language-yaml">env:
  # Project identifier used in logs and reports
  PROJECT_NAME: "prodigy"

  # Path to project configuration file
  PROJECT_CONFIG: "prodigy.yml"

  # Maximum concurrent agents (tune based on resources)
  MAX_PARALLEL: "10"
</code></pre>
</li>
<li>
<p><strong>Use secrets for sensitive data</strong>:</p>
<pre><code class="language-yaml">secrets:
  GITHUB_TOKEN:
    provider: env
    key: "GH_TOKEN"
</code></pre>
</li>
<li>
<p><strong>Prefer <code>${VAR}</code> syntax</strong>:</p>
<pre><code class="language-yaml"># Good - explicit and safe
- shell: "test -f ${CONFIG_PATH}"

# Risky - may fail with special characters
- shell: "test -f $CONFIG_PATH"
</code></pre>
</li>
</ol>
<hr />
<h2 id="environment-files-1"><a class="header" href="#environment-files-1">Environment Files</a></h2>
<p>Load environment variables from <code>.env</code> files:</p>
<pre><code class="language-yaml"># Environment files to load
env_files:
  - .env
  - .env.local
  - config/.env.production

commands:
  - shell: "echo $DATABASE_URL"
</code></pre>
<p><strong>Environment File Format:</strong></p>
<p>Environment files use the standard <code>.env</code> format with <code>KEY=value</code> pairs:</p>
<pre><code class="language-bash"># .env file example
DATABASE_URL=postgresql://localhost:5432/mydb
REDIS_HOST=localhost
REDIS_PORT=6379

# Comments are supported
API_KEY=secret-key-here

# Multi-line values use quotes
PRIVATE_KEY="-----BEGIN PRIVATE KEY-----
MIIEvQIBADANBg...
-----END PRIVATE KEY-----"
</code></pre>
<p><strong>Loading Order and Precedence:</strong></p>
<ol>
<li>Files are loaded in the order specified in <code>env_files</code></li>
<li>Later files override earlier files</li>
<li>Step-level <code>env</code> overrides environment files</li>
<li>Global <code>env</code> overrides environment files</li>
</ol>
<hr />
<h2 id="secrets-management"><a class="header" href="#secrets-management">Secrets Management</a></h2>
<p>Store sensitive values securely using secret providers:</p>
<pre><code class="language-yaml">secrets:
  # Provider-based secrets (recommended)
  AWS_SECRET:
    provider: aws
    key: "my-app/api-key"

  VAULT_SECRET:
    provider: vault
    key: "secret/data/myapp"
    version: "v2"  # Optional version

  # Environment variable reference
  API_KEY:
    provider: env
    key: "SECRET_API_KEY"

  # File-based secret
  DB_PASSWORD:
    provider: file
    key: "~/.secrets/db.pass"

  # Custom provider (extensible)
  CUSTOM_SECRET:
    provider:
      custom: "my-custom-provider"
    key: "secret-id"

commands:
  - shell: "echo $API_KEY"  # Secrets are available as environment variables
</code></pre>
<p><strong>Supported Secret Providers:</strong></p>
<ul>
<li><code>env</code> - Reference another environment variable</li>
<li><code>file</code> - Read secret from a file</li>
<li><code>vault</code> - HashiCorp Vault integration (requires Vault setup)</li>
<li><code>aws</code> - AWS Secrets Manager (requires AWS credentials)</li>
<li><code>custom</code> - Custom provider (extensible for your own secret backends)</li>
</ul>
<p><strong>Security Notes:</strong></p>
<ul>
<li>Secrets are masked in logs and output</li>
<li>Secret values are only resolved at runtime</li>
<li>Use secrets for API keys, passwords, tokens, and other sensitive data</li>
</ul>
<hr />
<h2 id="environment-profiles-1"><a class="header" href="#environment-profiles-1">Environment Profiles</a></h2>
<p>Define named environment configurations for different contexts:</p>
<pre><code class="language-yaml"># Define profiles with environment variables
profiles:
  development:
    description: "Development environment with debug enabled"
    NODE_ENV: development
    DEBUG: "true"
    API_URL: http://localhost:3000

  production:
    description: "Production environment configuration"
    NODE_ENV: production
    DEBUG: "false"
    API_URL: https://api.example.com

# Global environment still applies
env:
  APP_NAME: "my-app"

commands:
  - shell: "npm run build"
</code></pre>
<p><strong>Profile Structure:</strong></p>
<p>Profiles use a flat structure where environment variables are defined directly at the profile level (not nested under an <code>env:</code> key). The <code>description</code> field is optional and helps document the profile’s purpose.</p>
<pre><code class="language-yaml">profiles:
  staging:
    description: "Staging environment"  # Optional
    NODE_ENV: staging                   # Direct key-value pairs
    API_URL: https://staging.api.com
    DEBUG: "true"
</code></pre>
<p><strong>Note:</strong> Profile activation is managed internally by the runtime environment manager. The selection mechanism is not currently exposed in WorkflowConfig YAML. Profiles are defined for future use and internal runtime configuration.</p>
<hr />
<h2 id="per-command-environment-overrides"><a class="header" href="#per-command-environment-overrides">Per-Command Environment Overrides</a></h2>
<p>While WorkflowStepCommand does not support a dedicated <code>env</code> field, you can override environment variables for individual commands using shell syntax:</p>
<pre><code class="language-yaml">env:
  RUST_LOG: info
  API_URL: "https://api.example.com"

# Steps go directly in the workflow
- shell: "cargo run"  # Uses RUST_LOG=info from global env

# Override environment for this command only using shell syntax
- shell: "RUST_LOG=debug cargo run --verbose"

# Change directory and set environment in shell
- shell: "cd frontend &amp;&amp; PATH=./node_modules/.bin:$PATH npm run build"
</code></pre>
<p><strong>Shell-based Environment Techniques:</strong></p>
<ul>
<li><strong>Single variable override:</strong> <code>ENV_VAR=value command</code></li>
<li><strong>Multiple variables:</strong> <code>VAR1=value1 VAR2=value2 command</code></li>
<li><strong>Change directory:</strong> <code>cd path &amp;&amp; command</code></li>
<li><strong>Combine both:</strong> <code>cd path &amp;&amp; ENV_VAR=value command</code></li>
</ul>
<p><strong>Note:</strong> A <code>StepEnvironment</code> struct exists in the internal runtime (<code>EnvironmentConfig</code>), but it is not currently exposed in the WorkflowStepCommand YAML syntax. All per-command environment changes must use shell syntax as shown above.</p>
<hr />
<h2 id="environment-precedence"><a class="header" href="#environment-precedence">Environment Precedence</a></h2>
<p>Environment variables are resolved in the following order (highest to lowest precedence):</p>
<ol>
<li><strong>Active profile</strong> - If a profile is activated (internal runtime feature)</li>
<li><strong>Global <code>env</code></strong> - Defined at workflow level in WorkflowConfig</li>
<li><strong>Environment files</strong> - Loaded from <code>env_files</code> (in order)</li>
<li><strong>Parent environment</strong> - Always inherited from the parent process</li>
</ol>
<p>Example demonstrating precedence:</p>
<pre><code class="language-yaml"># Parent environment: NODE_ENV=local

env_files:
  - .env  # Contains: NODE_ENV=development

env:
  NODE_ENV: production  # Overrides .env file

profiles:
  test:
    NODE_ENV: test  # Would override global env if profile activation were exposed
    description: "Test environment profile"

# Steps go directly in the workflow
- shell: "echo $NODE_ENV"  # Prints: production (from global env)

# Override using shell syntax
- shell: "NODE_ENV=staging echo $NODE_ENV"  # Prints: staging
</code></pre>
<p><strong>Note:</strong> Profile activation is currently managed internally and not exposed in WorkflowConfig YAML.</p>
<hr />
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="1-use-environment-files-for-configuration"><a class="header" href="#1-use-environment-files-for-configuration">1. Use Environment Files for Configuration</a></h3>
<p>Store configuration in <code>.env</code> files instead of hardcoding in YAML:</p>
<pre><code class="language-yaml"># Good: Load from files
env_files:
  - .env
  - .env.${ENVIRONMENT}

# Avoid: Hardcoding sensitive values
env:
  API_KEY: "hardcoded-key-here"  # Don't do this!
</code></pre>
<h3 id="2-use-secrets-for-sensitive-data"><a class="header" href="#2-use-secrets-for-sensitive-data">2. Use Secrets for Sensitive Data</a></h3>
<p>Always use the <code>secrets</code> field for sensitive information:</p>
<pre><code class="language-yaml"># Good: Use secrets provider
secrets:
  DATABASE_PASSWORD:
    provider: vault
    key: "db/password"

# Bad: Sensitive data in plain env
env:
  DATABASE_PASSWORD: "my-password"  # Don't do this!
</code></pre>
<h3 id="3-leverage-profiles-for-environments"><a class="header" href="#3-leverage-profiles-for-environments">3. Leverage Profiles for Environments</a></h3>
<p>Define profiles for different deployment environments:</p>
<pre><code class="language-yaml">profiles:
  development:
    NODE_ENV: development
    LOG_LEVEL: debug
    API_URL: http://localhost:3000

  production:
    NODE_ENV: production
    LOG_LEVEL: error
    API_URL: https://api.example.com
</code></pre>
<h3 id="4-use-shell-syntax-for-command-specific-overrides"><a class="header" href="#4-use-shell-syntax-for-command-specific-overrides">4. Use Shell Syntax for Command-Specific Overrides</a></h3>
<p>Override global settings for specific commands using shell environment syntax:</p>
<pre><code class="language-yaml">env:
  RUST_LOG: info

# Steps go directly in the workflow
# Most commands use info level
- shell: "cargo run"

# Override for this specific command using shell syntax
- shell: "RUST_LOG=debug cargo run --verbose"
</code></pre>
<h3 id="5-document-your-environment-variables"><a class="header" href="#5-document-your-environment-variables">5. Document Your Environment Variables</a></h3>
<p>Add comments to explain environment variables:</p>
<pre><code class="language-yaml">env:
  # Number of worker threads (adjust based on CPU cores)
  WORKER_COUNT: "4"

  # API rate limit (requests per minute)
  RATE_LIMIT: "1000"

  # Feature flags
  ENABLE_BETA_FEATURES: "false"
</code></pre>
<hr />
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="multi-environment-workflows"><a class="header" href="#multi-environment-workflows">Multi-Environment Workflows</a></h3>
<pre><code class="language-yaml"># Load environment-specific configuration
env_files:
  - .env.${ENVIRONMENT}

env:
  APP_NAME: "my-app"

commands:
  - shell: "npm run deploy"
</code></pre>
<h3 id="secrets-with-fallbacks"><a class="header" href="#secrets-with-fallbacks">Secrets with Fallbacks</a></h3>
<pre><code class="language-yaml">secrets:
  # Try Vault first, fall back to environment variable
  API_KEY:
    provider: vault
    key: "api/key"

env:
  # Fallback for local development
  API_KEY: "${API_KEY:-default-key}"
</code></pre>
<h3 id="build-matrix-with-profiles"><a class="header" href="#build-matrix-with-profiles">Build Matrix with Profiles</a></h3>
<pre><code class="language-yaml">profiles:
  debug:
    CARGO_PROFILE: debug
    RUST_BACKTRACE: "1"

  release:
    CARGO_PROFILE: release
    RUST_BACKTRACE: "0"

commands:
  - shell: "cargo build --profile ${CARGO_PROFILE}"
</code></pre>
<h3 id="temporary-environment-changes"><a class="header" href="#temporary-environment-changes">Temporary Environment Changes</a></h3>
<pre><code class="language-yaml"># Steps go directly in the workflow
# Set PATH for this command only using shell syntax
- shell: "cd frontend &amp;&amp; PATH=./node_modules/.bin:$PATH ./node_modules/.bin/webpack"

# PATH is back to normal for subsequent commands
- shell: "echo $PATH"
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h1>
<p>This chapter covers advanced workflow features for building sophisticated automation pipelines. These features enable conditional execution, parallel processing, validation, and complex control flow.</p>
<hr />
<h2 id="conditional-execution-1"><a class="header" href="#conditional-execution-1">Conditional Execution</a></h2>
<p>Control when commands execute based on expressions or previous command results.</p>
<h3 id="expression-based-conditions"><a class="header" href="#expression-based-conditions">Expression-Based Conditions</a></h3>
<p>Use the <code>when</code> field to conditionally execute commands based on variable values:</p>
<pre><code class="language-yaml"># Execute only when variable is true
- shell: "cargo build --release"
  when: "${tests_passed}"

# Execute based on complex expression
- shell: "deploy.sh"
  when: "${environment == 'production' &amp;&amp; tests_passed}"
</code></pre>
<h3 id="on-success-handlers"><a class="header" href="#on-success-handlers">On Success Handlers</a></h3>
<p>Execute follow-up commands when a command succeeds:</p>
<pre><code class="language-yaml">- shell: "cargo test"
  on_success:
    shell: "cargo bench"
</code></pre>
<h3 id="on-failure-handlers"><a class="header" href="#on-failure-handlers">On Failure Handlers</a></h3>
<p>Handle failures with automatic remediation:</p>
<pre><code class="language-yaml">- shell: "cargo clippy"
  on_failure:
    claude: "/fix-warnings"
    max_attempts: 3
    fail_workflow: false
</code></pre>
<p>The <code>on_failure</code> configuration supports:</p>
<ul>
<li><code>max_attempts</code>: Maximum retry attempts (default: 1)</li>
<li><code>fail_workflow</code>: Whether to fail entire workflow on final failure (default: true)</li>
</ul>
<h3 id="nested-conditionals"><a class="header" href="#nested-conditionals">Nested Conditionals</a></h3>
<p>Chain multiple levels of conditional execution:</p>
<pre><code class="language-yaml">- shell: "cargo check"
  on_success:
    shell: "cargo build --release"
    on_success:
      shell: "cargo test --release"
      on_failure:
        claude: "/debug-failures '${shell.output}'"
</code></pre>
<hr />
<h2 id="output-capture-and-variable-management"><a class="header" href="#output-capture-and-variable-management">Output Capture and Variable Management</a></h2>
<p>Capture command output in different formats for use in subsequent steps.</p>
<h3 id="capture-variable"><a class="header" href="#capture-variable">Capture Variable</a></h3>
<p>Capture output to a named variable using the <code>capture_output</code> field:</p>
<pre><code class="language-yaml"># Capture as string (backward compatible)
- shell: "git rev-parse HEAD"
  capture_output: "commit_hash"

# Reference in later steps
- shell: "echo 'Commit: ${commit_hash}'"
</code></pre>
<h3 id="capture-formats-1"><a class="header" href="#capture-formats-1">Capture Formats</a></h3>
<p>Control how output is parsed with <code>capture_format</code>:</p>
<pre><code class="language-yaml"># String (default) - trimmed output as single string
- shell: "git rev-parse HEAD"
  capture_output: "commit_hash"
  capture_format: "string"

# Number - parse output as number
- shell: "wc -l &lt; file.txt"
  capture_output: "line_count"
  capture_format: "number"

# JSON - parse output as JSON object
- shell: "cargo metadata --format-version 1"
  capture_output: "metadata"
  capture_format: "json"

# Lines - split output into array of lines
- shell: "find . -name '*.rs'"
  capture_output: "rust_files"
  capture_format: "lines"

# Boolean - parse "true"/"false" as boolean
- shell: "test -f README.md &amp;&amp; echo true || echo false"
  capture_output: "has_readme"
  capture_format: "boolean"
</code></pre>
<h3 id="stream-capture-control"><a class="header" href="#stream-capture-control">Stream Capture Control</a></h3>
<p>Control which streams to capture using <code>capture_streams</code>:</p>
<pre><code class="language-yaml"># Capture only stdout (default)
- shell: "cargo build"
  capture_output: "build_log"
  capture_streams: "stdout"

# Capture only stderr
- shell: "cargo test"
  capture_output: "errors"
  capture_streams: "stderr"

# Capture both streams
- shell: "npm install"
  capture_output: "full_output"
  capture_streams: "both"
</code></pre>
<h3 id="output-file-redirection"><a class="header" href="#output-file-redirection">Output File Redirection</a></h3>
<p>Write command output directly to a file:</p>
<pre><code class="language-yaml"># Redirect output to file
- shell: "cargo test --verbose"
  output_file: "test-results.txt"

# File is written to working directory
# Can be combined with capture_output to save and use output
</code></pre>
<hr />
<h2 id="step-identification"><a class="header" href="#step-identification">Step Identification</a></h2>
<p>Assign unique IDs to steps for referencing their outputs:</p>
<pre><code class="language-yaml">- shell: "cargo test"
  id: "test-step"
  capture_output: "test_results"

# Reference step output by ID
- shell: "echo 'Tests: ${test-step.output}'"
</code></pre>
<hr />
<h2 id="timeout-configuration"><a class="header" href="#timeout-configuration">Timeout Configuration</a></h2>
<p>Set execution timeouts at the command level:</p>
<pre><code class="language-yaml"># Command-level timeout (in seconds)
- shell: "cargo bench"
  timeout: 600  # 10 minutes

# Timeout for long-running operations
- claude: "/analyze-codebase"
  timeout: 1800  # 30 minutes
</code></pre>
<p><strong>Note</strong>: Timeouts are only supported at the individual command level, not for MapReduce agents.</p>
<hr />
<h2 id="implementation-validation"><a class="header" href="#implementation-validation">Implementation Validation</a></h2>
<p>Validate that implementations meet requirements using the <code>validate</code> field.</p>
<h3 id="basic-validation"><a class="header" href="#basic-validation">Basic Validation</a></h3>
<p>Run validation commands after a step completes:</p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    shell: "cargo test"
    threshold: 100  # Require 100% completion
</code></pre>
<h3 id="validation-with-claude"><a class="header" href="#validation-with-claude">Validation with Claude</a></h3>
<p>Use Claude to validate implementation quality:</p>
<pre><code class="language-yaml">- shell: "generate-code.sh"
  validate:
    claude: "/verify-implementation"
    threshold: 95
</code></pre>
<h3 id="multi-step-validation"><a class="header" href="#multi-step-validation">Multi-Step Validation</a></h3>
<p>Run multiple validation commands in sequence:</p>
<pre><code class="language-yaml">- claude: "/refactor"
  validate:
    commands:
      - shell: "cargo test"
      - shell: "cargo clippy"
      - shell: "cargo fmt --check"
    threshold: 100
</code></pre>
<h3 id="validation-with-result-files"><a class="header" href="#validation-with-result-files">Validation with Result Files</a></h3>
<p>Read validation results from a file instead of stdout:</p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    shell: "run-validator.sh"
    result_file: "validation-results.json"
    threshold: 95
</code></pre>
<h3 id="handling-incomplete-implementations"><a class="header" href="#handling-incomplete-implementations">Handling Incomplete Implementations</a></h3>
<p>Automatically remediate when validation fails:</p>
<pre><code class="language-yaml">- claude: "/implement-spec"
  validate:
    shell: "check-completeness.sh"
    threshold: 100
    on_incomplete:
      claude: "/fill-gaps"
      max_attempts: 3
      fail_workflow: true
</code></pre>
<p>The <code>on_incomplete</code> configuration supports:</p>
<ul>
<li><code>claude</code>: Claude command to execute for gap-filling</li>
<li><code>shell</code>: Shell command to execute for gap-filling</li>
<li><code>commands</code>: Array of commands to execute</li>
<li><code>max_attempts</code>: Maximum remediation attempts (default: 1)</li>
<li><code>fail_workflow</code>: Whether to fail workflow if remediation fails (default: true)</li>
<li><code>commit_required</code>: Whether remediation command should create a commit (default: false)</li>
</ul>
<hr />
<h2 id="parallel-iteration-with-foreach"><a class="header" href="#parallel-iteration-with-foreach">Parallel Iteration with Foreach</a></h2>
<p>Process multiple items in parallel using the <code>foreach</code> command.</p>
<h3 id="basic-foreach"><a class="header" href="#basic-foreach">Basic Foreach</a></h3>
<p>Iterate over a list of items:</p>
<pre><code class="language-yaml">- foreach:
    foreach: ["a", "b", "c"]
    do:
      - shell: "process ${item}"
</code></pre>
<h3 id="dynamic-item-lists"><a class="header" href="#dynamic-item-lists">Dynamic Item Lists</a></h3>
<p>Generate items from a command:</p>
<pre><code class="language-yaml">- foreach:
    foreach: "find . -name '*.rs'"
    do:
      - shell: "rustfmt ${item}"
</code></pre>
<h3 id="parallel-execution"><a class="header" href="#parallel-execution">Parallel Execution</a></h3>
<p>Control parallelism with the <code>parallel</code> field:</p>
<pre><code class="language-yaml">- foreach:
    foreach: "ls *.txt"
    parallel: 5  # Process 5 items concurrently
    do:
      - shell: "analyze ${item}"
</code></pre>
<h3 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h3>
<p>Continue processing remaining items on failure:</p>
<pre><code class="language-yaml">- foreach:
    foreach: ["test1", "test2", "test3"]
    continue_on_error: true
    do:
      - shell: "run-test ${item}"
</code></pre>
<h3 id="limiting-items"><a class="header" href="#limiting-items">Limiting Items</a></h3>
<p>Process only a subset of items:</p>
<pre><code class="language-yaml">- foreach:
    foreach: "find . -name '*.log'"
    max_items: 10  # Process first 10 items only
    do:
      - shell: "compress ${item}"
</code></pre>
<hr />
<h2 id="goal-seeking-operations"><a class="header" href="#goal-seeking-operations">Goal-Seeking Operations</a></h2>
<p>Iteratively refine implementations until they meet validation criteria.</p>
<h3 id="basic-goal-seek"><a class="header" href="#basic-goal-seek">Basic Goal Seek</a></h3>
<p>Define a goal and validation command:</p>
<pre><code class="language-yaml">- goal_seek:
    goal: "All tests pass"
    command: "cargo fix"
    validate: "cargo test"
    threshold: 100
</code></pre>
<p>The goal-seeking operation will:</p>
<ol>
<li>Run the command</li>
<li>Run the validation</li>
<li>Retry if validation threshold not met</li>
<li>Stop when goal achieved or max attempts reached</li>
</ol>
<h3 id="advanced-goal-seek-configuration"><a class="header" href="#advanced-goal-seek-configuration">Advanced Goal Seek Configuration</a></h3>
<p>Control iteration behavior:</p>
<pre><code class="language-yaml">- goal_seek:
    goal: "Code passes all quality checks"
    command: "auto-fix.sh"
    validate: "quality-check.sh"
    threshold: 95
    max_attempts: 5
    timeout: 300
    fail_on_incomplete: true
</code></pre>
<hr />
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="1-use-meaningful-variable-names"><a class="header" href="#1-use-meaningful-variable-names">1. Use Meaningful Variable Names</a></h3>
<pre><code class="language-yaml"># Good
- shell: "cargo test --format json"
  capture_output: "test_results"
  capture_format: "json"

# Avoid
- shell: "cargo test --format json"
  capture_output: "x"
</code></pre>
<h3 id="2-set-appropriate-timeouts"><a class="header" href="#2-set-appropriate-timeouts">2. Set Appropriate Timeouts</a></h3>
<pre><code class="language-yaml"># Set timeouts for potentially long-running operations
- shell: "npm install"
  timeout: 300

- claude: "/analyze-large-codebase"
  timeout: 1800
</code></pre>
<h3 id="3-handle-failures-gracefully"><a class="header" href="#3-handle-failures-gracefully">3. Handle Failures Gracefully</a></h3>
<pre><code class="language-yaml"># Provide automatic remediation
- shell: "cargo test"
  on_failure:
    claude: "/fix-failing-tests"
    max_attempts: 2
    fail_workflow: true
</code></pre>
<h3 id="4-validate-critical-changes"><a class="header" href="#4-validate-critical-changes">4. Validate Critical Changes</a></h3>
<pre><code class="language-yaml"># Ensure implementation meets requirements
- claude: "/implement-feature"
  validate:
    commands:
      - shell: "cargo test"
      - shell: "cargo clippy -- -D warnings"
    threshold: 100
    on_incomplete:
      claude: "/fix-issues"
      max_attempts: 3
</code></pre>
<h3 id="5-use-step-ids-for-complex-workflows"><a class="header" href="#5-use-step-ids-for-complex-workflows">5. Use Step IDs for Complex Workflows</a></h3>
<pre><code class="language-yaml"># Make output references explicit
- shell: "git diff --stat"
  id: "git-changes"
  capture_output: "diff"

- claude: "/review-changes '${git-changes.output}'"
  id: "code-review"
</code></pre>
<hr />
<h2 id="common-patterns-1"><a class="header" href="#common-patterns-1">Common Patterns</a></h2>
<h3 id="test-fix-verify-loop"><a class="header" href="#test-fix-verify-loop">Test-Fix-Verify Loop</a></h3>
<pre><code class="language-yaml">- shell: "cargo test"
  on_failure:
    claude: "/fix-tests"
    on_success:
      shell: "cargo test --release"
</code></pre>
<h3 id="parallel-processing-with-aggregation"><a class="header" href="#parallel-processing-with-aggregation">Parallel Processing with Aggregation</a></h3>
<pre><code class="language-yaml">- foreach:
    foreach: "find src -name '*.rs'"
    parallel: 10
    do:
      - shell: "analyze-file ${item}"
        capture_output: "analysis_${item}"

- shell: "aggregate-results.sh"
</code></pre>
<h3 id="gradual-quality-improvement"><a class="header" href="#gradual-quality-improvement">Gradual Quality Improvement</a></h3>
<pre><code class="language-yaml">- goal_seek:
    goal: "Code quality score above 90"
    command: "auto-improve.sh"
    validate: "quality-check.sh"
    threshold: 90
    max_attempts: 5
  on_success:
    shell: "git commit -m 'Improved code quality'"
</code></pre>
<h3 id="conditional-deployment"><a class="header" href="#conditional-deployment">Conditional Deployment</a></h3>
<pre><code class="language-yaml">- shell: "cargo test"
  capture_output: "test_results"
  capture_format: "json"

- shell: "deploy.sh"
  when: "${test_results.passed == test_results.total}"
  on_success:
    shell: "notify-success.sh"
  on_failure:
    shell: "rollback.sh"
</code></pre>
<h3 id="multi-stage-validation"><a class="header" href="#multi-stage-validation">Multi-Stage Validation</a></h3>
<pre><code class="language-yaml">- claude: "/implement-feature"
  validate:
    commands:
      - shell: "cargo build"
      - shell: "cargo test"
      - shell: "cargo clippy"
      - shell: "cargo fmt --check"
    threshold: 100
    on_incomplete:
      commands:
        - claude: "/fix-build-errors"
        - shell: "cargo fmt"
      max_attempts: 3
      fail_workflow: true
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h1>
<p>Prodigy provides comprehensive error handling at both the workflow level (for MapReduce jobs) and the command level (for individual workflow steps). This chapter covers the practical features available for handling failures gracefully.</p>
<hr />
<h2 id="command-level-error-handling"><a class="header" href="#command-level-error-handling">Command-Level Error Handling</a></h2>
<p>Command-level error handling allows you to specify what happens when a single workflow step fails. Use the <code>on_failure</code> configuration to define recovery, cleanup, or fallback strategies.</p>
<h3 id="simple-forms"><a class="header" href="#simple-forms">Simple Forms</a></h3>
<p>For basic error handling, use the simplest form that meets your needs:</p>
<pre><code class="language-yaml"># Ignore errors - don't fail the workflow
- shell: "optional-cleanup.sh"
  on_failure: true

# Single recovery command (shell or claude)
- shell: "npm install"
  on_failure: "npm cache clean --force"

- shell: "cargo clippy"
  on_failure: "/fix-warnings"

# Multiple recovery commands
- shell: "build-project"
  on_failure:
    - "cleanup-artifacts"
    - "/diagnose-build-errors"
    - "retry-build"
</code></pre>
<h3 id="advanced-configuration"><a class="header" href="#advanced-configuration">Advanced Configuration</a></h3>
<p>For more control over error handling behavior:</p>
<pre><code class="language-yaml">- shell: "cargo clippy"
  on_failure:
    claude: "/fix-warnings ${shell.output}"
    fail_workflow: false     # Continue workflow even if handler fails
    max_attempts: 3          # Retry original command up to 3 times (alias: max_retries)
</code></pre>
<p><strong>Available Fields:</strong></p>
<ul>
<li><code>shell</code> - Shell command to run on failure</li>
<li><code>claude</code> - Claude command to run on failure</li>
<li><code>fail_workflow</code> - Whether to fail the entire workflow (default: <code>false</code>)</li>
<li><code>max_attempts</code> - Maximum retry attempts for the original command (default: <code>1</code>, alias: <code>max_retries</code>)</li>
</ul>
<p><strong>Notes:</strong></p>
<ul>
<li>If <code>max_attempts &gt; 1</code>, Prodigy will retry the original command after running the failure handler</li>
<li>You can specify both <code>shell</code> and <code>claude</code> commands - they will execute in sequence</li>
<li>By default, having a handler means the workflow continues even if the step fails</li>
</ul>
<h3 id="detailed-handler-configuration"><a class="header" href="#detailed-handler-configuration">Detailed Handler Configuration</a></h3>
<p>For complex error handling scenarios with multiple commands and fine-grained control:</p>
<pre><code class="language-yaml">- shell: "deploy-production"
  on_failure:
    strategy: recovery        # Options: recovery, fallback, cleanup, custom
    timeout: 300             # Handler timeout in seconds
    handler_failure_fatal: true  # Fail workflow if handler fails
    fail_workflow: false     # Don't fail workflow if step fails
    commands:
      - shell: "rollback-deployment"
        continue_on_error: true
      - claude: "/analyze-deployment-failure"
      - shell: "notify-team"
</code></pre>
<p><strong>Handler Strategies:</strong></p>
<ul>
<li><code>recovery</code> - Try to fix the problem and retry (default)</li>
<li><code>fallback</code> - Use an alternative approach</li>
<li><code>cleanup</code> - Clean up resources</li>
<li><code>custom</code> - Custom handler logic</li>
</ul>
<p><strong>Handler Command Fields:</strong></p>
<ul>
<li><code>shell</code> or <code>claude</code> - The command to execute</li>
<li><code>continue_on_error</code> - Continue to next handler command even if this fails</li>
</ul>
<h3 id="success-handling"><a class="header" href="#success-handling">Success Handling</a></h3>
<p>Execute commands when a step succeeds:</p>
<pre><code class="language-yaml">- shell: "deploy-staging"
  on_success:
    shell: "notify-success"
    claude: "/update-deployment-docs"
</code></pre>
<h3 id="commit-requirements"><a class="header" href="#commit-requirements">Commit Requirements</a></h3>
<p>Specify whether a workflow step must create a git commit:</p>
<pre><code class="language-yaml">- claude: "/implement-feature"
  commit_required: true   # Fail if no commit is made
</code></pre>
<p>This is useful for ensuring that Claude commands that are expected to make code changes actually do so.</p>
<hr />
<h2 id="workflow-level-error-policy-mapreduce"><a class="header" href="#workflow-level-error-policy-mapreduce">Workflow-Level Error Policy (MapReduce)</a></h2>
<p>For MapReduce workflows, you can configure workflow-level error policies that control how the entire job responds to failures. This is separate from command-level error handling and only applies to MapReduce mode.</p>
<h3 id="basic-configuration"><a class="header" href="#basic-configuration">Basic Configuration</a></h3>
<pre><code class="language-yaml">name: process-items
mode: mapreduce

error_policy:
  # What to do when a work item fails
  on_item_failure: dlq      # Options: dlq, retry, skip, stop, custom:&lt;handler_name&gt;

  # Continue processing after failures
  continue_on_failure: true

  # Stop after this many failures
  max_failures: 10

  # Stop if failure rate exceeds threshold (0.0 to 1.0)
  failure_threshold: 0.2    # Stop if 20% of items fail

  # How to report errors
  error_collection: aggregate  # Options: aggregate, immediate, batched
</code></pre>
<p><strong>Item Failure Actions:</strong></p>
<ul>
<li><code>dlq</code> - Send failed items to Dead Letter Queue for later retry (default)</li>
<li><code>retry</code> - Retry the item immediately with backoff (if retry_config is set)</li>
<li><code>skip</code> - Skip the failed item and continue</li>
<li><code>stop</code> - Stop the entire workflow on first failure</li>
<li><code>custom:&lt;name&gt;</code> - Use a custom failure handler (not yet implemented)</li>
</ul>
<p><strong>Error Collection Strategies:</strong></p>
<ul>
<li><code>aggregate</code> - Collect all errors and report at the end (default)</li>
<li><code>immediate</code> - Report errors as they occur</li>
<li><code>batched: {size: N}</code> - Report errors in batches of N items</li>
</ul>
<h3 id="circuit-breaker"><a class="header" href="#circuit-breaker">Circuit Breaker</a></h3>
<p>Prevent cascading failures by opening a circuit after consecutive failures:</p>
<pre><code class="language-yaml">error_policy:
  circuit_breaker:
    failure_threshold: 5      # Open circuit after 5 consecutive failures
    success_threshold: 2      # Close circuit after 2 successes
    timeout: 30s             # Time before attempting half-open state
    half_open_requests: 3    # Test requests in half-open state
</code></pre>
<p><strong>Note:</strong> Use duration format for timeout (e.g., <code>30s</code>, <code>1m</code>, <code>500ms</code>)</p>
<h3 id="retry-configuration-with-backoff"><a class="header" href="#retry-configuration-with-backoff">Retry Configuration with Backoff</a></h3>
<p>Configure automatic retry behavior for failed items:</p>
<pre><code class="language-yaml">error_policy:
  on_item_failure: retry
  retry_config:
    max_attempts: 3
    backoff:
      type: exponential
      initial: 1s            # Initial delay (duration format)
      multiplier: 2          # Double delay each retry
</code></pre>
<p><strong>Backoff Strategy Options:</strong></p>
<pre><code class="language-yaml"># Fixed delay between retries
backoff:
  type: fixed
  delay: 1s

# Linear increase in delay
backoff:
  type: linear
  initial: 1s
  increment: 500ms

# Exponential backoff (recommended)
backoff:
  type: exponential
  initial: 1s
  multiplier: 2

# Fibonacci sequence delays
backoff:
  type: fibonacci
  initial: 1s
</code></pre>
<p><strong>Important:</strong> All duration values use humantime format (e.g., <code>1s</code>, <code>100ms</code>, <code>2m</code>, <code>30s</code>), not milliseconds.</p>
<h3 id="error-metrics"><a class="header" href="#error-metrics">Error Metrics</a></h3>
<p>Prodigy automatically tracks error metrics for MapReduce jobs:</p>
<ul>
<li><strong>Counts:</strong> total_items, successful, failed, skipped</li>
<li><strong>Rates:</strong> failure_rate (0.0 to 1.0)</li>
<li><strong>Patterns:</strong> Detects recurring error types with suggested remediation</li>
<li><strong>Error types:</strong> Frequency of each error category</li>
</ul>
<p>Access metrics during execution or after completion to understand job health.</p>
<hr />
<h2 id="dead-letter-queue-dlq-1"><a class="header" href="#dead-letter-queue-dlq-1">Dead Letter Queue (DLQ)</a></h2>
<p>The Dead Letter Queue stores failed work items from MapReduce jobs for later retry or analysis. This is only available for MapReduce workflows, not regular workflows.</p>
<h3 id="sending-items-to-dlq"><a class="header" href="#sending-items-to-dlq">Sending Items to DLQ</a></h3>
<p>Configure your MapReduce workflow to use DLQ:</p>
<pre><code class="language-yaml">mode: mapreduce
error_policy:
  on_item_failure: dlq
</code></pre>
<p>Failed items are automatically sent to the DLQ with:</p>
<ul>
<li>Original work item data</li>
<li>Failure reason and error message</li>
<li>Timestamp of failure</li>
<li>Attempt history</li>
</ul>
<h3 id="retrying-failed-items"><a class="header" href="#retrying-failed-items">Retrying Failed Items</a></h3>
<p>Use the CLI to retry failed items:</p>
<pre><code class="language-bash"># Retry all failed items for a job
prodigy dlq retry &lt;job_id&gt;

# Retry with custom parallelism (default: 5)
prodigy dlq retry &lt;job_id&gt; --max-parallel 10

# Dry run to see what would be retried
prodigy dlq retry &lt;job_id&gt; --dry-run
</code></pre>
<p><strong>DLQ Retry Features:</strong></p>
<ul>
<li>Streams items to avoid memory issues with large queues</li>
<li>Respects original workflow’s max_parallel setting (unless overridden)</li>
<li>Preserves correlation IDs for tracking</li>
<li>Updates DLQ state (removes successful, keeps failed)</li>
<li>Supports interruption and resumption</li>
<li>Shared across worktrees for centralized failure tracking</li>
</ul>
<h3 id="dlq-storage-1"><a class="header" href="#dlq-storage-1">DLQ Storage</a></h3>
<p>DLQ data is stored in:</p>
<pre><code>~/.prodigy/dlq/{repo_name}/{job_id}/
</code></pre>
<p>This centralized storage allows multiple worktrees to share the same DLQ.</p>
<hr />
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="when-to-use-command-level-error-handling"><a class="header" href="#when-to-use-command-level-error-handling">When to Use Command-Level Error Handling</a></h3>
<ul>
<li><strong>Recovery:</strong> Use <code>on_failure</code> to fix issues and retry (e.g., clearing cache before reinstalling)</li>
<li><strong>Cleanup:</strong> Use <code>strategy: cleanup</code> to clean up resources after failures</li>
<li><strong>Fallback:</strong> Use <code>strategy: fallback</code> for alternative approaches</li>
<li><strong>Notifications:</strong> Use handler commands to notify teams of failures</li>
</ul>
<h3 id="when-to-use-workflow-level-error-policy"><a class="header" href="#when-to-use-workflow-level-error-policy">When to Use Workflow-Level Error Policy</a></h3>
<ul>
<li><strong>MapReduce jobs:</strong> Use error_policy for consistent failure handling across all work items</li>
<li><strong>Failure thresholds:</strong> Use max_failures or failure_threshold to prevent runaway jobs</li>
<li><strong>Circuit breakers:</strong> Use when external dependencies might fail cascading</li>
<li><strong>DLQ:</strong> Use for large batch jobs where you want to retry failures separately</li>
</ul>
<h3 id="error-information-available"><a class="header" href="#error-information-available">Error Information Available</a></h3>
<p>When a command fails, you can access error information in handler commands:</p>
<pre><code class="language-yaml">- shell: "risky-command"
  on_failure:
    claude: "/analyze-error ${shell.output}"
</code></pre>
<p>The <code>${shell.output}</code> variable contains the command’s stdout/stderr output.</p>
<h3 id="common-patterns-2"><a class="header" href="#common-patterns-2">Common Patterns</a></h3>
<p><strong>Cleanup and Retry:</strong></p>
<pre><code class="language-yaml">- shell: "npm install"
  on_failure:
    - "npm cache clean --force"
    - "rm -rf node_modules"
    - "npm install"
</code></pre>
<p><strong>Conditional Recovery:</strong></p>
<pre><code class="language-yaml">- shell: "cargo test"
  on_failure:
    claude: "/fix-failing-tests"
  max_attempts: 3
  fail_workflow: false
</code></pre>
<p><strong>Critical Step with Notification:</strong></p>
<pre><code class="language-yaml">- shell: "deploy-production"
  on_failure:
    commands:
      - shell: "rollback-deployment"
      - shell: "notify-team 'Deployment failed'"
    fail_workflow: true   # Still fail workflow after cleanup
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="automated-documentation-with-mdbook"><a class="header" href="#automated-documentation-with-mdbook">Automated Documentation with mdBook</a></h1>
<p>This guide shows you how to set up automated, always-up-to-date documentation for any project using Prodigy’s book workflow system. This same system maintains the documentation you’re reading right now.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>The book workflow system:</p>
<ul>
<li><strong>Analyzes your codebase</strong> to build a feature inventory</li>
<li><strong>Detects documentation drift</strong> by comparing docs to implementation</li>
<li><strong>Updates documentation</strong> automatically using Claude</li>
<li><strong>Maintains consistency</strong> across all chapters</li>
<li><strong>Runs on any project</strong> - just configure and go</li>
</ul>
<p>The generalized commands work for any codebase: Rust, Python, JavaScript, etc.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ol>
<li>
<p><strong>Install Prodigy</strong>:</p>
<pre><code class="language-bash">cargo install prodigy
</code></pre>
</li>
<li>
<p><strong>Install mdBook</strong>:</p>
<pre><code class="language-bash">cargo install mdbook
</code></pre>
</li>
<li>
<p><strong>Claude Code CLI</strong> with valid API credentials</p>
</li>
<li>
<p><strong>Git repository</strong> for your project</p>
</li>
</ol>
<h2 id="quick-start-30-minutes"><a class="header" href="#quick-start-30-minutes">Quick Start (30 Minutes)</a></h2>
<h3 id="step-1-initialize-prodigy-commands"><a class="header" href="#step-1-initialize-prodigy-commands">Step 1: Initialize Prodigy Commands</a></h3>
<p>In your project directory:</p>
<pre><code class="language-bash"># Initialize Prodigy and install book documentation commands
prodigy init
</code></pre>
<p>This creates <code>.claude/commands/</code> with the generalized book commands:</p>
<ul>
<li><code>/prodigy-analyze-features-for-book</code> - Analyze codebase for feature inventory</li>
<li><code>/prodigy-analyze-book-chapter-drift</code> - Detect documentation drift per chapter</li>
<li><code>/prodigy-fix-book-drift</code> - Update chapters to fix drift</li>
<li><code>/prodigy-fix-book-build-errors</code> - Fix mdBook build errors</li>
</ul>
<h3 id="step-2-initialize-mdbook-structure"><a class="header" href="#step-2-initialize-mdbook-structure">Step 2: Initialize mdBook Structure</a></h3>
<pre><code class="language-bash"># Create book directory structure
mdbook init book --title "Your Project Documentation"

# Create workflow and config directories
mkdir -p workflows/data
mkdir -p .myproject  # Or .config, whatever you prefer
</code></pre>
<h3 id="step-3-create-project-configuration"><a class="header" href="#step-3-create-project-configuration">Step 3: Create Project Configuration</a></h3>
<p>Create <code>.myproject/book-config.json</code> (adjust paths and analysis targets for your project):</p>
<pre><code class="language-json">{
  "project_name": "YourProject",
  "project_type": "cli_tool",
  "book_dir": "book",
  "book_src": "book/src",
  "book_build_dir": "book/book",
  "analysis_targets": [
    {
      "area": "cli_commands",
      "source_files": ["src/cli/", "src/commands/"],
      "feature_categories": ["commands", "arguments", "options"]
    },
    {
      "area": "core_features",
      "source_files": ["src/lib.rs", "src/core/"],
      "feature_categories": ["api", "public_functions", "exports"]
    },
    {
      "area": "configuration",
      "source_files": ["src/config/"],
      "feature_categories": ["config_options", "defaults", "validation"]
    }
  ],
  "chapter_file": "workflows/data/chapters.json",
  "custom_analysis": {
    "include_examples": true,
    "include_best_practices": true,
    "include_troubleshooting": true
  }
}
</code></pre>
<p><strong>Key Fields to Customize</strong>:</p>
<ul>
<li><code>project_name</code>: Your project’s name (used in prompts)</li>
<li><code>project_type</code>: <code>cli_tool</code>, <code>library</code>, <code>web_service</code>, etc.</li>
<li><code>analysis_targets</code>: Areas of code to analyze for documentation
<ul>
<li><code>area</code>: Logical grouping name</li>
<li><code>source_files</code>: Paths to analyze (relative to project root)</li>
<li><code>feature_categories</code>: Types of features to extract</li>
</ul>
</li>
</ul>
<h3 id="step-4-define-chapter-structure"><a class="header" href="#step-4-define-chapter-structure">Step 4: Define Chapter Structure</a></h3>
<p>Create <code>workflows/data/chapters.json</code>:</p>
<pre><code class="language-json">{
  "chapters": [
    {
      "id": "getting-started",
      "title": "Getting Started",
      "file": "book/src/getting-started.md",
      "topics": ["Installation", "Quick start", "First steps"],
      "validation": "Check installation instructions and basic usage"
    },
    {
      "id": "user-guide",
      "title": "User Guide",
      "file": "book/src/user-guide.md",
      "topics": ["Core features", "Common workflows", "Examples"],
      "validation": "Verify all main features are documented"
    },
    {
      "id": "configuration",
      "title": "Configuration",
      "file": "book/src/configuration.md",
      "topics": ["Config files", "Options", "Defaults"],
      "validation": "Check config options match implementation"
    },
    {
      "id": "troubleshooting",
      "title": "Troubleshooting",
      "file": "book/src/troubleshooting.md",
      "topics": ["Common issues", "Debug mode", "FAQ"],
      "validation": "Ensure common issues are covered"
    }
  ]
}
</code></pre>
<p><strong>Chapter Definition Fields</strong>:</p>
<ul>
<li><code>id</code>: Unique identifier for the chapter</li>
<li><code>title</code>: Display title in the book</li>
<li><code>file</code>: Path to markdown file (relative to project root)</li>
<li><code>topics</code>: What should be covered in this chapter</li>
<li><code>validation</code>: What Claude should check for accuracy</li>
</ul>
<h3 id="step-5-create-book-configuration"><a class="header" href="#step-5-create-book-configuration">Step 5: Create Book Configuration</a></h3>
<p>Edit <code>book/book.toml</code>:</p>
<pre><code class="language-toml">[book]
title = "Your Project Documentation"
authors = ["Your Team"]
description = "Comprehensive guide to Your Project"
src = "src"
language = "en"

[build]
build-dir = "book"
create-missing = false

[output.html]
default-theme = "rust"
preferred-dark-theme = "navy"
smart-punctuation = true
git-repository-url = "https://github.com/yourorg/yourproject"
git-repository-icon = "fa-github"
edit-url-template = "https://github.com/yourorg/yourproject/edit/main/book/{path}"

[output.html.search]
enable = true
limit-results = 30
use-boolean-and = true
boost-title = 2

[output.html.fold]
enable = true
level = 1

[output.html.playground]
editable = false
copyable = true
line-numbers = true
</code></pre>
<h3 id="step-6-create-chapter-files"><a class="header" href="#step-6-create-chapter-files">Step 6: Create Chapter Files</a></h3>
<p>Create placeholder files for each chapter:</p>
<pre><code class="language-bash"># Create initial chapters with basic structure
cat &gt; book/src/getting-started.md &lt;&lt;EOF
# Getting Started

This chapter covers installation and initial setup.

## Installation

TODO: Add installation instructions

## Quick Start

TODO: Add quick start guide
EOF

# Repeat for other chapters...
</code></pre>
<p>Update <code>book/src/SUMMARY.md</code>:</p>
<pre><code class="language-markdown"># Summary

[Introduction](intro.md)

# User Guide

- [Getting Started](getting-started.md)
- [User Guide](user-guide.md)
- [Configuration](configuration.md)

# Reference

- [Troubleshooting](troubleshooting.md)
</code></pre>
<h3 id="step-7-create-the-workflow"><a class="header" href="#step-7-create-the-workflow">Step 7: Create the Workflow</a></h3>
<p>Create <code>workflows/book-docs-drift.yml</code>:</p>
<pre><code class="language-yaml">name: book-docs-drift-detection
mode: mapreduce

env:
  PROJECT_NAME: "YourProject"
  PROJECT_CONFIG: ".myproject/book-config.json"
  FEATURES_PATH: ".myproject/book-analysis/features.json"

setup:
  - shell: "mkdir -p .myproject/book-analysis"

  # Analyze codebase and build feature inventory
  - claude: "/prodigy-analyze-features-for-book --project $PROJECT_NAME --config $PROJECT_CONFIG"

map:
  input: "workflows/data/chapters.json"
  json_path: "$.chapters[*]"

  agent_template:
    # Analyze each chapter for drift
    - claude: "/prodigy-analyze-book-chapter-drift --project $PROJECT_NAME --json '${item}' --features $FEATURES_PATH"
      commit_required: true

  max_parallel: 3
  agent_timeout_secs: 900

reduce:
  # Aggregate all drift reports and fix issues
  - claude: "/prodigy-fix-book-drift --project $PROJECT_NAME --config $PROJECT_CONFIG"
    commit_required: true

  # Build the book
  - shell: "cd book &amp;&amp; mdbook build"
    on_failure:
      claude: "/prodigy-fix-book-build-errors --project $PROJECT_NAME"

error_policy:
  on_item_failure: dlq
  continue_on_failure: true
  max_failures: 2

merge:
  commands:
    # Clean up temporary analysis files
    - shell: "rm -rf .myproject/book-analysis"
    - shell: "git add -A &amp;&amp; git commit -m 'chore: remove temporary book analysis files' || true"

    # Final build verification
    - shell: "cd book &amp;&amp; mdbook build"

    # Merge back to main branch
    - shell: "git fetch origin"
    - claude: "/merge-master"
    - claude: "/prodigy-merge-worktree ${merge.source_branch}"
</code></pre>
<p><strong>Workflow Sections</strong>:</p>
<ul>
<li><strong>env</strong>: Environment variables for project-specific configuration</li>
<li><strong>setup</strong>: Initialize analysis directory and build feature inventory</li>
<li><strong>map</strong>: Process each chapter in parallel to detect drift</li>
<li><strong>reduce</strong>: Aggregate results and update documentation</li>
<li><strong>merge</strong>: Cleanup and merge changes back to main branch</li>
</ul>
<p><strong>Key Variables</strong>:</p>
<ul>
<li><code>PROJECT_NAME</code>: Used in prompts and context</li>
<li><code>PROJECT_CONFIG</code>: Path to your book-config.json</li>
<li><code>FEATURES_PATH</code>: Where feature inventory is stored</li>
</ul>
<h3 id="step-8-run-the-workflow"><a class="header" href="#step-8-run-the-workflow">Step 8: Run the Workflow</a></h3>
<pre><code class="language-bash"># Run the documentation workflow
prodigy run workflows/book-docs-drift.yml

# The workflow will:
# 1. Analyze your codebase for features
# 2. Check each chapter for documentation drift
# 3. Update chapters to match current implementation
# 4. Build the book to verify everything works
# 5. Merge changes back to your main branch
</code></pre>
<h2 id="understanding-the-workflow"><a class="header" href="#understanding-the-workflow">Understanding the Workflow</a></h2>
<h3 id="phase-1-setup---feature-analysis"><a class="header" href="#phase-1-setup---feature-analysis">Phase 1: Setup - Feature Analysis</a></h3>
<p>The setup phase analyzes your codebase and creates a feature inventory:</p>
<pre><code class="language-yaml">setup:
  - shell: "mkdir -p .myproject/book-analysis"
  - claude: "/prodigy-analyze-features-for-book --project $PROJECT_NAME --config $PROJECT_CONFIG"
</code></pre>
<p>This generates <code>.myproject/book-analysis/features.json</code>:</p>
<pre><code class="language-json">{
  "cli_commands": [
    {
      "name": "run",
      "description": "Execute a workflow",
      "arguments": ["workflow_file"],
      "options": ["--resume", "--dry-run"]
    }
  ],
  "api_functions": [
    {
      "name": "execute_workflow",
      "signature": "fn execute_workflow(config: Config) -&gt; Result&lt;()&gt;",
      "purpose": "Main entry point for workflow execution"
    }
  ]
}
</code></pre>
<h3 id="phase-2-map---chapter-drift-detection"><a class="header" href="#phase-2-map---chapter-drift-detection">Phase 2: Map - Chapter Drift Detection</a></h3>
<p>Each chapter is processed in parallel to detect drift:</p>
<pre><code class="language-yaml">map:
  input: "workflows/data/chapters.json"
  json_path: "$.chapters[*]"

  agent_template:
    - claude: "/prodigy-analyze-book-chapter-drift --project $PROJECT_NAME --json '${item}' --features $FEATURES_PATH"
      commit_required: true
</code></pre>
<p>For each chapter, Claude:</p>
<ol>
<li>Reads the current chapter content</li>
<li>Compares it to the feature inventory</li>
<li>Identifies missing, outdated, or incorrect information</li>
<li>Creates a drift report</li>
</ol>
<h3 id="phase-3-reduce---fix-drift"><a class="header" href="#phase-3-reduce---fix-drift">Phase 3: Reduce - Fix Drift</a></h3>
<p>The reduce phase aggregates all drift reports and updates chapters:</p>
<pre><code class="language-yaml">reduce:
  - claude: "/prodigy-fix-book-drift --project $PROJECT_NAME --config $PROJECT_CONFIG"
    commit_required: true

  - shell: "cd book &amp;&amp; mdbook build"
    on_failure:
      claude: "/prodigy-fix-book-build-errors --project $PROJECT_NAME"
</code></pre>
<p>Claude:</p>
<ol>
<li>Reviews all drift reports</li>
<li>Updates chapters to fix issues</li>
<li>Ensures consistency across chapters</li>
<li>Verifies the book builds successfully</li>
</ol>
<h3 id="phase-4-merge---integration"><a class="header" href="#phase-4-merge---integration">Phase 4: Merge - Integration</a></h3>
<p>The merge phase cleans up and integrates changes:</p>
<pre><code class="language-yaml">merge:
  commands:
    - shell: "rm -rf .myproject/book-analysis"
    - shell: "git add -A &amp;&amp; git commit -m 'chore: remove temporary book analysis files' || true"
    - shell: "cd book &amp;&amp; mdbook build"
    - shell: "git fetch origin"
    - claude: "/merge-master"
    - claude: "/prodigy-merge-worktree ${merge.source_branch}"
</code></pre>
<h2 id="github-actions-integration"><a class="header" href="#github-actions-integration">GitHub Actions Integration</a></h2>
<h3 id="automated-documentation-deployment"><a class="header" href="#automated-documentation-deployment">Automated Documentation Deployment</a></h3>
<p>Create <code>.github/workflows/deploy-docs.yml</code>:</p>
<pre><code class="language-yaml">name: Deploy Documentation

on:
  push:
    branches: [main, master]
    paths:
      - 'book/**'
      - 'workflows/book-docs-drift.yml'
  workflow_dispatch:  # Allow manual triggers

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup mdBook
        uses: peaceiris/actions-mdbook@v2
        with:
          mdbook-version: 'latest'

      - name: Build book
        run: |
          cd book
          mdbook build

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./book/book
          cname: docs.yourproject.com  # Optional: custom domain
</code></pre>
<h3 id="periodic-documentation-updates"><a class="header" href="#periodic-documentation-updates">Periodic Documentation Updates</a></h3>
<p>Create <code>.github/workflows/update-docs.yml</code>:</p>
<pre><code class="language-yaml">name: Update Documentation

on:
  schedule:
    # Run weekly on Monday at 9 AM UTC
    - cron: '0 9 * * 1'
  workflow_dispatch:  # Allow manual triggers

jobs:
  update-docs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable

      - name: Install Prodigy
        run: cargo install prodigy

      - name: Install mdBook
        uses: peaceiris/actions-mdbook@v2
        with:
          mdbook-version: 'latest'

      - name: Configure Claude API
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Configure Claude Code CLI with API key
          echo "$ANTHROPIC_API_KEY" | claude-code auth login

      - name: Run documentation workflow
        run: |
          prodigy run workflows/book-docs-drift.yml

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: 'docs: automated documentation update'
          title: 'Automated Documentation Update'
          body: |
            This PR was automatically created by the documentation workflow.

            Changes:
            - Updated documentation to match current codebase
            - Fixed any detected drift between docs and implementation

            Please review the changes before merging.
          branch: docs/automated-update
          delete-branch: true
</code></pre>
<p><strong>Required Secrets</strong>:</p>
<ul>
<li><code>ANTHROPIC_API_KEY</code>: Your Claude API key (add in repository settings)</li>
</ul>
<h3 id="enable-github-pages"><a class="header" href="#enable-github-pages">Enable GitHub Pages</a></h3>
<ol>
<li>Go to repository Settings → Pages</li>
<li>Source: Deploy from a branch</li>
<li>Branch: <code>gh-pages</code> / <code>root</code></li>
<li>Save</li>
</ol>
<p>Your documentation will be available at: <code>https://yourorg.github.io/yourproject</code></p>
<h2 id="customization-examples"><a class="header" href="#customization-examples">Customization Examples</a></h2>
<h3 id="for-cli-tools"><a class="header" href="#for-cli-tools">For CLI Tools</a></h3>
<p>Focus on commands and usage:</p>
<pre><code class="language-json">{
  "analysis_targets": [
    {
      "area": "cli_commands",
      "source_files": ["src/cli/", "src/commands/"],
      "feature_categories": ["commands", "subcommands", "options", "arguments"]
    },
    {
      "area": "configuration",
      "source_files": ["src/config/"],
      "feature_categories": ["config_file", "environment_vars", "flags"]
    }
  ]
}
</code></pre>
<p>Chapter structure:</p>
<ul>
<li>Installation</li>
<li>Quick Start</li>
<li>Commands Reference</li>
<li>Configuration</li>
<li>Examples</li>
<li>Troubleshooting</li>
</ul>
<h3 id="for-libraries"><a class="header" href="#for-libraries">For Libraries</a></h3>
<p>Focus on API and usage patterns:</p>
<pre><code class="language-json">{
  "analysis_targets": [
    {
      "area": "public_api",
      "source_files": ["src/lib.rs", "src/api/"],
      "feature_categories": ["functions", "types", "traits", "macros"]
    },
    {
      "area": "examples",
      "source_files": ["examples/"],
      "feature_categories": ["use_cases", "patterns", "integrations"]
    }
  ]
}
</code></pre>
<p>Chapter structure:</p>
<ul>
<li>Getting Started</li>
<li>API Reference</li>
<li>Core Concepts</li>
<li>Advanced Usage</li>
<li>Examples</li>
<li>Migration Guides</li>
</ul>
<h3 id="for-web-services"><a class="header" href="#for-web-services">For Web Services</a></h3>
<p>Focus on endpoints and integration:</p>
<pre><code class="language-json">{
  "analysis_targets": [
    {
      "area": "api_endpoints",
      "source_files": ["src/routes/", "src/handlers/"],
      "feature_categories": ["endpoints", "methods", "parameters", "responses"]
    },
    {
      "area": "authentication",
      "source_files": ["src/auth/"],
      "feature_categories": ["auth_methods", "tokens", "permissions"]
    },
    {
      "area": "deployment",
      "source_files": ["deploy/", "docker/"],
      "feature_categories": ["docker", "kubernetes", "configuration"]
    }
  ]
}
</code></pre>
<p>Chapter structure:</p>
<ul>
<li>Overview</li>
<li>Authentication</li>
<li>API Reference</li>
<li>Integration Guide</li>
<li>Deployment</li>
<li>Monitoring</li>
</ul>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="1-start-with-minimal-chapters"><a class="header" href="#1-start-with-minimal-chapters">1. Start with Minimal Chapters</a></h3>
<p>Don’t try to document everything at once:</p>
<pre><code class="language-json">{
  "chapters": [
    {"id": "intro", "title": "Introduction", ...},
    {"id": "quickstart", "title": "Quick Start", ...},
    {"id": "reference", "title": "Reference", ...}
  ]
}
</code></pre>
<p>Add more chapters as your project grows.</p>
<h3 id="2-focus-analysis-targets"><a class="header" href="#2-focus-analysis-targets">2. Focus Analysis Targets</a></h3>
<p>Be specific about what to analyze:</p>
<pre><code class="language-json">{
  "area": "cli_commands",
  "source_files": ["src/cli/commands/"],  // Specific path
  "feature_categories": ["commands", "options"]  // Specific categories
}
</code></pre>
<p>Overly broad targets create unfocused documentation.</p>
<h3 id="3-provide-chapter-context"><a class="header" href="#3-provide-chapter-context">3. Provide Chapter Context</a></h3>
<p>Give Claude clear guidance on what each chapter should cover:</p>
<pre><code class="language-json">{
  "id": "advanced",
  "title": "Advanced Features",
  "topics": ["Custom plugins", "Scripting", "Automation"],
  "validation": "Check that plugin API and scripting examples are up-to-date"
}
</code></pre>
<h3 id="4-review-initial-output"><a class="header" href="#4-review-initial-output">4. Review Initial Output</a></h3>
<p>The first workflow run will:</p>
<ul>
<li>Identify what’s missing</li>
<li>Add current implementation details</li>
<li>Create a baseline</li>
</ul>
<p>Review and refine before committing.</p>
<h3 id="5-run-regularly"><a class="header" href="#5-run-regularly">5. Run Regularly</a></h3>
<p>Documentation drift happens constantly:</p>
<pre><code class="language-bash"># Run monthly or after major features
prodigy run workflows/book-docs-drift.yml

# Or set up GitHub Actions for automation
</code></pre>
<h3 id="6-use-validation-topics"><a class="header" href="#6-use-validation-topics">6. Use Validation Topics</a></h3>
<p>Specify what Claude should validate:</p>
<pre><code class="language-json">{
  "validation": "Check that all CLI commands in src/cli/commands/ are documented with current options and examples"
}
</code></pre>
<p>This ensures focused, accurate updates.</p>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="issue-feature-analysis-produces-empty-results"><a class="header" href="#issue-feature-analysis-produces-empty-results">Issue: Feature Analysis Produces Empty Results</a></h3>
<p><strong>Cause</strong>: Analysis targets don’t match your code structure</p>
<p><strong>Solution</strong>: Check that <code>source_files</code> paths exist:</p>
<pre><code class="language-bash">ls -la src/cli/  # Verify paths in analysis_targets
</code></pre>
<p>Adjust paths in <code>book-config.json</code> to match your actual structure.</p>
<h3 id="issue-chapters-not-updating"><a class="header" href="#issue-chapters-not-updating">Issue: Chapters Not Updating</a></h3>
<p><strong>Cause</strong>: Chapter files don’t exist or paths are wrong</p>
<p><strong>Solution</strong>: Verify chapter files exist:</p>
<pre><code class="language-bash"># Check all chapters listed in chapters.json exist
cat workflows/data/chapters.json | jq -r '.chapters[].file' | xargs ls -la
</code></pre>
<h3 id="issue-mdbook-build-fails"><a class="header" href="#issue-mdbook-build-fails">Issue: mdBook Build Fails</a></h3>
<p><strong>Cause</strong>: SUMMARY.md doesn’t match chapter files</p>
<p><strong>Solution</strong>: Ensure all chapters in <code>SUMMARY.md</code> have corresponding files:</p>
<pre><code class="language-bash">cd book &amp;&amp; mdbook build
</code></pre>
<p>Fix any missing files or broken links.</p>
<h3 id="issue-workflow-takes-too-long"><a class="header" href="#issue-workflow-takes-too-long">Issue: Workflow Takes Too Long</a></h3>
<p><strong>Cause</strong>: Too many chapters or overly broad analysis</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Reduce <code>max_parallel</code> in map phase (default: 3)</li>
<li>Split large chapters into smaller ones</li>
<li>Narrow <code>analysis_targets</code> to essential code paths</li>
</ol>
<h3 id="issue-documentation-quality-issues"><a class="header" href="#issue-documentation-quality-issues">Issue: Documentation Quality Issues</a></h3>
<p><strong>Cause</strong>: Insufficient initial content or unclear validation</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Create better chapter outlines before running workflow</li>
<li>Add more specific <code>validation</code> criteria in chapters.json</li>
<li>Review and manually refine after first run</li>
</ol>
<h2 id="advanced-configuration-1"><a class="header" href="#advanced-configuration-1">Advanced Configuration</a></h2>
<h3 id="custom-analysis-functions"><a class="header" href="#custom-analysis-functions">Custom Analysis Functions</a></h3>
<p>You can extend the analysis by providing custom analysis functions in your config:</p>
<pre><code class="language-json">{
  "custom_analysis": {
    "include_examples": true,
    "include_best_practices": true,
    "include_troubleshooting": true,
    "analyze_dependencies": true,
    "extract_code_comments": true,
    "include_performance_notes": true
  }
}
</code></pre>
<h3 id="multi-language-projects"><a class="header" href="#multi-language-projects">Multi-Language Projects</a></h3>
<p>For projects with multiple languages:</p>
<pre><code class="language-json">{
  "analysis_targets": [
    {
      "area": "rust_backend",
      "source_files": ["src/"],
      "feature_categories": ["api", "services"],
      "language": "rust"
    },
    {
      "area": "typescript_frontend",
      "source_files": ["web/src/"],
      "feature_categories": ["components", "hooks"],
      "language": "typescript"
    }
  ]
}
</code></pre>
<h3 id="chapter-dependencies"><a class="header" href="#chapter-dependencies">Chapter Dependencies</a></h3>
<p>Some chapters may depend on others:</p>
<pre><code class="language-json">{
  "chapters": [
    {
      "id": "basics",
      "title": "Basic Usage",
      "dependencies": []
    },
    {
      "id": "advanced",
      "title": "Advanced Usage",
      "dependencies": ["basics"],
      "validation": "Ensure examples build on concepts from Basic Usage chapter"
    }
  ]
}
</code></pre>
<h2 id="real-world-example-prodigys-own-documentation"><a class="header" href="#real-world-example-prodigys-own-documentation">Real-World Example: Prodigy’s Own Documentation</a></h2>
<p>This documentation you’re reading is maintained by the same workflow described here. You can examine the configuration:</p>
<p><strong>Configuration</strong>: <code>.prodigy/book-config.json</code></p>
<pre><code class="language-json">{
  "project_name": "Prodigy",
  "project_type": "cli_tool",
  "analysis_targets": [
    {
      "area": "workflow_execution",
      "source_files": ["src/workflow/", "src/orchestrator/"],
      "feature_categories": ["workflow_types", "execution_modes", "lifecycle"]
    },
    {
      "area": "mapreduce",
      "source_files": ["src/mapreduce/"],
      "feature_categories": ["map_phase", "reduce_phase", "parallelism"]
    }
  ]
}
</code></pre>
<p><strong>Chapters</strong>: <code>workflows/data/prodigy-chapters.json</code></p>
<pre><code class="language-json">{
  "chapters": [
    {
      "id": "workflow-basics",
      "title": "Workflow Basics",
      "file": "book/src/workflow-basics.md",
      "topics": ["Standard workflows", "Basic structure"],
      "validation": "Check workflow syntax matches current implementation"
    }
  ]
}
</code></pre>
<p><strong>Workflow</strong>: <code>workflows/book-docs-drift.yml</code></p>
<p>Study these files for a complete working example.</p>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<ol>
<li><strong>Set up the basics</strong>: Follow the Quick Start to get a minimal book running</li>
<li><strong>Customize for your project</strong>: Adjust analysis targets and chapters</li>
<li><strong>Run the workflow</strong>: Generate your first automated update</li>
<li><strong>Refine iteratively</strong>: Review output and improve configuration</li>
<li><strong>Automate</strong>: Set up GitHub Actions for continuous documentation</li>
<li><strong>Extend</strong>: Add more chapters as your project grows</li>
</ol>
<h2 id="benefits"><a class="header" href="#benefits">Benefits</a></h2>
<p>This approach provides:</p>
<ul>
<li>✅ <strong>Always up-to-date documentation</strong> - Runs automatically to detect drift</li>
<li>✅ <strong>Consistent quality</strong> - Same analysis across all chapters</li>
<li>✅ <strong>Reduced maintenance</strong> - Less manual documentation work</li>
<li>✅ <strong>Accurate examples</strong> - Extracted from actual code</li>
<li>✅ <strong>Version control</strong> - All changes tracked in git</li>
<li>✅ <strong>Easy to customize</strong> - Configuration-based, works for any project</li>
</ul>
<p>The same commands that maintain Prodigy’s documentation can maintain yours.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="examples"><a class="header" href="#examples">Examples</a></h1>
<h2 id="example-1-simple-build-and-test"><a class="header" href="#example-1-simple-build-and-test">Example 1: Simple Build and Test</a></h2>
<pre><code class="language-yaml">- shell: "cargo build"
- shell: "cargo test"
  on_failure:
    claude: "/fix-failing-tests"
- shell: "cargo clippy"
</code></pre>
<hr />
<h2 id="example-2-coverage-improvement-with-goal-seeking"><a class="header" href="#example-2-coverage-improvement-with-goal-seeking">Example 2: Coverage Improvement with Goal Seeking</a></h2>
<pre><code class="language-yaml">- goal_seek:
    goal: "Achieve 80% test coverage"
    claude: "/improve-coverage"
    validate: |
      coverage=$(cargo tarpaulin | grep 'Coverage' | sed 's/.*: \([0-9.]*\)%.*/\1/')
      echo "score: ${coverage%.*}"
    threshold: 80
    max_attempts: 5
  commit_required: true
</code></pre>
<hr />
<h2 id="example-3-foreach-iteration"><a class="header" href="#example-3-foreach-iteration">Example 3: Foreach Iteration</a></h2>
<pre><code class="language-yaml"># Test multiple configurations in sequence
- foreach:
    - rust-version: "1.70"
      profile: debug
    - rust-version: "1.71"
      profile: release
    - rust-version: "stable"
      profile: release
  commands:
    - shell: "rustup install ${foreach.item.rust-version}"
    - shell: "cargo +${foreach.item.rust-version} build --profile ${foreach.item.profile}"
    - shell: "cargo +${foreach.item.rust-version} test"

# Parallel foreach with error handling
- foreach:
    - "web-service"
    - "api-gateway"
    - "worker-service"
  parallel: 3
  continue_on_error: true
  commands:
    - shell: "cd services/${foreach.item} &amp;&amp; cargo build"
    - shell: "cd services/${foreach.item} &amp;&amp; cargo test"
      on_failure:
        claude: "/fix-service-tests ${foreach.item}"
</code></pre>
<hr />
<h2 id="example-4-parallel-code-review"><a class="header" href="#example-4-parallel-code-review">Example 4: Parallel Code Review</a></h2>
<pre><code class="language-yaml">name: parallel-code-review
mode: mapreduce

setup:
  - shell: "find src -name '*.rs' &gt; files.txt"
  - shell: "jq -R -s -c 'split(\"\n\") | map(select(length &gt; 0) | {path: .})' files.txt &gt; items.json"

map:
  input: items.json
  json_path: "$[*]"  # Process all items
  agent_template:
    - claude: "/review-file ${item.path}"
      id: "review"
      capture: "review_result"
      capture_format: "json"
    - shell: "cargo check ${item.path}"
  max_parallel: 5

reduce:
  - claude: "/summarize-reviews ${map.results}"
</code></pre>
<hr />
<h2 id="example-5-conditional-deployment"><a class="header" href="#example-5-conditional-deployment">Example 5: Conditional Deployment</a></h2>
<pre><code class="language-yaml">- shell: "cargo test --quiet &amp;&amp; echo true || echo false"
  id: "test"
  capture: "test_result"
  capture_format: "boolean"  # Supported: string, json, lines, number, boolean

- shell: "cargo build --release"
  when: "${test_result} == true"

- shell: "docker build -t myapp ."
  when: "${test_result} == true"
  on_success:
    shell: "docker push myapp:latest"
</code></pre>
<hr />
<h2 id="example-6-multi-step-validation"><a class="header" href="#example-6-multi-step-validation">Example 6: Multi-Step Validation</a></h2>
<pre><code class="language-yaml">- claude: "/implement-feature auth"
  commit_required: true
  validate:
    commands:
      - shell: "cargo test auth"
      - shell: "cargo clippy -- -D warnings"
      - claude: "/validate-implementation --output validation.json"
    result_file: "validation.json"
    threshold: 90
    on_incomplete:
      claude: "/complete-gaps ${validation.gaps}"
      commit_required: true
      max_attempts: 2
</code></pre>
<hr />
<h2 id="example-7-environment-aware-workflow"><a class="header" href="#example-7-environment-aware-workflow">Example 7: Environment-Aware Workflow</a></h2>
<pre><code class="language-yaml"># Global environment variables
env:
  NODE_ENV: production
  API_URL: https://api.production.com

# Environment profiles for different contexts
profiles:
  production:
    API_URL: https://api.production.com
    LOG_LEVEL: error
    description: "Production environment"

  staging:
    API_URL: https://api.staging.com
    LOG_LEVEL: warn
    description: "Staging environment"

# Secrets (masked in logs)
secrets:
  API_KEY:
    provider: env
    key: SECRET_API_KEY

# Load additional variables from .env files
env_files:
  - .env
  - .env.production

# Workflow steps (no 'commands' wrapper in simple format)
- shell: "cargo build --release"

# Use environment variables in commands
- shell: "echo 'Deploying to ${NODE_ENV} at ${API_URL}'"

# Override environment for specific command using shell syntax
- shell: "LOG_LEVEL=debug ./deploy.sh"
</code></pre>
<p><strong>Note:</strong> Profile activation with <code>active_profile</code> is managed internally and not currently exposed in WorkflowConfig YAML. Use <code>--profile</code> CLI flag to activate profiles.</p>
<hr />
<h2 id="example-8-complex-mapreduce-with-error-handling"><a class="header" href="#example-8-complex-mapreduce-with-error-handling">Example 8: Complex MapReduce with Error Handling</a></h2>
<pre><code class="language-yaml">name: tech-debt-elimination
mode: mapreduce

setup:
  - shell: "debtmap analyze . --output debt.json"

map:
  input: debt.json
  json_path: "$.items[*]"
  filter: "item.severity == 'critical'"
  sort_by: "item.priority DESC"
  max_items: 20
  max_parallel: 5

  agent_template:
    - claude: "/fix-debt-item '${item.description}'"
      commit_required: true
    - shell: "cargo test"
      on_failure:
        claude: "/debug-and-fix"

reduce:
  - shell: "debtmap analyze . --output debt-after.json"
  - claude: "/compare-debt-reports --before debt.json --after debt-after.json"

error_policy:
  on_item_failure: dlq
  continue_on_failure: true
  max_failures: 5
  failure_threshold: 0.3
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h1>
<h2 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h2>
<h3 id="1-variables-not-interpolating"><a class="header" href="#1-variables-not-interpolating">1. Variables not interpolating</a></h3>
<p><strong>Symptom:</strong> Variables appear as literal <code>${variable_name}</code> in output instead of their values.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Incorrect syntax (missing <code>${}</code> wrapper)</li>
<li>Variable not defined or not in scope</li>
<li>Typo in variable name</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Ensure proper <code>${}</code> syntax: <code>${workflow.name}</code>, not <code>$workflow.name</code></li>
<li>Check variable is defined before use</li>
<li>Verify variable is available in current context (e.g., <code>${item.*}</code> only available in map phase)</li>
<li>Use echo to debug: <code>- shell: "echo 'Variable value: ${my_var}'"</code></li>
</ul>
<hr />
<h3 id="2-capture-not-working"><a class="header" href="#2-capture-not-working">2. Capture not working</a></h3>
<p><strong>Symptom:</strong> Captured variables are empty or contain unexpected data.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Incorrect <code>capture_format</code> for output type</li>
<li>Command output not in expected format</li>
<li>Missing or incorrect <code>capture_streams</code> configuration</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Match <code>capture_format</code> to output type and how it transforms output:
<ul>
<li><code>string</code> - Captures raw text output as-is</li>
<li><code>number</code> - Parses output as numeric value (int or float)</li>
<li><code>json</code> - Parses JSON and allows JSONPath queries on the result</li>
<li><code>lines</code> - Splits multi-line output into an array</li>
<li><code>boolean</code> - Evaluates to true/false based on success status</li>
</ul>
</li>
<li>Test command output manually first</li>
<li>Capture all streams for debugging:
<pre><code class="language-yaml">- shell: "cargo test 2&gt;&amp;1"
  capture: "test_output"
  capture_streams:
    stdout: true      # Capture standard output
    stderr: true      # Capture error output
    exit_code: true   # Capture exit code
    success: true     # Capture success boolean
    duration: true    # Capture execution duration
</code></pre>
</li>
</ul>
<hr />
<h3 id="3-validation-failing"><a class="header" href="#3-validation-failing">3. Validation failing</a></h3>
<p><strong>Symptom:</strong> Goal-seeking or validation commands fail to recognize completion.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Validate command not outputting <code>score: N</code> format</li>
<li>Threshold too high</li>
<li>Score calculation incorrect</li>
<li>Validation command not configured correctly</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Ensure validate command outputs exactly <code>score: N</code> (where N is 0-100)</li>
<li>Validation is part of goal_seek commands with these fields:
<ul>
<li><code>validate</code> - Command that outputs score</li>
<li><code>threshold</code> - Minimum score to consider success (0-100)</li>
<li><code>max_iterations</code> - Maximum attempts before giving up</li>
<li><code>on_incomplete</code> - Commands to run when score below threshold</li>
</ul>
</li>
<li>Test validate command independently</li>
<li>Lower threshold temporarily for debugging</li>
<li>Example correct format:
<pre><code class="language-yaml">- goal_seek:
    validate: |
      result=$(run-checks.sh | grep 'Percentage' | sed 's/.*: \([0-9]*\)%.*/\1/')
      echo "score: $result"
    threshold: 80
    max_iterations: 5
    on_incomplete:
      - claude: "/fix-issues"
</code></pre>
</li>
</ul>
<hr />
<h3 id="4-mapreduce-items-not-found"><a class="header" href="#4-mapreduce-items-not-found">4. MapReduce items not found</a></h3>
<p><strong>Symptom:</strong> Map phase finds zero items or wrong items.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Incorrect JSONPath expression</li>
<li>Input file format doesn’t match expectations</li>
<li>Input file not generated in setup phase</li>
<li>JSONPath syntax errors</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Test JSONPath expression with actual data using <code>jq</code>:
<pre><code class="language-bash">jq '$.items[*]' items.json
</code></pre>
</li>
<li>Verify input file exists and contains expected structure</li>
<li>Check setup phase completed successfully</li>
<li>Use simpler JSONPath first: <code>$[*]</code> to get all items</li>
<li>Common JSONPath mistakes:
<ul>
<li>Wrong bracket syntax: Use <code>$.items[*]</code> not <code>$.items[]</code></li>
<li>Missing root <code>$</code>: Always start with <code>$</code></li>
<li>Incorrect filter syntax: <code>$[?(@.score &gt;= 5)]</code> for filtering</li>
<li>Nested paths: <code>$.data.items[*].field</code> for deep structures</li>
</ul>
</li>
</ul>
<hr />
<h3 id="5-timeout-errors"><a class="header" href="#5-timeout-errors">5. Timeout errors</a></h3>
<p><strong>Symptom:</strong> Commands or workflows fail with timeout errors.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Commands take longer than expected</li>
<li>Default timeout too short</li>
<li>Infinite loops or hanging processes</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Increase timeout values using duration strings:
<pre><code class="language-yaml">- shell: "slow-command.sh"
  timeout: "600s"  # or "10m" - uses humantime duration format
</code></pre>
</li>
<li>For MapReduce, increase agent timeout (note: this uses seconds as a number):
<pre><code class="language-yaml">map:
  agent_timeout_secs: 600  # Takes a number (seconds) not a duration string
</code></pre>
</li>
<li><strong>Note:</strong> <code>agent_timeout_secs</code> takes a number (seconds) while most other timeout fields use duration strings like “10m”</li>
<li>Debug hanging commands by running them manually</li>
<li>Add logging to identify slow steps</li>
</ul>
<hr />
<h3 id="6-environment-variables-not-set"><a class="header" href="#6-environment-variables-not-set">6. Environment variables not set</a></h3>
<p><strong>Symptom:</strong> Commands fail because required environment variables are missing.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Environment not inherited from parent process</li>
<li>Typo in variable name</li>
<li>Profile not activated</li>
<li>Secret not loaded</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Ensure <code>inherit: true</code> in workflow config (default)</li>
<li>Verify profile activation:
<pre><code class="language-yaml">active_profile: "development"
</code></pre>
</li>
<li>Check secrets are properly configured:
<pre><code class="language-yaml">secrets:
  API_KEY: "${env:SECRET_API_KEY}"
</code></pre>
</li>
<li>Debug with: <code>- shell: "env | grep VARIABLE_NAME"</code></li>
</ul>
<hr />
<h3 id="7-merge-workflow-not-running"><a class="header" href="#7-merge-workflow-not-running">7. Merge workflow not running</a></h3>
<p><strong>Symptom:</strong> Custom merge commands not executed when merging worktree.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Merge block not properly formatted</li>
<li>Syntax error in merge commands</li>
<li>Merge workflow timeout too short</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>
<p>Both merge formats are valid - choose based on needs:</p>
<p><strong>Simplified format (direct list of commands):</strong></p>
<pre><code class="language-yaml">merge:
  - shell: "git fetch origin"
  - claude: "/merge-worktree ${merge.source_branch}"
</code></pre>
<p><strong>Full format (with timeout configuration):</strong></p>
<pre><code class="language-yaml">merge:
  commands:
    - shell: "slow-merge-validation.sh"
  timeout: "600s"  # Duration string format
</code></pre>
</li>
<li>
<p>Use the full format when you need to set a custom timeout</p>
</li>
<li>
<p>Check logs for merge execution errors</p>
</li>
</ul>
<hr />
<h3 id="8-commands-failing-without-error-handler"><a class="header" href="#8-commands-failing-without-error-handler">8. Commands failing without error handler</a></h3>
<p><strong>Symptom:</strong> Command fails and workflow stops immediately without recovery.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>No <code>on_failure</code> handler configured</li>
<li>Error not being caught by handler</li>
<li>Handler itself failing</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Add <code>on_failure</code> handler to commands that might fail:
<pre><code class="language-yaml">- shell: "risky-command.sh"
  on_failure:
    - shell: "echo 'Command failed, attempting recovery'"
    - claude: "/fix-issue"
</code></pre>
</li>
<li>Commands without <code>on_failure</code> will stop the workflow on first error</li>
<li>Check that your handler commands don’t also fail</li>
<li>Use shell exit codes to control failure: <code>command || exit 0</code> to ignore failures</li>
</ul>
<hr />
<h3 id="9-error-policy-configuration-issues"><a class="header" href="#9-error-policy-configuration-issues">9. Error policy configuration issues</a></h3>
<p><strong>Symptom:</strong> Retry, backoff, or circuit breaker not working as expected.</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Incorrect Duration format for timeouts</li>
<li>Wrong BackoffStrategy enum variant</li>
<li>Invalid retry_config structure</li>
</ul>
<p><strong>Solutions:</strong></p>
<ul>
<li>Use Duration strings for all timeout values:
<pre><code class="language-yaml">error_policy:
  retry_config:
    max_attempts: 3
    initial_delay: "1s"    # Not 1000
    max_delay: "30s"       # Use duration strings
  circuit_breaker:
    timeout: "60s"         # Not 60
    failure_threshold: 5
</code></pre>
</li>
<li>Valid BackoffStrategy values:
<ul>
<li><code>constant</code> - Same delay every time</li>
<li><code>linear</code> - Increases linearly</li>
<li><code>exponential</code> - Doubles each time</li>
<li><code>fibonacci</code> - Fibonacci sequence</li>
</ul>
</li>
<li>Circuit breaker requires both timeout and failure_threshold</li>
</ul>
<hr />
<h2 id="debug-tips"><a class="header" href="#debug-tips">Debug Tips</a></h2>
<h3 id="use-verbosity-flags-for-debugging"><a class="header" href="#use-verbosity-flags-for-debugging">Use verbosity flags for debugging</a></h3>
<p>Prodigy supports multiple verbosity levels for debugging:</p>
<pre><code class="language-bash"># Default: Clean output, no Claude streaming
prodigy run workflow.yml

# -v: Shows Claude streaming JSON output (useful for debugging Claude interactions)
prodigy run workflow.yml -v

# -vv: Adds debug-level logs
prodigy run workflow.yml -vv

# -vvv: Adds trace-level logs (very detailed)
prodigy run workflow.yml -vvv

# Force Claude streaming regardless of verbosity
PRODIGY_CLAUDE_CONSOLE_OUTPUT=true prodigy run workflow.yml
</code></pre>
<h3 id="enable-verbose-output-in-shell-commands"><a class="header" href="#enable-verbose-output-in-shell-commands">Enable verbose output in shell commands</a></h3>
<pre><code class="language-yaml">- shell: "set -x; your-command"
</code></pre>
<h3 id="inspect-variables"><a class="header" href="#inspect-variables">Inspect variables</a></h3>
<pre><code class="language-yaml">- shell: "echo 'Variable value: ${my_var}'"
- shell: "echo 'Item fields: path=${item.path} name=${item.name}'"
</code></pre>
<h3 id="capture-all-streams-for-debugging"><a class="header" href="#capture-all-streams-for-debugging">Capture all streams for debugging</a></h3>
<pre><code class="language-yaml">- shell: "cargo test 2&gt;&amp;1"
  capture: "test_output"
  capture_streams:
    stdout: true
    stderr: true
    exit_code: true
    success: true
    duration: true

# Then inspect
- shell: "echo 'Exit code: ${test_output.exit_code}'"
- shell: "echo 'Success: ${test_output.success}'"
- shell: "echo 'Duration: ${test_output.duration}s'"
</code></pre>
<h3 id="test-jsonpath-expressions"><a class="header" href="#test-jsonpath-expressions">Test JSONPath expressions</a></h3>
<pre><code class="language-bash"># Manually test your JSONPath
jq '$.items[*]' items.json

# Test with filter
jq '$.items[] | select(.score &gt;= 5)' items.json
</code></pre>
<h3 id="validate-workflow-syntax"><a class="header" href="#validate-workflow-syntax">Validate workflow syntax</a></h3>
<pre><code class="language-bash"># Workflows are validated automatically when loaded
# Check for syntax errors by attempting to run
prodigy run workflow.yml

# View the validation result file (if workflow validation completed)
cat .prodigy/validation-result.json
</code></pre>
<h3 id="check-dlq-for-failed-items"><a class="header" href="#check-dlq-for-failed-items">Check DLQ for failed items</a></h3>
<pre><code class="language-bash"># List failed items
prodigy dlq list &lt;job_id&gt;

# View failure details
prodigy dlq inspect &lt;job_id&gt;

# Retry failed items (primary recovery operation)
prodigy dlq retry &lt;job_id&gt;

# Retry with custom parallelism
prodigy dlq retry &lt;job_id&gt; --max-parallel 10

# Dry run to see what would be retried
prodigy dlq retry &lt;job_id&gt; --dry-run
</code></pre>
<h3 id="monitor-mapreduce-progress"><a class="header" href="#monitor-mapreduce-progress">Monitor MapReduce progress</a></h3>
<pre><code class="language-bash"># View events
prodigy events &lt;job_id&gt;

# Check checkpoints
prodigy checkpoints list

# View event logs directly
ls ~/.prodigy/events/

# Check session state
cat .prodigy/session_state.json
</code></pre>
<hr />
<h2 id="faq"><a class="header" href="#faq">FAQ</a></h2>
<h3 id="q-why-are-my-changes-not-being-committed"><a class="header" href="#q-why-are-my-changes-not-being-committed">Q: Why are my changes not being committed?</a></h3>
<p><strong>A:</strong> Add <code>commit_required: true</code> to your command or use <code>auto_commit: true</code> for automatic commits when changes are detected. Note: <code>auto_commit</code> can be set at the workflow level (applies to all steps) or per-step. When true, Prodigy creates commits automatically when git diff detects changes.</p>
<h3 id="q-how-do-i-retry-failed-mapreduce-items"><a class="header" href="#q-how-do-i-retry-failed-mapreduce-items">Q: How do I retry failed MapReduce items?</a></h3>
<p><strong>A:</strong> Use the DLQ retry command:</p>
<pre><code class="language-bash">prodigy dlq retry &lt;job_id&gt;
</code></pre>
<h3 id="q-can-i-use-environment-variables-in-jsonpath-expressions"><a class="header" href="#q-can-i-use-environment-variables-in-jsonpath-expressions">Q: Can I use environment variables in JSONPath expressions?</a></h3>
<p><strong>A:</strong> No, JSONPath expressions are evaluated against the input data, not the environment. Use variables in command arguments instead.</p>
<h3 id="q-how-do-i-skip-items-in-mapreduce"><a class="header" href="#q-how-do-i-skip-items-in-mapreduce">Q: How do I skip items in MapReduce?</a></h3>
<p><strong>A:</strong> Use the <code>filter</code> field:</p>
<pre><code class="language-yaml">map:
  filter: "item.score &gt;= 5"
</code></pre>
<h3 id="q-whats-the-difference-between-on_failure-and-on_incomplete"><a class="header" href="#q-whats-the-difference-between-on_failure-and-on_incomplete">Q: What’s the difference between <code>on_failure</code> and <code>on_incomplete</code>?</a></h3>
<p><strong>A:</strong> <code>on_failure</code> runs when a command exits with a non-zero code. <code>on_incomplete</code> is used in goal_seek commands and runs when the validation score is below the threshold.</p>
<h3 id="q-how-do-i-run-commands-in-parallel"><a class="header" href="#q-how-do-i-run-commands-in-parallel">Q: How do I run commands in parallel?</a></h3>
<p><strong>A:</strong> Use MapReduce mode with <code>max_parallel</code>:</p>
<pre><code class="language-yaml">mode: mapreduce
map:
  max_parallel: 5
</code></pre>
<h3 id="q-can-i-nest-workflows"><a class="header" href="#q-can-i-nest-workflows">Q: Can I nest workflows?</a></h3>
<p><strong>A:</strong> Not directly, but you can use <code>shell</code> commands to invoke other workflows:</p>
<pre><code class="language-yaml">- shell: "prodigy run other-workflow.yml"
</code></pre>
<hr />
<h2 id="common-error-messages"><a class="header" href="#common-error-messages">Common Error Messages</a></h2>
<h3 id="mapreduceerror-types"><a class="header" href="#mapreduceerror-types">MapReduceError Types</a></h3>
<p>Prodigy uses structured errors to help diagnose issues:</p>
<p><strong>Job-level errors:</strong></p>
<ul>
<li><code>JobNotFound</code> - Job ID doesn’t exist, check job_id spelling or if job was cleaned up</li>
<li><code>InvalidJobConfiguration</code> - Workflow YAML has configuration errors</li>
<li><code>WorktreeSetupFailed</code> - Failed to create git worktree, check disk space and git status</li>
</ul>
<p><strong>Agent-level errors:</strong></p>
<ul>
<li><code>AgentFailed</code> - Individual agent execution failed, check DLQ for details</li>
<li><code>AgentTimeout</code> - Agent exceeded timeout, increase agent_timeout_secs</li>
<li><code>CommandExecutionFailed</code> - Shell or Claude command failed in agent</li>
</ul>
<p><strong>Resource errors:</strong></p>
<ul>
<li><code>WorktreeMergeConflict</code> - Git merge conflict when merging agent results</li>
<li><code>ResourceExhausted</code> - Out of disk space, memory, or other resources</li>
<li><code>StorageError</code> - Failed to read/write to storage, check permissions</li>
</ul>
<p><strong>Recovery actions:</strong></p>
<ul>
<li>Check event logs: <code>prodigy events &lt;job_id&gt;</code></li>
<li>Review DLQ: <code>prodigy dlq list &lt;job_id&gt;</code></li>
<li>View detailed state: <code>cat ~/.prodigy/state/{repo}/mapreduce/jobs/{job_id}/checkpoint.json</code></li>
</ul>
<h3 id="checkpoint-and-resume-errors"><a class="header" href="#checkpoint-and-resume-errors">Checkpoint and Resume Errors</a></h3>
<p><strong>“Checkpoint not found”</strong></p>
<ul>
<li>Cause: No checkpoint file exists for this job</li>
<li>Solution: Job may have completed or checkpoint was deleted, start fresh</li>
</ul>
<p><strong>“Failed to resume from checkpoint”</strong></p>
<ul>
<li>Cause: Checkpoint file is corrupted or format changed</li>
<li>Solution: Check checkpoint JSON syntax, may need to start over</li>
</ul>
<p><strong>“Worktree conflicts during merge”</strong></p>
<ul>
<li>Cause: Git merge conflicts when combining agent results</li>
<li>Solution: Resolve conflicts manually in worktree, then retry merge</li>
</ul>
<h3 id="variable-and-capture-errors"><a class="header" href="#variable-and-capture-errors">Variable and Capture Errors</a></h3>
<p><strong>“Variable not found: ${variable_name}”</strong></p>
<ul>
<li>Cause: Variable not defined or out of scope</li>
<li>Solution: Check variable is defined before use, verify scope (workflow vs item vs capture)</li>
</ul>
<p><strong>“Failed to parse capture output as {format}”</strong></p>
<ul>
<li>Cause: Command output doesn’t match capture_format</li>
<li>Solution: Check output manually, adjust capture_format or command output</li>
</ul>
<p><strong>“JSONPath expression failed”</strong></p>
<ul>
<li>Cause: Invalid JSONPath syntax or doesn’t match data structure</li>
<li>Solution: Test with <code>jq</code> command, simplify expression, check input data format</li>
</ul>
<hr />
<h2 id="best-practices-for-debugging"><a class="header" href="#best-practices-for-debugging">Best Practices for Debugging</a></h2>
<ol>
<li><strong>Start simple</strong>: Test commands individually before adding to workflow</li>
<li><strong>Use verbosity flags</strong>: Use <code>-v</code> to see Claude interactions, <code>-vv</code> for debug logs, <code>-vvv</code> for trace</li>
<li><strong>Use echo liberally</strong>: Debug variable values with echo statements</li>
<li><strong>Check logs and state</strong>: Review event logs (<code>~/.prodigy/events/</code>) and session state (<code>.prodigy/session_state.json</code>)</li>
<li><strong>Test incrementally</strong>: Add commands one at a time and test after each</li>
<li><strong>Validate input data</strong>: Ensure JSON files and data formats are correct before MapReduce</li>
<li><strong>Check DLQ regularly</strong>: Monitor failed items with <code>prodigy dlq list</code> and retry when appropriate</li>
<li><strong>Monitor resources</strong>: Check disk space, memory, and CPU during execution</li>
<li><strong>Version control</strong>: Commit working workflows before making changes</li>
<li><strong>Read error messages carefully</strong>: MapReduceError types indicate specific failure modes</li>
<li><strong>Ask for help</strong>: Include full error messages, workflow config, and verbosity output when seeking support</li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
