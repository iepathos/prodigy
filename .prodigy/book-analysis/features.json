{
  "metadata": {
    "project_name": "Prodigy",
    "analyzed_version": "0.3.0+",
    "analysis_date": "2025-01-11",
    "analysis_source": "Comprehensive codebase analysis covering workflow system, MapReduce, command types, variables, and advanced features"
  },
  "workflow_basics": {
    "structure": {
      "simple_array": "Direct command array format for straightforward workflows",
      "full_config": "Object format with env, secrets, profiles, and merge configuration",
      "supported_formats": ["YAML", "JSON"]
    },
    "execution_model": {
      "sequential": "Commands execute in order",
      "commit_tracking": "Automatic git integration tracks all changes",
      "worktree_isolation": "Each workflow runs in isolated git worktree",
      "session_management": "UnifiedSession tracks state across execution"
    },
    "command_types_supported": ["claude", "shell", "goal_seek", "foreach", "write_file", "validate"],
    "workflow_naming": "Optional name field for identification"
  },
  "mapreduce": {
    "phases": {
      "setup": {
        "description": "Optional preparation phase before map",
        "features": ["command execution", "timeout control", "variable capture"],
        "configuration": ["commands", "timeout", "capture_outputs"]
      },
      "map": {
        "description": "Parallel processing of work items",
        "features": ["parallel execution", "work distribution", "agent worktrees", "agent merge"],
        "configuration": ["input", "json_path", "agent_template", "max_parallel", "filter", "sort_by", "max_items", "offset", "distinct", "agent_timeout_secs", "timeout_config"]
      },
      "reduce": {
        "description": "Aggregation phase after map completes",
        "features": ["access to map results", "sequential execution"],
        "configuration": ["commands", "timeout_secs"]
      },
      "merge": {
        "description": "Custom merge workflow for worktree integration",
        "features": ["merge variables", "validation", "conflict resolution"],
        "configuration": ["commands", "timeout"]
      }
    },
    "capabilities": {
      "parallel_execution": "Multiple agents process items concurrently",
      "work_distribution": "Automatic distribution across agents based on max_parallel",
      "result_aggregation": "Map results available as ${map.results} in reduce",
      "checkpoint_resume": "Full checkpoint and resume support for all phases",
      "worktree_hierarchy": "Parent worktree for setup/reduce, child worktrees for agents",
      "agent_merge": "Agents merge to parent worktree, parent merges to master",
      "dlq_support": "Failed items sent to Dead Letter Queue for retry",
      "event_streaming": "Real-time event tracking for monitoring",
      "cleanup_failure_handling": "Graceful handling of worktree cleanup failures"
    },
    "input_processing": {
      "json_path": "JSONPath expressions for item extraction",
      "filter": "Filter items with expressions",
      "sort_by": "Sort items before processing (field ASC/DESC)",
      "max_items": "Limit number of items to process",
      "offset": "Skip initial items",
      "distinct": "Deduplicate items by field"
    },
    "configuration": {
      "max_parallel": "Number of concurrent agents (supports env vars)",
      "agent_timeout_secs": "Timeout per agent execution",
      "timeout_config": "Advanced timeout configuration",
      "error_policy": "Workflow-level error handling",
      "environment": "Shared environment variables across phases"
    }
  },
  "command_types": {
    "claude": {
      "description": "Execute Claude AI commands via CLI",
      "fields": ["claude", "commit_required", "validate", "when"],
      "features": ["JSON streaming output", "log location tracking", "verbose mode control"],
      "use_cases": ["Code generation", "Analysis", "Refactoring", "Review", "Documentation"]
    },
    "shell": {
      "description": "Execute shell commands",
      "fields": ["shell", "timeout", "capture_output", "capture_format", "capture_streams", "on_failure", "output_file", "when"],
      "features": ["Output capture", "Error handling", "Timeout control", "Exit code tracking"],
      "use_cases": ["Build", "Test", "Deploy", "Data processing", "Validation"]
    },
    "goal_seek": {
      "description": "Iterative refinement to reach quality threshold",
      "fields": ["goal", "claude", "shell", "validate", "threshold", "max_attempts", "timeout_seconds", "fail_on_incomplete"],
      "features": ["Score-based convergence", "Automatic retry", "Progress tracking"],
      "use_cases": ["Coverage improvement", "Performance optimization", "Quality gates"]
    },
    "foreach": {
      "description": "Iterate over lists with optional parallelism",
      "fields": ["foreach", "do", "parallel", "continue_on_error", "max_items"],
      "features": ["Parallel execution", "Error handling", "Item filtering"],
      "use_cases": ["File processing", "Batch operations", "Multi-target deployment"]
    },
    "write_file": {
      "description": "Write content to files with format support",
      "fields": ["path", "content", "format", "mode", "create_dirs"],
      "formats": ["text", "json", "yaml"],
      "features": ["Variable interpolation", "JSON validation", "YAML formatting", "Permission control"],
      "use_cases": ["Configuration generation", "Report creation", "Data export"]
    },
    "validate": {
      "description": "Check implementation completeness",
      "fields": ["validate", "threshold", "on_incomplete"],
      "features": ["Requirement tracking", "Gap detection", "Completion scoring"],
      "use_cases": ["Spec validation", "Documentation checks", "Feature completeness"]
    }
  },
  "variables": {
    "standard": {
      "last.output": "Output from last command",
      "last.exit_code": "Exit code from last command",
      "shell.output": "Output from last shell command",
      "claude.output": "Output from last Claude command",
      "item": "Current work item (all execution modes)",
      "item_index": "Zero-based index of current item",
      "item_total": "Total number of items"
    },
    "mapreduce": {
      "item.*": "Access work item fields (e.g., ${item.path}, ${item.name})",
      "map.results": "Aggregated results from map phase",
      "map.total": "Total items in map phase",
      "map.successful": "Successfully processed items",
      "map.failed": "Failed items",
      "worker.id": "Parallel worker ID",
      "map.key": "Key for map output"
    },
    "validation": {
      "validation.completion": "Completion percentage (0-100)",
      "validation.gaps": "Missing requirements",
      "validation.status": "Status (complete/incomplete/failed)",
      "validation.missing_count": "Number of missing items"
    },
    "git_context": {
      "git.branch": "Current git branch",
      "git.commit": "Current commit hash",
      "git.modified_files": "List of modified files",
      "git.staged_files": "List of staged files",
      "git.unstaged_files": "List of unstaged files"
    },
    "merge": {
      "merge.worktree": "Name of worktree being merged",
      "merge.source_branch": "Source branch (worktree branch)",
      "merge.target_branch": "Target branch (original branch)",
      "merge.session_id": "Session ID for correlation"
    },
    "workflow_metadata": {
      "workflow.name": "Workflow name",
      "workflow.id": "Workflow ID",
      "workflow.iteration": "Current iteration number",
      "step.name": "Current step name",
      "step.index": "Current step index"
    },
    "capture_formats": ["string", "json", "lines", "number", "boolean"],
    "interpolation": {
      "syntax": ["${var}", "$VAR"],
      "nested_access": "${map.results.status}",
      "defaults": "${var|default:fallback}"
    }
  },
  "environment": {
    "global_env": {
      "description": "Workflow-level environment variables",
      "features": ["Static values", "Variable interpolation", "Profile-specific values"]
    },
    "secrets": {
      "description": "Masked in logs and output",
      "features": ["Secret masking", "Provider support", "Profile-specific secrets"],
      "fields": ["secret", "value", "provider"]
    },
    "profiles": {
      "description": "Environment-specific configurations",
      "use_cases": ["dev", "staging", "production"],
      "activation": "--profile flag on CLI"
    },
    "step_env": {
      "description": "Command-level environment overrides",
      "features": ["Per-command variables", "Inherit from global", "Temporary scope"]
    },
    "env_files": {
      "description": "Load variables from .env files",
      "format": "dotenv format",
      "features": ["Multiple files", "Variable expansion", "Profile-specific"]
    }
  },
  "advanced_features": {
    "conditional_execution": {
      "when": "Expression-based conditional execution",
      "examples": ["${env} == 'production'", "${build.success} == true"],
      "features": ["Variable comparison", "Boolean logic", "Complex expressions"]
    },
    "output_capture": {
      "formats": ["string", "json", "lines", "number", "boolean"],
      "streams": ["stdout", "stderr", "exit_code", "success", "duration"],
      "features": ["Named capture", "Format conversion", "Nested access"],
      "variable_names": "Custom variable names for captured output"
    },
    "nested_handlers": {
      "on_success": "Execute on command success",
      "on_failure": "Execute on command failure",
      "on_exit_code": "Map exit codes to handlers",
      "features": ["Nested command execution", "Error recovery", "Conditional flow"]
    },
    "timeout_control": {
      "levels": ["command", "workflow", "phase", "agent"],
      "features": ["Graceful termination", "Timeout propagation", "Custom timeout handling"]
    },
    "working_directory": {
      "cwd": "Per-command working directory",
      "features": ["Relative paths", "Variable interpolation", "Automatic directory creation"]
    },
    "git_context_advanced": {
      "pattern_filtering": "Filter files by glob patterns",
      "format_modifiers": "Transform file paths",
      "combined_filters": "Multiple filter criteria",
      "examples": ["${git.modified_files|pattern:**/*.rs}", "${git.staged_files|basename}"]
    },
    "workflow_composition": {
      "imports": "Import and reuse workflow templates",
      "extends": "Inherit from base workflows",
      "parameters": "Parameterized workflow templates",
      "sub_workflows": "Nested workflow execution",
      "registry": "Template storage and versioning",
      "features": ["Template reuse", "Version control", "Parameter validation"]
    }
  },
  "error_handling": {
    "workflow_level": {
      "on_item_failure": {
        "options": ["dlq", "retry", "skip", "stop", "custom"],
        "description": "Action to take when work item fails"
      },
      "error_collection": {
        "strategies": ["aggregate", "immediate", "batched"],
        "description": "How to collect and report errors"
      },
      "circuit_breaker": {
        "features": ["Failure threshold", "Success threshold", "Timeout", "Half-open state"],
        "description": "Prevent cascading failures"
      },
      "max_failures": "Stop after N failures",
      "failure_threshold": "Stop after failure rate exceeds threshold (0.0-1.0)",
      "continue_on_failure": "Whether to continue after failures"
    },
    "command_level": {
      "on_failure": {
        "description": "Nested command to execute on failure",
        "features": ["Error recovery", "Debugging", "Retry logic"],
        "fields": ["claude", "max_attempts", "fail_workflow", "commit_required"]
      },
      "on_success": {
        "description": "Execute command on success",
        "features": ["Success handlers", "Conditional flow"]
      },
      "on_exit_code": {
        "description": "Map exit codes to actions",
        "features": ["Custom exit code handling", "Conditional execution"]
      }
    },
    "retry_configuration": {
      "max_attempts": "Maximum retry attempts",
      "backoff_strategies": {
        "fixed": "Fixed delay between retries",
        "linear": "Linear increase in delay",
        "exponential": "Exponential backoff",
        "fibonacci": "Fibonacci sequence delays"
      },
      "retry_budget": "Limit total retry attempts across workflow",
      "conditional_retry": "Retry only on specific errors",
      "jitter": "Add randomness to backoff"
    },
    "dlq": {
      "description": "Dead Letter Queue for failed items",
      "features": ["Failure tracking", "Retry support", "Error analysis", "Parallel retry"],
      "commands": ["prodigy dlq show", "prodigy dlq retry", "prodigy dlq clear"]
    }
  },
  "configuration": {
    "file_locations": {
      "global": "~/.prodigy/config.toml",
      "project": ".prodigy/config.toml",
      "precedence": "project > global > defaults"
    },
    "claude_settings": {
      "streaming": "Enable/disable JSON streaming",
      "console_output": "Force console output in automation",
      "log_location": "Custom log location"
    },
    "worktree_settings": {
      "location": "Custom worktree directory",
      "cleanup": "Automatic cleanup on completion",
      "branch_naming": "Custom branch naming pattern"
    },
    "storage_settings": {
      "mode": ["local", "global"],
      "location": "Custom storage directory",
      "event_storage": "Event log location"
    },
    "retry_defaults": {
      "max_attempts": "Default retry attempts",
      "backoff": "Default backoff strategy",
      "timeout": "Default command timeout"
    }
  },
  "best_practices": {
    "workflow_design": [
      "Keep workflows simple and focused on single responsibility",
      "Use validation steps for quality gates",
      "Handle errors gracefully with on_failure handlers",
      "Capture important outputs for debugging",
      "Use descriptive names for commands and variables",
      "Leverage environment variables for configuration",
      "Use profiles for environment-specific behavior"
    ],
    "mapreduce": [
      "Set appropriate parallelism based on resource constraints",
      "Use DLQ for failed items to enable retry",
      "Monitor execution with event logs",
      "Design idempotent work items for safe retry",
      "Use setup phase for shared data preparation",
      "Filter and sort items to optimize processing order",
      "Use distinct to avoid duplicate work",
      "Set agent timeouts to prevent hanging agents"
    ],
    "testing": [
      "Include test steps in workflows",
      "Use on_failure for automatic debugging",
      "Validate before deploying changes",
      "Test with small batches before full runs",
      "Use dry-run mode when available"
    ],
    "error_handling": [
      "Set appropriate failure thresholds",
      "Use circuit breakers for external dependencies",
      "Collect errors for analysis",
      "Provide meaningful error messages",
      "Use DLQ for automatic retry capabilities"
    ],
    "performance": [
      "Optimize max_parallel for your workload",
      "Use filters to reduce work items",
      "Set appropriate timeouts",
      "Use checkpoints for long-running workflows",
      "Monitor resource usage with events"
    ]
  },
  "common_patterns": [
    {
      "name": "Build and Test",
      "description": "Standard CI workflow with validation",
      "structure": "build -> test -> validate -> deploy",
      "features": ["error handling", "output capture", "conditional execution"]
    },
    {
      "name": "Parallel Processing",
      "description": "MapReduce for independent work items",
      "structure": "setup -> map (parallel) -> reduce",
      "features": ["parallel execution", "result aggregation", "DLQ"]
    },
    {
      "name": "Goal Seeking",
      "description": "Iterative improvement to quality threshold",
      "structure": "goal_seek with validate",
      "features": ["threshold-based", "automatic retry", "convergence detection"]
    },
    {
      "name": "Multi-Environment Deployment",
      "description": "Deploy to multiple environments with profiles",
      "structure": "foreach environments with profiles",
      "features": ["profile switching", "parallel deployment", "rollback"]
    },
    {
      "name": "Documentation Automation",
      "description": "Automated book documentation workflow",
      "structure": "analyze features -> detect drift -> fix gaps -> validate",
      "features": ["gap detection", "MapReduce for chapters", "validation"]
    }
  ],
  "troubleshooting": {
    "common_issues": [
      {
        "issue": "Variables not interpolating",
        "causes": ["Incorrect syntax", "Variable not captured", "Scope issues"],
        "solutions": [
          "Check ${} syntax is correct",
          "Verify variable is available in scope",
          "Use capture_output to capture command output",
          "Check variable names match exactly"
        ]
      },
      {
        "issue": "MapReduce items not found",
        "causes": ["Invalid JSONPath", "Empty input file", "Wrong input format"],
        "solutions": [
          "Verify JSONPath expression with online tools",
          "Check input file exists and has content",
          "Ensure input is valid JSON",
          "Use json_path field explicitly"
        ]
      },
      {
        "issue": "Timeout errors",
        "causes": ["Agent taking too long", "Network issues", "Resource constraints"],
        "solutions": [
          "Increase agent_timeout_secs",
          "Optimize agent commands",
          "Reduce max_parallel to lower resource usage",
          "Check network connectivity"
        ]
      },
      {
        "issue": "Worktree cleanup failures",
        "causes": ["File locks", "Permission issues", "Disk full"],
        "solutions": [
          "Check for running processes using worktree",
          "Verify file permissions",
          "Ensure sufficient disk space",
          "Use 'prodigy worktree clean-orphaned' to retry cleanup"
        ]
      },
      {
        "issue": "DLQ items not retrying",
        "causes": ["Missing job ID", "Invalid item data", "Workflow changed"],
        "solutions": [
          "Verify job ID with 'prodigy dlq show'",
          "Check DLQ item format",
          "Use --dry-run to preview retry",
          "Ensure workflow file still exists"
        ]
      },
      {
        "issue": "Resume not working",
        "causes": ["No checkpoint found", "Corrupted state", "Session mismatch"],
        "solutions": [
          "Check ~/.prodigy/state/ for checkpoints",
          "Verify session ID matches",
          "Use 'prodigy sessions list' to find sessions",
          "Check for concurrent resume locks"
        ]
      }
    ]
  },
  "mapreduce_worktree_architecture": {
    "worktree_hierarchy": {
      "parent_worktree": "Created from original branch, runs setup and reduce",
      "agent_worktrees": "Child worktrees branch from parent, process individual items",
      "isolation": "Each agent has independent git state and filesystem"
    },
    "branch_naming": {
      "parent": "prodigy-session-{session_id}",
      "agent": "agent-{agent_id}-{session_id}",
      "original_branch": "Branch user was on when workflow started"
    },
    "merge_flow": {
      "agent_to_parent": "Agents merge changes to parent after completion",
      "parent_to_original": "Parent merges to original branch with user confirmation",
      "conflict_resolution": "Custom merge workflow for validation and conflict handling"
    },
    "debugging": {
      "verify_main_clean": "git status in main repo should show clean",
      "verify_parent_changes": "cd to parent worktree and check git log",
      "verify_agent_work": "cd to agent worktree to inspect changes",
      "event_logs": "Check ~/.prodigy/events/{repo}/{job_id}/ for execution events"
    }
  },
  "automated_documentation": {
    "workflow_setup": {
      "workflow_file": "MapReduce workflow for parallel chapter processing",
      "phases": ["analyze features", "detect drift per chapter", "fix gaps", "validate"],
      "features": ["gap detection", "drift detection", "automatic fixes", "validation loop"]
    },
    "book_config_structure": {
      "project_name": "Display name of project",
      "book_dir": "Book root directory",
      "analysis_targets": "Areas to analyze with source files and categories",
      "chapter_file": "Chapter definitions JSON",
      "custom_analysis": "Options for examples, best practices, troubleshooting"
    },
    "claude_commands": {
      "analyze_features": "Comprehensive feature inventory from codebase",
      "analyze_drift": "Detect missing features in chapter",
      "fix_drift": "Add missing content to chapter",
      "fix_build_errors": "Resolve mdBook build issues"
    },
    "customization": {
      "analysis_targets": "Configure which code areas to analyze",
      "chapter_definitions": "Define book structure and expected content",
      "feature_categories": "Specify what features to extract per area",
      "depth_levels": "Control thoroughness (quick, medium, very thorough)"
    }
  },
  "spec_coverage": [
    "101: Error Handling Guidelines",
    "110: Branch Tracking",
    "120: Environment Variables",
    "121: Claude Command Observability",
    "126: Viewing Claude Execution Logs",
    "127: Worktree Isolation",
    "131: Workflow Template Execution Layer",
    "132: Workflow Template CLI Interface",
    "133: Workflow Template Integration Polish",
    "134: MapReduce Checkpoint and Resume",
    "136: Cleanup Failure Handling",
    "140: Concurrent Resume Protection"
  ]
}
