{
  "workflow_basics": {
    "structure": {
      "simple_array": "Direct command array without wrapper object",
      "full_config": "Configuration object with commands, env, secrets, and profiles fields",
      "formats_supported": [
        "simple_array",
        "full_config",
        "with_commands_field"
      ]
    },
    "execution_model": {
      "sequential": "Commands execute in order",
      "commit_tracking": "Each successful command creates a git commit for audit trail",
      "worktree_isolation": "Workflows execute in isolated git worktrees"
    },
    "command_formats": {
      "simple_string": "Direct command string (legacy)",
      "workflow_step": "Object with claude/shell/goal_seek/foreach/write_file fields",
      "structured": "Full Command object with args, options, metadata"
    }
  },
  "mapreduce": {
    "phases": {
      "setup": {
        "description": "Optional initialization phase that runs once before map",
        "configuration": [
          "commands",
          "timeout",
          "capture_outputs"
        ],
        "worktree": "Executes in dedicated parent worktree",
        "use_cases": [
          "Generate work items",
          "Analyze codebase",
          "Setup environment"
        ]
      },
      "map": {
        "description": "Process work items in parallel across multiple agents",
        "configuration": [
          "input",
          "json_path",
          "agent_template",
          "max_parallel",
          "filter",
          "sort_by",
          "max_items",
          "offset",
          "distinct",
          "agent_timeout_secs",
          "timeout_config"
        ],
        "worktree": "Each agent executes in child worktree branched from setup",
        "use_cases": [
          "Parallel code fixes",
          "Batch file processing",
          "Distributed analysis"
        ]
      },
      "reduce": {
        "description": "Aggregate results from all map agents",
        "configuration": [
          "commands",
          "timeout_secs"
        ],
        "worktree": "Executes in parent worktree (same as setup)",
        "use_cases": [
          "Generate summary reports",
          "Merge results",
          "Validate completion"
        ]
      },
      "merge": {
        "description": "Optional custom merge workflow for worktree integration",
        "configuration": [
          "commands",
          "timeout"
        ],
        "variables": [
          "merge.worktree",
          "merge.source_branch",
          "merge.target_branch",
          "merge.session_id"
        ],
        "use_cases": [
          "Pre-merge validation",
          "Conflict resolution",
          "Custom merge strategies"
        ]
      }
    },
    "capabilities": {
      "parallel_execution": "Distribute work across multiple Claude agents concurrently",
      "work_distribution": "Automatic based on max_parallel setting",
      "result_aggregation": "Collected in reduce phase via map.results variable",
      "checkpoint_resume": "Resume interrupted jobs from last checkpoint",
      "event_tracking": "Comprehensive event logs for debugging",
      "dlq_support": "Failed items sent to Dead Letter Queue for retry",
      "worktree_isolation": "All phases execute in isolated worktrees"
    },
    "work_item_processing": {
      "input_sources": [
        "JSON files",
        "Shell command output"
      ],
      "json_path": "JSONPath expressions to extract items from input",
      "filtering": "Filter items with expressions like 'severity == high'",
      "sorting": "Sort items by field (e.g., 'priority DESC')",
      "pagination": "max_items for limit, offset for skipping",
      "deduplication": "distinct field to deduplicate by"
    },
    "syntax_formats": {
      "agent_template": {
        "simplified": "Direct array of commands (preferred)",
        "nested": "Commands nested under 'commands' key (legacy)"
      },
      "reduce": {
        "simplified": "Direct array of commands (preferred)",
        "nested": "Commands nested under 'commands' key (legacy)"
      },
      "setup": {
        "simple": "Direct array of commands",
        "full": "Object with commands, timeout, capture_outputs"
      }
    }
  },
  "command_types": {
    "shell": {
      "description": "Execute shell commands",
      "fields": [
        "shell",
        "timeout",
        "capture_output",
        "capture_format",
        "capture_streams",
        "output_file",
        "on_failure",
        "on_success",
        "when"
      ],
      "use_cases": [
        "Build",
        "Test",
        "Deploy",
        "Data processing",
        "File operations"
      ]
    },
    "claude": {
      "description": "Execute Claude AI commands via Claude Code CLI",
      "fields": [
        "claude",
        "commit_required",
        "on_failure",
        "on_success",
        "validate",
        "when"
      ],
      "use_cases": [
        "Code generation",
        "Refactoring",
        "Analysis",
        "Documentation",
        "Bug fixes"
      ],
      "environment": [
        "PRODIGY_AUTOMATION=true",
        "PRODIGY_CLAUDE_STREAMING=true (with -v)"
      ]
    },
    "goal_seek": {
      "description": "Iterative refinement with validation until quality threshold reached",
      "fields": [
        "goal",
        "claude",
        "shell",
        "validate",
        "threshold",
        "max_attempts",
        "timeout_seconds",
        "fail_on_incomplete"
      ],
      "use_cases": [
        "Coverage improvement",
        "Performance optimization",
        "Quality gates",
        "Spec implementation"
      ],
      "validation": "Returns score 0-100, compared against threshold"
    },
    "foreach": {
      "description": "Iterate over lists with optional parallel execution",
      "fields": [
        "foreach (input)",
        "do",
        "parallel",
        "continue_on_error",
        "max_items"
      ],
      "input_sources": [
        "Command output",
        "Static list"
      ],
      "parallel_config": [
        "Boolean (true/false)",
        "Number (specific count)"
      ],
      "use_cases": [
        "File batch processing",
        "Multiple commands on list",
        "Parallel operations"
      ]
    },
    "write_file": {
      "description": "Write files with format validation and permissions",
      "fields": [
        "path",
        "content",
        "format",
        "mode",
        "create_dirs"
      ],
      "formats": [
        "text",
        "json",
        "yaml"
      ],
      "use_cases": [
        "Generate config files",
        "Create reports",
        "Write data files"
      ]
    },
    "validate": {
      "description": "Check implementation completeness against requirements",
      "fields": [
        "validate",
        "threshold",
        "fail_on_incomplete"
      ],
      "use_cases": [
        "Spec validation",
        "Quality checks",
        "Completeness verification"
      ]
    },
    "conditional_handlers": {
      "on_failure": "Execute commands when step fails",
      "on_success": "Execute commands when step succeeds",
      "on_exit_code": "Map specific exit codes to actions",
      "when": "Conditional execution based on expression"
    }
  },
  "variables": {
    "standard": {
      "last.output": "Output from most recent command",
      "last.exit_code": "Exit code from most recent command",
      "shell.output": "Output from shell command",
      "claude.output": "Output from Claude command"
    },
    "item_processing": {
      "item": "Current work item being processed",
      "item.value": "Value of current item",
      "item.path": "File path for file items",
      "item.name": "Display name of item",
      "item_index": "Zero-based index of current item",
      "item_total": "Total number of items"
    },
    "mapreduce": {
      "map.results": "Aggregated results from all map agents",
      "map.total": "Total items processed",
      "map.successful": "Successfully processed items",
      "map.failed": "Failed items count",
      "map.key": "Key for map output",
      "worker.id": "Parallel worker ID"
    },
    "workflow_context": {
      "workflow.name": "Name of current workflow",
      "workflow.id": "Unique workflow ID",
      "workflow.iteration": "Current iteration number"
    },
    "step_context": {
      "step.name": "Current step name",
      "step.index": "Current step index"
    },
    "merge_context": {
      "merge.worktree": "Name of worktree being merged",
      "merge.source_branch": "Source branch (worktree branch)",
      "merge.target_branch": "Target branch (usually main/master)",
      "merge.session_id": "Session ID for correlation"
    },
    "git_context": {
      "git.files": "Modified files in worktree",
      "git.files.added": "Newly added files",
      "git.files.modified": "Modified existing files",
      "git.files.deleted": "Deleted files",
      "git.branch": "Current git branch",
      "git.commit": "Latest commit hash"
    },
    "validation": {
      "validation.completion": "Completion percentage (0-100)",
      "validation.gaps": "Missing requirements",
      "validation.status": "Status (complete/incomplete/failed)"
    },
    "interpolation": {
      "syntax": [
        "variable_syntax_dollar_brace",
        "variable_syntax_dollar"
      ],
      "nested_access": "Access nested fields with dot notation",
      "defaults": "Use pipe and default keyword for fallback values",
      "wildcards": "Use wildcards for file patterns"
    }
  },
  "environment": {
    "global_env": {
      "description": "Static and dynamic environment variables for all commands",
      "types": [
        "Static values",
        "Dynamic from commands",
        "Conditional based on expressions"
      ],
      "scope": "Available to all workflow steps"
    },
    "secrets": {
      "description": "Secret values masked in logs and outputs",
      "providers": [
        "Environment variables",
        "Files",
        "Secret stores"
      ],
      "masking": "Automatically masked in command output and logs"
    },
    "profiles": {
      "description": "Environment-specific configurations",
      "examples": [
        "development",
        "staging",
        "production"
      ],
      "activation": "Via --profile flag on CLI"
    },
    "step_env": {
      "description": "Step-level environment overrides",
      "scope": "Applied only to specific step",
      "temporary": "Can be marked temporary to restore after step"
    },
    "env_files": {
      "description": "Load variables from .env files",
      "format": "KEY=value pairs",
      "precedence": "Loaded before workflow env, overridden by step env"
    },
    "working_directory": {
      "description": "Control working directory per command",
      "resolution": "Supports tilde expansion and environment variable interpolation",
      "scope": "Per-step configuration"
    }
  },
  "advanced_features": {
    "conditional_execution": {
      "when_clause": "Execute step only if expression is true",
      "syntax_example": "when expression for environment production",
      "use_cases": [
        "Environment-specific steps",
        "Conditional deployment",
        "Feature flags"
      ]
    },
    "output_capture": {
      "formats": [
        "string",
        "number",
        "json",
        "lines",
        "boolean"
      ],
      "streams": [
        "stdout",
        "stderr",
        "both"
      ],
      "metadata": [
        "exit_code",
        "success",
        "duration"
      ],
      "usage": "Captured values available as variables in subsequent steps"
    },
    "nested_conditionals": {
      "on_success": "Execute nested commands on success",
      "on_failure": "Execute nested commands on failure",
      "on_exit_code": "Map specific exit codes to different actions",
      "chaining": "Can nest multiple levels of handlers"
    },
    "timeout_control": {
      "command_level": "Timeout for individual commands",
      "workflow_level": "Timeout for entire workflow",
      "phase_level": "Timeout for setup/map/reduce phases",
      "units": "Seconds"
    },
    "git_context_advanced": {
      "pattern_filtering": "Filter files by glob patterns",
      "format_modifiers": "Access specific file properties",
      "combined_filters": "Combine multiple filters with AND/OR",
      "examples": [
        "Filter by Rust files",
        "Filter modified files in src"
      ]
    },
    "worktree_management": {
      "automatic_creation": "Create worktrees for each session",
      "branch_tracking": "Track original branch for merge target",
      "cleanup": "Automatic cleanup after successful merge",
      "locations": "In .prodigy/worktrees subdirectory"
    }
  },
  "error_handling": {
    "workflow_level": {
      "on_item_failure": {
        "options": [
          "dlq",
          "retry",
          "skip",
          "stop",
          "custom"
        ],
        "default": "dlq"
      },
      "continue_on_failure": "Whether to continue after failures (default: true)",
      "max_failures": "Stop after N failures",
      "failure_threshold": "Stop if failure rate exceeds threshold (0.0-1.0)",
      "error_collection": {
        "strategies": [
          "aggregate",
          "immediate",
          "batched"
        ],
        "use_cases": [
          "Collect all errors",
          "Report as they occur",
          "Report in batches"
        ]
      },
      "circuit_breaker": {
        "failure_threshold": "Number of failures to trigger open state",
        "success_threshold": "Number of successes to close circuit",
        "timeout": "Duration before attempting to close",
        "half_open_requests": "Requests allowed in half-open state"
      }
    },
    "command_level": {
      "on_failure": "Nested commands to execute on failure",
      "on_success": "Nested commands to execute on success",
      "on_exit_code": "Map exit codes to specific actions",
      "continue_on_error": "Continue workflow even if this command fails"
    },
    "dead_letter_queue": {
      "description": "Failed items stored for review and retry",
      "location": "In .prodigy/dlq subdirectory organized by repo and job",
      "commands": [
        "prodigy dlq show",
        "prodigy dlq retry",
        "prodigy dlq clear"
      ],
      "contents": [
        "Original work item",
        "Failure details",
        "Correlation IDs",
        "Claude JSON log location"
      ]
    }
  },
  "retry_configuration": {
    "retry_defaults": {
      "max_attempts": "Maximum retry attempts per command (default: 3)",
      "backoff_strategy": "Strategy for delays between retries"
    },
    "backoff_strategies": {
      "fixed": "Fixed delay between retries",
      "linear": "Linear increase in delay",
      "exponential": "Exponential backoff (default)",
      "fibonacci": "Fibonacci sequence delays"
    },
    "retry_budget": {
      "description": "Limit total retry attempts across workflow",
      "configuration": [
        "max_total_retries",
        "per_item_limit"
      ],
      "use_cases": [
        "Prevent infinite retry loops",
        "Cost control"
      ]
    },
    "conditional_retry": {
      "description": "Retry only for specific error types",
      "examples": [
        "Network errors",
        "Timeout errors",
        "Transient failures"
      ]
    },
    "jitter": {
      "description": "Add randomness to backoff delays",
      "purpose": "Prevent thundering herd problem",
      "implementation": "Randomize delay by percentage"
    }
  },
  "workflow_composition": {
    "imports": {
      "description": "Import commands from other workflow files",
      "syntax": "import: path/to/workflow.yml",
      "use_cases": [
        "Reuse common patterns",
        "Share configurations",
        "Modular workflows"
      ]
    },
    "templates": {
      "description": "Define reusable command templates",
      "parameters": "Support parameterization with default values",
      "instantiation": "Use templates with specific parameter values"
    },
    "extends": {
      "description": "Extend base workflow configurations",
      "override": "Override specific fields from base",
      "use_cases": [
        "Environment variations",
        "Customization"
      ]
    },
    "parameters": {
      "description": "Define workflow parameters for reuse",
      "default_values": "Specify defaults for optional parameters",
      "validation": "Type checking and validation"
    }
  },
  "configuration": {
    "file_locations": {
      "global": "In home directory .prodigy/config.toml",
      "project": "In project .prodigy/config.toml",
      "workflow": "workflow.yml or specified path"
    },
    "precedence": {
      "order": [
        "CLI flags",
        "Environment variables",
        "Project config",
        "Global config",
        "Defaults"
      ],
      "override": "Later sources override earlier ones"
    },
    "claude_settings": {
      "streaming_output": "Control Claude JSON streaming with -v flag or environment",
      "json_log_location": "Displayed after each Claude command execution",
      "automation_mode": "PRODIGY_AUTOMATION=true set for all Claude commands"
    },
    "worktree_settings": {
      "base_path": "In .prodigy/worktrees subdirectory",
      "branch_tracking": "Track original branch for intelligent merge target",
      "cleanup_policy": "Manual or automatic cleanup options"
    },
    "storage_settings": {
      "local": ".prodigy/ (legacy)",
      "global": "In home .prodigy directory (default)",
      "events": "Event logs grouped by repository",
      "dlq": "Dead Letter Queue grouped by repository",
      "state": "Job checkpoints and session state"
    },
    "retry_defaults": {
      "max_attempts": "Default retry attempts (3)",
      "backoff": "Default backoff strategy (exponential)"
    }
  },
  "git_context_advanced": {
    "pattern_filtering": {
      "description": "Filter files using glob patterns",
      "syntax": "Use brackets for patterns in variable references",
      "examples": [
        "*.rs",
        "src/**/*.ts",
        "*.{rs,toml}"
      ]
    },
    "format_modifiers": {
      "description": "Access specific file properties",
      "available": [
        "basename",
        "dirname",
        "extension",
        "relative"
      ],
      "syntax": "Access via dot notation on git.files"
    },
    "file_patterns": {
      "added": "git.files.added with pattern",
      "modified": "git.files.modified with pattern",
      "deleted": "git.files.deleted with pattern",
      "all": "git.files with pattern"
    },
    "combined_filters": {
      "description": "Combine multiple filters",
      "operators": [
        "AND",
        "OR",
        "NOT"
      ],
      "examples": [
        "Rust files in src",
        "TypeScript or TSX files"
      ]
    }
  },
  "automated_documentation": {
    "workflow_setup": {
      "description": "MapReduce workflow for maintaining documentation in sync with code",
      "file": "workflows/book-docs-drift.yml",
      "phases": [
        "analyze",
        "detect_drift",
        "fix_drift",
        "build_verification"
      ]
    },
    "book_config_structure": {
      "description": "Configuration file defining documentation targets and structure",
      "file": ".prodigy/book-config.json",
      "fields": [
        "project_name",
        "project_type",
        "book_dir",
        "analysis_targets",
        "chapter_file",
        "custom_analysis"
      ]
    },
    "chapter_definitions": {
      "description": "JSON file mapping documentation chapters to work items",
      "file": "workflows/data/prodigy-chapters.json",
      "structure": [
        "chapter_id",
        "title",
        "file_path",
        "description",
        "dependencies"
      ]
    },
    "claude_commands": {
      "analyze_features": "/prodigy-analyze-features-for-book",
      "detect_drift": "/prodigy-analyze-book-chapter-drift",
      "fix_drift": "/prodigy-fix-book-drift",
      "fix_build_errors": "/prodigy-fix-book-build-errors"
    },
    "mapreduce_phases": {
      "setup": "Analyze codebase features and generate feature inventory",
      "map": "Detect drift for each chapter in parallel",
      "reduce": "Aggregate results and build documentation"
    },
    "github_actions": {
      "description": "CI workflow for continuous documentation validation",
      "triggers": [
        "push",
        "pull_request",
        "schedule"
      ],
      "steps": [
        "Run drift detection",
        "Auto-fix issues",
        "Build book",
        "Deploy"
      ]
    },
    "customization": {
      "analysis_targets": "Configure which code areas to analyze",
      "feature_categories": "Define what aspects to extract from code",
      "custom_analysis": "Enable/disable examples, best practices, troubleshooting"
    }
  },
  "best_practices": {
    "workflow_design": [
      "Keep workflows simple and focused on single purpose",
      "Use validation for quality gates",
      "Handle errors gracefully with on_failure handlers",
      "Capture important outputs for downstream steps",
      "Use meaningful variable names for clarity"
    ],
    "mapreduce": [
      "Set appropriate max_parallel based on resource availability",
      "Use DLQ for failed items to enable retry",
      "Monitor with events for debugging",
      "Design idempotent work items that can be safely retried",
      "Use filter and sort_by to process high-priority items first",
      "Keep agent_template commands focused and testable"
    ],
    "environment": [
      "Use secrets for sensitive data like API keys",
      "Parameterize project-specific values with env vars",
      "Use profiles for environment-specific configurations",
      "Document required environment variables in workflow comments"
    ],
    "error_handling": [
      "Set appropriate continue_on_failure for workflow needs",
      "Use circuit breaker for unstable operations",
      "Configure max_failures to prevent runaway workflows",
      "Leverage DLQ for manual review of complex failures"
    ],
    "testing": [
      "Include test steps in workflows before deployment",
      "Use on_failure for debugging failing tests",
      "Validate before deploying to production",
      "Use goal_seek for iterative quality improvement"
    ]
  },
  "common_patterns": [
    {
      "name": "Build and Test Pipeline",
      "description": "Standard CI workflow with build, test, and quality checks",
      "example": "workflows/complex-build-pipeline.yml",
      "steps": [
        "Checkout code",
        "Build",
        "Run tests",
        "Quality checks",
        "Deploy"
      ]
    },
    {
      "name": "Parallel Processing",
      "description": "MapReduce for processing independent items concurrently",
      "example": "workflows/mapreduce-example.yml",
      "use_case": "Code reviews, debt elimination, batch fixes"
    },
    {
      "name": "Goal Seeking",
      "description": "Iterative improvement to reach quality threshold",
      "example": "workflows/goal-seeking-examples.yml",
      "use_case": "Coverage improvement, performance optimization, spec compliance"
    },
    {
      "name": "Test Debug Cycle",
      "description": "Run tests with automatic debugging on failure",
      "example": "workflows/coverage-with-test-debug.yml",
      "pattern": "shell test with on_failure handler calling claude debug"
    },
    {
      "name": "Documentation Maintenance",
      "description": "Automated drift detection and documentation updates",
      "example": "workflows/book-docs-drift.yml",
      "phases": [
        "Analyze features",
        "Detect drift",
        "Fix issues",
        "Build book"
      ]
    }
  ],
  "troubleshooting": {
    "common_issues": [
      {
        "issue": "Variables not interpolating",
        "symptoms": "Literal variable syntax appears in output",
        "solution": "Check variable syntax and verify variable is available in current scope"
      },
      {
        "issue": "MapReduce items not found",
        "symptoms": "Empty work items or no items to process message",
        "solution": "Verify JSONPath expression matches input structure, check input file exists"
      },
      {
        "issue": "Timeout errors in MapReduce",
        "symptoms": "Agents timing out during execution",
        "solution": "Increase agent_timeout_secs or configure timeout_config with appropriate values"
      },
      {
        "issue": "Claude command fails silently",
        "symptoms": "No output or unclear failure",
        "solution": "Use -v flag for streaming output, check Claude JSON log location displayed after command"
      },
      {
        "issue": "Environment variables not set",
        "symptoms": "Empty or undefined variables in commands",
        "solution": "Check env block syntax, verify profile is activated with --profile flag"
      },
      {
        "issue": "Worktree merge conflicts",
        "symptoms": "Merge fails with conflicts",
        "solution": "Use custom merge workflow with conflict resolution steps"
      },
      {
        "issue": "DLQ items not being processed",
        "symptoms": "Failed items not appearing in DLQ",
        "solution": "Check on_item_failure is set to dlq, verify DLQ path permissions"
      }
    ],
    "debugging_tools": [
      {
        "tool": "Verbose mode (-v)",
        "usage": "prodigy run workflow.yml -v",
        "shows": "Claude streaming output, detailed execution logs"
      },
      {
        "tool": "Claude JSON logs",
        "usage": "Check log path displayed after each Claude command",
        "shows": "Full conversation history, tool invocations, token usage"
      },
      {
        "tool": "Event logs",
        "usage": "prodigy events with job_id parameter",
        "shows": "Timeline of workflow execution, agent lifecycle, errors"
      },
      {
        "tool": "DLQ inspection",
        "usage": "prodigy dlq show with job_id",
        "shows": "Failed items with error details and retry information"
      },
      {
        "tool": "Checkpoint inspection",
        "usage": "Check state directory for mapreduce jobs",
        "shows": "Job state for resumption, processed items"
      }
    ]
  },
  "version_info": {
    "analyzed_version": "0.2.0+",
    "analysis_date": "2025-01-11",
    "schema_version": "1.0",
    "completeness": "comprehensive"
  }
}